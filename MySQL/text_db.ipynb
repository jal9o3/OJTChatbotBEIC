{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Database Notebook\n",
    "I made this notebook to explore the MySQL Python Connector. Markdown cells have\n",
    "been added for the team's future reference.\n",
    "### WARNING: Do not 'RUN ALL' cells! \n",
    "### This notebook contains cells that remove databases, papers, writes data, etc.\n",
    "### For exploration purposes only! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enter MySQL Password\n",
    "Password will be input this way to avoid being exposed in the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "password = input(\"Enter your database password: \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial Connection\n",
    "This cell connects us to MySQL. Change the host and username as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_db = mysql.connector.connect(\n",
    "    host=\"127.0.0.1\",\n",
    "    user=\"root\",\n",
    "    password=password,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initializing the MySQL cursor\n",
    "This cursor allows us to perform MySQL operations using Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mycursor = text_db.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a database\n",
    "This cell creates a new database. Change the database name as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mycursor.execute(\"CREATE DATABASE technical_database\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drop a database\n",
    "### (Be careful with this cell!)\n",
    "This cell removes an existing database. Change name as needed (the cell below outputs a list of existing databases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mycursor.execute(\"DROP DATABASE technical_database\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# List all existing databases\n",
    "This cell displays all MySQL databases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('information_schema',)\n",
      "('mysql',)\n",
      "('performance_schema',)\n",
      "('sakila',)\n",
      "('sys',)\n",
      "('technical_database',)\n",
      "('world',)\n"
     ]
    }
   ],
   "source": [
    "mycursor.execute(\"SHOW DATABASES\")\n",
    "for x in mycursor:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connecting to Database\n",
    "This connects us to a specific database. Change the database name as needed (you \n",
    "can choose from the list of databases output by the cell above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_db = mysql.connector.connect(\n",
    "    host=\"127.0.0.1\",\n",
    "    user=\"root\",\n",
    "    password=password,\n",
    "    database=\"technical_database\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mycursor = text_db.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drop a table from the database\n",
    "### (Be careful with this cell!)\n",
    "\n",
    "This removes a table from the database that we are connected to. Change the table name as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mycursor.execute(\"DROP TABLE papers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a sample table for papers\n",
    "This creates a database table called 'papers' with columns for primary key (auto incremented), title, author, and chunk (consisting of 255 chars at most)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mycursor.execute(\"\"\"\n",
    "    CREATE TABLE papers (\n",
    "        id INT AUTO_INCREMENT PRIMARY KEY,\n",
    "        title VARCHAR(255),\n",
    "        author VARCHAR(255),\n",
    "        chunk TEXT(255)\n",
    "    )\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show all tables in database\n",
    "This cell lists all the tables in the database that we're connected to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('chunks',)\n",
      "('papers',)\n"
     ]
    }
   ],
   "source": [
    "mycursor.execute(\"SHOW TABLES\")\n",
    "for x in mycursor:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# See current directory\n",
    "We're about to work with files (Tesseract output .txt files), so we need to check our current working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER\\Documents\\OJTChatbotBEIC\\MySQL\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upload an extracted paper into the database\n",
    "The paper is divided into chunks (up to length 255) and stored into the database, \n",
    "along with metadata such as title and author name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the entire file content\n",
    "with open('../Tesseract/Extracted.txt', 'r', encoding=\"utf-8\", errors='ignore') as file:\n",
    "    file_content = file.read()\n",
    "\n",
    "# Split the content into smaller strings (up to 255 characters)\n",
    "max_length = 255\n",
    "split_content = [file_content[i:i + max_length] for i in range(0, len(file_content), max_length)]\n",
    "\n",
    "title = \"A CASE STUDY OF UNDERSTANDING THE BONAPARTE BASIN USING UNSTRUCTURED DATA ANALYSIS WITH MACHINE LEARNING TECHNIQUES\"\n",
    "authors = \"A.N.N. Sazali, N.M. Hernandez, F. Baillard, K.G. Maver\"\n",
    "\n",
    "# Insert each smaller string into the database\n",
    "query = \"INSERT INTO papers (title, author, chunk) VALUES (%s, %s, %s)\"\n",
    "for content in split_content:\n",
    "    mycursor.execute(query, (title, authors, content))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Commit the changes into the database\n",
    "This updates the database, this time for real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_db.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Print all rows of the table\n",
    "Useful for checking the committed changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1, 1, \"\\nA CASE STUDY OF UNDERSTANDING THE\\nBONAPARTE BASIN USING UNSTRUCTURED DATA\\nANALYSIS WITH MACHINE LEARNING TECHNIQUES\\n\\nAN. Sazali!, N.M. Hernandez’, F. Baillard', K.G. Maver!\\n\\n'Traya Energies\\n\\nSummary\\n\\nAs part of exploration and production the oil and gas \")\n",
      "(2, 1, 2, 'industry produce substantial amounts of data\\nwithin different disciplines of which 80% are unstructured like reports, presentations, spreadsheets etc.\\nThe value of technical work is reduced due to the lack of time available for analysis and critical\\nthink')\n",
      "(3, 1, 3, 'ing and the under-utilization of the data. To assist geoscientist and engineers, Machine Learning\\n(ML) and Artificial Intelligence (AI) technologies are applied to process the unstructured data from\\n440 wells from the Bonaparte Basin in Australia making i')\n",
      "(4, 1, 4, 't possible to perform more accurate analysis\\nand make faster decisions.\\n\\nBased on the play-based exploration pyramid concept, the time spent at the Basin Focus stage can be\\nreduced, and more time are available to focus on the other project stages. The exp')\n",
      "(5, 1, 5, 'lorationist will be\\nable to bring more value to the study.\\n\\nIt will be shown that potential issues encountered during exploration of the Bonaparte Basin can be\\nidentified. Based on a quick look and gathering of all information it can be concluded that mos')\n",
      "(6, 1, 6, 't of the\\nproduction in the Bonaparte Basin is from Jurassic and Triassic with observed net pay of 18-60m\\nthickness, porosity of 11-29% and saturation of 11-55% Sw.\\n\\n\\n\\nA Case Study of Understanding the Bonaparte Basin using Unstructured Data Analysis with\\n')\n",
      "(7, 1, 7, 'Machine Learning Techniques\\n\\nIntroduction\\n\\nAs part of exploration and production the oil and gas industry produce substantial amounts of data\\nwithin different disciplines of which 80% are unstructured like reports, presentations, spreadsheets etc\\nand it i')\n",
      "(8, 1, 8, 's expected to grow exponentially. As a result, geoscientists and engineers spend 50 to 80% of\\ntheir time searching and assembling data and only 1 to 5% of the data is fully utilized. The value of\\ntechnical work is therefore reduced due to the lack of time')\n",
      "(9, 1, 9, ' available for analysis and critical thinking\\nand the under-utilization of the data. To assist geoscientist and engineers, Machine Learning (ML)\\nand Artificial Intelligence (AI) technologies are applied to process the unstructured data making it\\npossible ')\n",
      "(10, 1, 10, 'to perform more accurate analysis and make faster decisions.\\n\\nIn this case study the area of interest covers Bonaparte Basin, which is located north-west of\\nthe Australian continental margin (Figure 1). It joins the Money Shoal basin in the north-east and')\n",
      "(11, 1, 11, '\\nthe Browse Basin in the south-west. Furthermore, the Timor Trough defines the northern boundary.\\nThe areal extent of the basin is approximately 270,000 sq. km. The objective of this study is to\\nunderstand and obtain meaningful insights into the Bonaparte')\n",
      "(12, 1, 12, ' Basin based on the substantial amount\\nof information available in previous studies, reports and presentations. The unstructured data of the\\nBonaparte Basin have been ingested in a Knowledge Container through consecutive ML and AI\\npipelines and analysed u')\n",
      "(13, 1, 13, 'sing big data analytics tools.\\n\\nConsist of several structural elements :\\n@ Ashmore Platform © Malita Graben\\n© Vulcan Sub-Basin © Sahul Platform\\n\\n© Londonderry High @ Flamingo High\\n© Petrel Sub-basin @ Flamingo Syncline\\n© Darwin Shelf @® Sahul Syncline\\n@ C')\n",
      "(14, 1, 14, 'alder Graben ® Nancar Trough\\n@ Troubadour Terrace Laminaria High\\nFigure 1 Location of the Bonaparte Basin within the Australian continental margin (left) and 14\\nstructural elements observed within the Bonaparte Basin (right).\\n\\nMethodology\\n\\nAs of 2021, the')\n",
      "(15, 1, 15, ' Bonaparte Basin encompasses 440 wells representing 58 years of exploration history\\nsummarized in over 270,000 pages of documents and in 250,000 images. It is estimated that billions of\\ndollars have been invested over the years to acquire and interprete t')\n",
      "(16, 1, 16, 'he data, making it a substantial\\nsource of information for new exploration activities.\\n\\nThe Play Based Exploration (PBE) approach is often used as a traditional framework to refine the\\ngeoscientists’s understanding from a broad basin level to a narrow pro')\n",
      "(17, 1, 17, 'spect focus (Lottaroli et al., 2016).\\nAs a start such an approach often involves capturing the current state of knowledge with massive\\nbackground resources to understand and analyse the key features of the basin and the major risks\\nassociated to it. Such ')\n",
      "(18, 1, 18, 'information is primarily available in unstructured data, requiring geoscientist and\\nengineers to process and ingest the information before focusing on a specific play and prospect using\\nstructured data. Therefore, we have modified the existing PBE pyramid')\n",
      "(19, 1, 19, ' to introduce an additional\\n\\n\\n\\ndimension associated with data science identifying the different types of data available at different\\nstages, allowing us to better define the best suited ML/AI strategy for a given stage (Figure 2).\\n\\nSTRUCTURED\\n\\nTora nercar')\n",
      "(20, 1, 20, 'e cercest\\nUNSTRUCTURED ‘ 8 rence siento renown, se 30008)\\n\\nof being present and effective over 20,\\n\\n@ Assess the possibsty a play may\\nexiets ina basin\\n\\nFigure 2 Customized Play Based Exploration (PBE) pyramid with ML technology (Modified from\\nLottaroli et')\n",
      "(21, 1, 21, ' al., 2016).\\n\\nFocusing on the unstructured data associated with the Basin and Play Analysis, all the data from the\\nBonaparte Basin have been processed through a succession of AI/ML automated pipeline such as\\nNatural Language Processing or Deep Convolution')\n",
      "(22, 1, 22, 'al Neural Network (Hernandez et al., 2019), (Figure\\n3). The sharable structured data is then further processed through deeper level of analytics to detect\\ntrends and anomalies present within the data. Machine assistance is heavily used in repetitive tasks')\n",
      "(23, 1, 23, ' early\\nin the process during the processing of the data and up to 95% of the tasks will be performed by the\\nmachine. This provides additional time for the specialist to focus on critical thinking and cognitive skills\\n\\nto interpret the data.\\n\\nMACHINE LEARN')\n",
      "(24, 1, 24, 'ING PIPELINE ANALYTICS GEOLOGICAL INSIGHTS\\n\\nEarly intespretation on\\n\\n* lithology Cloud Geological environment\\n\\n‘Text Search = —~ Data are geospatially\\n+ Image Classification - + » distributed on maps for\\nDeep Convolutional trends and anomalies\\n\\nUnstructur')\n",
      "(25, 1, 25, 'ed Neural Network Sharable observation\\n\\nData Structured » Image Search\\nData\\n+ |, Extracted | Metadata Extraction |, Document\\n\\nText and Tagging Tags Heat Map\\n\\n‘Natural Language Processing\\n\\nEarly trend can be observed\\nacross the whole basin\\n\\nIdentify well a')\n",
      "(26, 1, 26, 'nalogues and\\n\\n* Knowledge Graph —- —* relationship between wells\\n\\n95% 1909 — 6) —\\n\\nMI/AI sequence automated with Analytics tools for data display Hurnan high-level interpretation\\nhuman in the loop for QC\\n9,\\n\\ntue oN $$ 5% 40% mee |\\n\\nFigure 3 Unstructured B')\n",
      "(27, 1, 27, 'ig Data pipeline\\n\\nIn this case study, interpretation using the Big Data workflow was used to understand the exploration\\nhistory, how the basin developed, its petroleum system and the main issue of the dry wells occurrence\\nto avoid repeating the mistakes o')\n",
      "(28, 1, 28, 'f the past and improve future decision making.\\n\\n\\n\\nBy analysing the data, five potential issues are identified i.e. (i) Discrepancies in Formation Tops, (ii)\\nLimited understanding of Lithology Distribution, (iii) Limited Mineral Composition Understanding,\\n')\n",
      "(29, 1, 29, '(iv) Fluid Distribution, and (v) Pressure/Temperature Patterns. Each potential issue is tackled by\\nidentifying trends and anomalies across the basin using images, tables and plots extracted from the\\nunstructured data corpus.\\n\\nResults\\n\\nAs an example, the a')\n",
      "(30, 1, 30, 'nalysis of the (ii) Limited Understanding of Lithology Distribution, shown in\\nFigure 4, is performed using heatmaps. The heatmaps show the distribution of clastic and carbonates\\nacross the Bonaparte Basin and identify patterns and anomalies present in the')\n",
      "(31, 1, 31, ' area. The result can be\\nsupported by the stratigraphic chart where the carbonate environment occurs in the younger formation\\nfrom Cretaceous to Neogene period, whereas clastic environment is present in the older formations from\\nTriassic to Cretaceous.\\n\\nB')\n",
      "(32, 1, 32, 'asal vanegrassive enadetone Limeston:\\nand marine shelf sand mestone\\nHE arine claystone and shale\\n\\nModitied from Frankowlez & McClay 2009\\n\\nFigure 4 Lithology distribution on heatmaps (left) and corresponding stratigraphic chart (right).\\n\\nThe analysis of th')\n",
      "(33, 1, 33, 'e (iii) Limited Mineral Composition Understanding, shown in Figure 5, utilizes the\\nthin section automatically extracted using ML classification over the full area and suggests that:\\n\\nQuartz overgrowth and kaolinite are quite common in Bonaparte Basin\\n\\nMic')\n",
      "(34, 1, 34, 'a mineral can be observed at the north-eastern part of the basin\\n\\nHighly corroded, skeletal feldspar has been extensively dissolved, which forms secondary\\nporosity, and can be observed in the northern part of the basin\\n\\nSome patchy siderites are also obse')\n",
      "(35, 1, 35, 'rved in the southern part of the basin\\n\\n\\n\\nstam (cone\\nFigure 5 Thin section images distributed on a map across the Bonaparte Basin.\\n\\nConclusion\\n\\nA regional understanding is critical and time consuming as it involves dealing with a very large data\\n\\nvolume. ')\n",
      "(36, 1, 36, 'Within a project time frame, based on PBE pyramid, the time spent at the Basin Focus stage\\n\\ncan be reduced, and more time are available to focus on the other project stages. The explorationist will\\nbe able to bring more value to the study.\\n\\nML application')\n",
      "(37, 1, 37, 's have proven to be able to play a crucial part in order to organize large unstructured\\ndata corpuses. This allows faster and accurate decision making within the fast-moving industry.\\n\\nIn this study, some potential issues encountered during exploration of')\n",
      "(38, 1, 38, ' the Bonaparte Basin can be\\nidentified. Based on a quick look and gathering of all information it can be concluded that most of the\\nproduction in the Bonaparte Basin is from Jurassic and Triassic with observed net pay ~18-60m\\nthickness, porosity ~11-29% a')\n",
      "(39, 1, 39, 'nd saturation ~11-55% Sw.\\n\\nReferences\\n\\nHernandez N., Lucafias P., Graciosa J.C., Mamador C., and Panganiban L. C. I, 2019: Automated\\ninformation retrieval from unstructured documents utilizing a sequence of smart machine learning\\nmethods within a hybrid c')\n",
      "(40, 1, 40, 'loud container. EAGE Workshop on Big Data and Machine Learning for E&P\\nEfficiency 25 - 27 February.\\n\\nLottaroli F., Craig J., Cozzi A., 2016: Evaluating a vintage play fairway exercise using subsequent\\nexploration results: did it work? Petroleum Geoscience')\n",
      "(41, 1, 41, ', Vol 24, no 2, p. 159 — 171.\\n\\nMaver K.G., Hernandez N., Lucafias P., Graciosa J.C., Mamador C., Panganiban L.C.L, Yu C., and\\nMaver M.G., 2018: An automated information retrieval platform for unstructured well data smart\\nmachine learning algorithms within')\n",
      "(42, 1, 42, ' a hybrid cloud container. EAGE/PESGB Workshop on Machine\\nLearning, 29 — 30 November.\\n\\n\\n')\n",
      "(43, 2, 1, \"\\nN.M. Hernandez’, P.J. Lucafias', J.C. Graciosa', C. Mamador’, L. Caezar', I. Panganiban’, C. Yu', K.G.\\nMaver’*, M.G. Maver”\\n' Traya Energies, 7 KGM geoconsulting\\n\\nSummary\\n\\nThere is a large amount of historic and valuable well information available stored\")\n",
      "(44, 2, 2, ' either on paper and more\\nrecently as digital documents and reports in the oil and gas industry especially by national data management\\nsystems and oil companies, These technical documents contain valuable information from disciplines like\\ngeoscience and e')\n",
      "(45, 2, 3, 'ngineering and are in general stored in a unstructured format. To extract and utilize all this well\\ndata, a machine learning-enabled platform, consisting of a carefully selected sequence of algorithms, has been\\ndeveloped as a hybrid cloud container that a')\n",
      "(46, 2, 4, 'utomatically reads and understands the technical documents with little\\nhuman supervision. The user can upload raw data to the platform, which are stored on a private local server. The\\nmachine learning algorithms are activated and implement the necessary p')\n",
      "(47, 2, 5, 'rocessing and workflows. Structured\\ndata is generated as output, which are pushed through to a search engine that is accessible to the user in the cloud.\\nThe aim of the platform is to ease the identification of important parts of the technical documents, ')\n",
      "(48, 2, 6, 'automatically\\nextract relevant information and visualize it for the user, so they can easily do further analysis, share it with\\ncolleagues or agnostically port it to other platforms as input.\\n\\nFirst EAGE/PESGB Workshop on Machine Learning\\n\\n\\nIntroduction\\n\\n')\n",
      "(49, 2, 7, 'There is a large amount of historic well information available stored either on paper and more recently\\nas digital documents and reports in the oil and gas industry. These technical documents contain\\nvaluable information from diverse disciplines such as g')\n",
      "(50, 2, 8, 'eology, geophysics, petrophysics, reservoir\\nengineering, drilling and other subject matters and are in general stored in a unstructured format.\\n\\nEspecially national data management systems and oil companies hosts these large amounts of very\\nvaluable histo')\n",
      "(51, 2, 9, 'rical well data, which contain information such as reservoir metadata, images, texts, and\\nprocessed information, such as lithology, geology, shows, drilling risks etc. Due to the large volume,\\nvintage variety, and non-standard formats, extraction of valua')\n",
      "(52, 2, 10, 'ble information, which can be used as\\ninput for further work, is an arduous task as the manual nature of data mining is very time-consuming.\\n\\nTo extract and utilize all this well data, a machine learning-enabled platform has been developed as a\\nhybrid clo')\n",
      "(53, 2, 11, 'ud container that automatically reads and understands hundreds or thousands of technical\\ndocuments with little human supervision. The aim of the platform is to ease the identification of\\nimportant parts of the technical documents, automatically extract re')\n",
      "(54, 2, 12, 'levant information and visualize it\\nfor the user, so they can easily do further analysis, share it with colleagues or agnostically port it to\\nother platforms as input.\\n\\nMethodology\\n\\nThe platform utilizes a hybrid data service architecture, which leverages')\n",
      "(55, 2, 13, ' the 2-tier strength of both\\ncloud and private servers. The hybrid architecture serves to:\\n\\nEnhance the platform’s security and data privacy by storing raw data locally\\nIncrease data shareability in real-time by utilizing a cloud solution\\n\\nReduce data red')\n",
      "(56, 2, 14, 'undancy and increase data integrity among users\\n\\nProvide a pragmatic solution to optimize data storage costs\\n\\nThe user can upload raw data to the platform, which are stored on a private local server. The machine\\nlearning algorithms are activated and imple')\n",
      "(57, 2, 15, 'ment the necessary processing and workflows. Structured\\ndata is generated as output, which are pushed through to a search engine that is accessible to the user\\nin the cloud (Figure 1).\\n\\nFigure 1 The hybrid architecture of platform (ElasticDocs) utilizing ')\n",
      "(58, 2, 16, 'the 2-tier strength of local and\\ncloud sever applications for data security, integrity and shareability. Carefully selected machine\\nlearning sequence for automated text and image analysis include: optical character recognition, deep\\nconvolutional neural n')\n",
      "(59, 2, 17, 'etwork and image clustering.\\n\\nMachine Learning\\n\\n\\nThe platform capitalizes on the machine learning algorithms that automatically process the\\nunstructured data into a condensed format in which only pre-selected information are stored. The\\nmachine learning a')\n",
      "(60, 2, 18, 'lgorithms employs a unique sequence of separate steps, which are set-up to mimic\\nthe human experience of processing unstructured documents.\\n\\nWorkflow\\n\\nA Norwegian dataset consisting of 400 well reports (58,000 pages) and an Australian well database\\nconsis')\n",
      "(61, 2, 19, 'ting of 6,000 pages have been used as training data for generating structured data.\\n\\nFor the unstructured data the first machine learning step is the digitization and conversion of .pdf or\\n.docx file formats into an editable format. This conversion uses O')\n",
      "(62, 2, 20, 'ptical Character Recognition (OCR),\\nwhere the machine identifies each character in the image.\\n\\nAfter the documents are digitized important information has to be identified. This metadata extraction\\nand tagging utilizes Natural Language Processing (NLP) to')\n",
      "(63, 2, 21, ' tokenize each digitized text and identify\\nterms of significant value. Named Entity Recognition (NER) is then performed to create a model to\\nextract the metadata like well name, basin, permit, operator, well classification, latitude, longitude,\\nspudding d')\n",
      "(64, 2, 22, 'ate, kelly bushing etc.\\n\\nFor the images extracted by the digitization process, a modified VGG-16 neural network is used to\\nautomatically classify tables, charts, stratigraphic chart images, maps, seismic, core samples and\\nscanning electron microscope imag')\n",
      "(65, 2, 23, 'es within each document (Simonyan ef al., 2014)\\n\\nFor the visualization of the images an at-Distributed Stochastic Neighbor Embedding (t-SNE)\\nalgorithm is used to quantify the similarity of each image, which has been developed to visualize\\nhigh-dimensional')\n",
      "(66, 2, 24, ' datasets and reveal clustering within the datasets (van der Maaten e¢ al., 2008).\\n\\nThe output from the machine learning sequence is then exposed to the users through the platform to\\nease the work of identifying important information and perform analysis ')\n",
      "(67, 2, 25, 'in a more efficient way. The\\nextracted information is outputted in an agnostic format, which can be efficiently loaded to other\\nplatforms or used as is, ie. X, Y or Latitude/Longitude, formation tops in csv or excel format,\\ndigitized maps as shapefile for')\n",
      "(68, 2, 26, ' loading into GIS software.\\n\\nDiscussion and conclusion\\n\\nWells provide key information about the subsurface in oil and gas exploration and production but at a\\nsubstantial cost. As this valuable information associated with a well is often stored as unstruct')\n",
      "(69, 2, 27, 'ured\\ndata, it is difficult to do further analysis or apply additional artificial intelligence processing to the\\nwell database to enable geoscientists to gain new insights and extract new relationships.\\n\\nThe carefully selected sequence of machine learning ')\n",
      "(70, 2, 28, 'algorithms in the workflow deals with these\\nlarge unstructured datasets, is housed within a hybrid cloud platform to automatically extract relevant\\ninformation within technical documents and convert the unstructured data into a shareable structured\\ndatase')\n",
      "(71, 2, 29, 't.\\n\\nReferences\\n\\nSimonyan, K. & Zisserman, A., 2014: Very Deep Convolutional Networks for Large-scale Image\\nRecognition. arXiv preprint arXiv: 1409.1556\\n\\nvan der Maaten, L.J.P. & Hinton G.E., 2008]: Visualizing High-Dimensional Data using t-SNE.\\nJournal of')\n",
      "(72, 2, 30, ' Machine Learning Research, 9, 2576-2605.\\n\\non Machine Learning\\n\\n')\n",
      "(73, 3, 1, '\\nSupporting the UN 2050 Net Zero goals by reading\\n\\nthe earth better\\n\\nNina Marie Hernandez\", Kim Gunn Maver and Charmyne Mamador present the ED2\\ninitiative, providing multivariate earth data to support UN climate change goals.\\n\\nIntroduction\\n\\nAgainst the ba')\n",
      "(74, 3, 2, 'ckdrop of the current global pandemic, the UN\\n2050 net zero goals call for global greenhouse emissions to be cut\\nby half by 2030 and reach net zero no later than 2050 to achieve\\nthe goal of limiting global warming to 1.5 Celsius above pre-in-\\ndustrial lev')\n",
      "(75, 3, 3, 'els. The EU has pledged to become the first carbon\\nneutral continent by 2050, and more than 110 other countries\\nhave pledged carbon neutrality by this time. Several energy com-\\npanies have laid out their medium-to-long-term plans towards\\nthis objective, w')\n",
      "(76, 3, 4, 'hich includes acquisition of renewables assets,\\nand developing competitive technologies for carbon capture and\\nstorage (CCS) and hydrogen production. Among the companies\\nthat have set zero-emissions targets are BP, Shell, Total, Repsol,\\nEquinor and Petron')\n",
      "(77, 3, 5, 'as. This energy pivot will require significant\\ncapital spending to reach the goals.\\n\\nTo determine the technical and economic feasibility of these\\nnew energy technologies and at the same time achieve sustainable\\ndevelopment goals, multivariate earth data, ')\n",
      "(78, 3, 6, 'both existing and\\nnew, are required and are key to making the right management\\nand investment decisions.\\n\\nEarthDoc pointing to the future\\n\\nTo this end, more than 39 years of conference proceedings and\\npublications are already available from EAGE through E')\n",
      "(79, 3, 7, 'arth-\\nDoc, which aggregates a wealth of subsurface information from\\nresearch institutions, energy companies, service companies\\nand dedicated professionals. The 70,000 scientific publications\\nfocus on conventional topics within geoscience and engineering\\ne')\n",
      "(80, 3, 8, 'specially in relation to oil and gas extraction. This subsurface\\ninformation can be upcycled to provide highly valuable insights\\nfor new energy technologies. The reuse of existing oil and\\ngas data reduces data acquisition costs, which translate into a\\nred')\n",
      "(81, 3, 9, 'uction in research and development costs.\\n\\nThrough a collaboration between Iraya Energies and EAGE, a\\nnew database initiative has been launched with EarthDoc’s repos-\\nitory of 70,000 scientific publications being processed using the\\nlatest in machine lear')\n",
      "(82, 3, 10, 'ning and artificial intelligence techniques\\nand initially available to institutional and corporate subscribers.\\nThe whole data corpus is made instantly accessible and provides\\nnew tools to search and retrieve the diversity of information that\\none is looki')\n",
      "(83, 3, 11, 'ng for across any technical discipline.\\n\\n‘raya Energies\\n“Corresponding author, E-mail: nmh@irayaenergies.com\\nDOI: 10.3997/1365-2397.fb2021045\\n\\nWith Big Data analytics applied to the entire data corpus of\\n70,000 scientific publications, additional in-depth')\n",
      "(84, 3, 12, ' and advanced\\nnavigation options are now available.\\n\\nTo extract information on a large scale, the ElasticDocs AI\\npipeline is applied to the EarthDoc corpus. This pipeline consists\\nof a set of algorithms which are used to identify blocks/segments\\nwithin th')\n",
      "(85, 3, 13, 'e document corpus. Optical Character Recognition\\n(OCR) is applied to the text segments to convert them into\\nprocessable text. A Deep Convolutional Neural Network (DCNN)\\nalgorithm pipeline classifies the images into various generic and\\ngeological image cla')\n",
      "(86, 3, 14, 'sses, including tables, seismic, map, well\\nplots, stratigraphic charts, core, thin sections, image logs, and\\nrose diagrams. Untagged images are generically categorized as\\nfigures and remain accessible to the user.\\n\\nThe ingested documents are now available')\n",
      "(87, 3, 15, ' as structured\\ninformation for analysis, which is possible in different ways:\\n\\n+ Metadata extraction of relevant information such as locations,\\nnames etc.\\nEfficient inter and intra-search of the global text corpus for\\nquantitative textual analysis of docu')\n",
      "(88, 3, 16, 'ment contents to create\\nautomated and standardized geoscience or engineering content\\nsummary.\\nAutomated heatmaps to visualize density of information\\nwithin a basin or country.\\nImage extraction of similar image classes for efficient identifi-\\ncation of ana')\n",
      "(89, 3, 17, 'logues, duplicates and clusters.\\n\\nSome key functionality that has a significant impact on utilizing\\nthe scientific publications is that not only are images classified\\naccording to type, but it is possible to do a search on image\\nembedded text making the s')\n",
      "(90, 3, 18, 'earch capabilities far more advanced\\nthan just a normal search-and-find option. The search results of\\nthis database are exportable as .csv files making statistical work\\nand analysis instantly possible across data points.\\n\\ntary corporate data meets publish')\n",
      "(91, 3, 19, 'ed\\n\\nic knowledge.\\nRecognizing that energy companies hold valuable information in\\ntheir repositories accumulated throughout many decades of oper-\\nations, the data kept internally can now be easily integrated with\\npublished geoscience and engineering data. ')\n",
      "(92, 3, 20, 'The combination of\\n\\n\\n\\nFinal_well_Report_Bas\\n\\nKNOWLEDGE GRAPH\\n\\nFigure 1 Data source tray in the new database allows\\naccess to multiple databases, including, but not\\nlimited to, public data, proprietary data, and EarthDoc\\ncorpus. Reference: Geoscience Austr')\n",
      "(93, 3, 21, \"alia, NOPIMS\\n\\nFigure 2 Earth readability tools are available in the\\nnew database dashboard (Rahim et al., 2012).\\n\\n(© Fiber Optic Technology for Reservou Survediance,\\n\\n@ Operatonal Excelence in Qatar's Fest Successful\\n' ber Ope Sensing for mnproves Wellbar\")\n",
      "(94, 3, 22, 'e\\nJo integrated Approach a Optenze Matera Selechon\\n\\nEngineanng Suceess mo Hartline Operations\\n\\n© few totalugent Completion Welt Design For.\\n\\n(@ Masere Hyaraune Fracture Sumulabon on South\\n\\n© integrated Ape\\n\\n(© Seratgrapluc Architecture of the Latest Juras')\n",
      "(95, 3, 23, 'sic\\n\\n(© Natural Fracture interaction with Hydraule aEQ4§Rf Jurassic to Early Barrer\\n\\n‘© Breaking Ou Recovery Lent in Malaysian.\\n\\ndatabase results in a two-way enrichment process between public\\nand private information. Scientific studies from peers in rela')\n",
      "(96, 3, 24, 'ted\\nfields offer additional information that either validates internal\\ncompany studies, or offer alternative technical perspectives from\\nindustry experts.\\n\\nIn the Figure 1 example above, we show how exploring\\ntemperature information available in a Final W')\n",
      "(97, 3, 25, 'ell Reports repos-\\nitory that is commonly considered as proprietary corporate data,\\nis combined with published EarthDoc contents. (Data source:\\nNOPIMS)\\n\\n@ Pus.ications Figure 3 Visualization of knowledge graph illustrates\\n\\nrelated geological and engineeri')\n",
      "(98, 3, 26, 'ng concepts.\\n\\nSeveral Earth readability tools are deployed in ED2K to\\namplify EarthDoc capabilities. This includes access to digital\\ntextual content, the ability to quality control OCR results and\\nread in multiple languages via machine-translate. Word clo')\n",
      "(99, 3, 27, 'uds are\\nsimple context clues which provide a quick summary of content\\nof the articles.\\n\\nThe full ED2K corpus is geotagged to more than 800\\ngeological basins around the world. The geotagging is one of the\\nmost complex machine learning tasks in this impleme')\n",
      "(100, 3, 28, 'ntation,\\nbecause the scientific articles contain both location of the\\n\\n\\n\\ngeological area of interest, as well as the location of confer-\\nences where the publications are presented. Often, these two\\nreference locations are different and introduce ambiguity')\n",
      "(101, 3, 29, ' for the\\nsystem.\\n\\nAnother feature that is implemented is the knowledge graph\\nvisualization. It illustrates the connectivity of ‘related concepts’\\nbased on publication references. In the example above, it shows\\n‘operational excellence’, ‘optimization’ and ')\n",
      "(102, 3, 30, '‘engineering suc-\\ncess’ within the same network (Figure 3). Similarly, ‘hydraulic\\nfracture stimulation’, ‘natural fracture interaction’, and ‘Jurassic\\ncarbonates’ show connectivity. In theory, a knowledge graph can\\nbe built in multiple ways by the user.\\n\\n')\n",
      "(103, 3, 31, 'Utilizing ED2K to reach the zero-emission goal\\n\\nThe advanced access in the new database makes possible a new\\nuse of the highly valuable subsurface information and facilitates\\ncross-discipline usage.\\n\\nMany of the new cross-function usages of the existing\\ns')\n",
      "(104, 3, 32, 'cientific publication repository are geothermal energy, hydrogen\\nenergy, CCS and windmill foundation derisking.\\n\\nA query for ‘carbon capture and storage’ generates an\\ninformation heat map captured in Figure 4. The map shows the\\ngeographical distribution o')\n",
      "(105, 3, 33, 'f the resulting publications either\\nbased on country or basin.\\n\\nFigure 5 maps out the major carbon capture projects around\\nthe world vis-a-vis needs requirement, Europe and US show high\\nactivity in CCS initiatives, which are driven by government poli-\\ncy.')\n",
      "(106, 3, 34, ' Comparing Figure 4 and Figure 5 (left), it may be incidental,\\n\\nalthough not entirely surprising that where there is a significant\\namount of data to aid technical and management decision mak-\\ning, CCS implementations are also active.\\n\\nMAP KNOWLEDGE GRAPH\\n')\n",
      "(107, 3, 35, '\\nResults Density\\n\\nThe new database contains climate change and greenhouse\\ngases industry discussion materials spanning over three decades.\\nAlready between 1990 and 2000, the possibility of disposing\\ncarbon dioxide (CO,) is discussed in papers such as J. L')\n",
      "(108, 3, 36, 'eeb. W,\\n(1993), and Wildenborg, F.B., et. al., (1996), in conjunction with\\nthe use of CO, for improved oil recovery methods (IOR).\\n\\nBetween 2001 and 2010, the discussions tackled issues in\\nestablishing a geological storage hub (Espie, 2000) and various\\npo')\n",
      "(109, 3, 37, 'tential site feasibility studies (Gregersen et. al, 2000), costs\\n(Wildenborg et. al, 2000), use of seismic monitoring (Benson,\\n2003), (Gosselet et. al., 2006), pilot and numerical simulations\\n(Domitrovic et. al., 2005), (Battistelli et.al, 2005), reservoi')\n",
      "(110, 3, 38, 'r\\nperformance (Broad et.al, 2007) and improving facilities perfor-\\nmance to reduce operating costs in CO, and H,S contaminated\\nfields (Swatton et. al, 2009).\\n\\nFrom 2011 up to the present, with the advancements in\\nseismic methods, reservoir modelling techn')\n",
      "(111, 3, 39, 'iques and laboratory\\nexperiments (Bolourinejad, 2013} many more complex analyses\\non the subject of carbon storage were performed. Combined with\\nenhanced oil recovery experiments (EOR), the amount of data\\nmodelling CO, behavior underground has multiplied t')\n",
      "(112, 3, 40, 'en-fold.\\n\\nIn areas where it is not possible to implement subsurface\\ncarbon capture, utilization strategies are discussed by Harsh, A.\\net. al (2014) on the industrial usage of CO, including, but not\\nlimited to, polymer processing and chemicals production.\\n')\n",
      "(113, 3, 41, '\\nFor a deeper dive in the corpus, we draw an arbitrary areal\\npolygon, indicated by the yellow box in Figure 5, around South\\nEast Asia. Our new database reveals some of the strategies\\nthat have been identified by an operator to manage greenhouse\\nemissions ')\n",
      "(114, 3, 42, 'in its operations in Malaysia (Mehta et.al.,2008).\\nThis includes, among others, ending continuous gas flaring\\n\\nFigure 4 Indicative geolocation of global knowledge\\nabout ‘carbon capture and storage’ between 2008\\nto 2020.\\n\\nFigure 5 Location of major carbon ')\n",
      "(115, 3, 43, 'capture projects\\naround the world (leff) and the requirement index\\nbased on fossil fuel production and consumption\\n(tight). Reference: Global CCS Institute.\\n\\n\\n\\nand minimizing gas venting, improving energy efficiency in\\nthe design of assets and production ')\n",
      "(116, 3, 44, 'operations, accounting for\\nthe cost of emitting greenhouse gases in investment decisions,\\nsupporting development of CCS infrastructures, and policy\\nadvocacy.\\n\\nThe rich diversity of data available in the new database\\nare illustrated in Figures 6 and 7. The')\n",
      "(117, 3, 45, 'se include graphical\\ninformation of PVT analyses, miscibility, flow rates, and time-\\nlapse pressure profiles, which are useful for reservoir simulation\\nstudies focused on the interaction of reservoir rocks with CO,\\nduring injection. Also available are pet')\n",
      "(118, 3, 46, 'rography data that makes\\nit easier to interpret reservoir modelling results by being able\\nto look at the structural fabric of the storage rocks down to\\nmicroscopic levels.\\n\\nNew energy from old data\\nWith this data-driven strategy it will be possible to fac')\n",
      "(119, 3, 47, 'ilitate the\\npivot to new energy from valuable existing data. No part of the\\ndata is left unprocessed. It may be that not all relevant informa-\\ntion will exist within the 70,000 scientific publications, but this\\ncan be confirmed instantly saving valuable t')\n",
      "(120, 3, 48, 'ime and resources\\ndoing data exploration. On the other hand, if the information is\\navailable, it will be immediately accessible, trackable and put\\ninto context with other relevant information and geographically.\\nFor example, the geothermal gradient is a k')\n",
      "(121, 3, 49, 'ey parameter of\\ninterest in relation to geothermal energy. The temperature data in\\n\\nthe new database has been acquired by energy companies mostly\\nfor the purpose of understanding the hydrocarbon generation\\nwindow, petrophysical interpretation and reservoi')\n",
      "(122, 3, 50, 'r modelling\\nanalyses. They can be relooked at for further exploratory geo-\\nthermal applications. It currently excludes temperature data from\\ngeothermal companies.\\n\\nWe are barely scratching the surface on the data and insights\\navailable — multiple data sto')\n",
      "(123, 3, 51, 'ries are waiting to be reimagined,\\nreconnected and retold in the context of the future of energy.\\n\\nAccelerating internal digitalization initiatives\\n\\nAll the elements of the new database are stored and structured\\nin a digital data warehouse. They will be o')\n",
      "(124, 3, 52, 'ptionally available\\nas an API link to be used for additional geological analysis,\\ndata analytics, or machine learning experimentations. Already\\nin structured format, they can be fed into additional natural lan-\\nguage processing or image segmentation proce')\n",
      "(125, 3, 53, 'ssing for in-house\\nexperimentation.\\n\\nOpportunity for the energy geoscientists and\\nengineers of the future\\n\\nWhile the energy industry has faced significant headwinds, it is\\nnow moving faster than ever towards new, cleaner energy pro-\\nduction. It is possibl')\n",
      "(126, 3, 54, 'e to see that multiple opportunities remain,\\nas already pointed out by Raistrick (2008), and remain relevant in\\n2021, for the geoscientists and engineers who are looking at the\\n\\nFigure 6 Experimental engineering data of CO,\\nbehaviours in enhanced oil reco')\n",
      "(127, 3, 55, 'very operations of\\nmature fields can be transferable to carbon storage\\ndesign and monitoring.\\n\\n7 | | | | | | | | | Figure 7 Combination of carbonate petrography data\\n\\nand information extracted from well reports.\\n\\n\\n\\nResults Density\\n\\now EE High\\n\\nFigure 8 Lo')\n",
      "(128, 3, 56, 'cations of relatively ‘high geothermal gradient areas’ based on existing\\ncorpus, data acquired by oil and gas companies. Data excludes information from\\ngeothermal companies.\\n\\nFigure 9 Compiled graphical temperature information filtered by country, basin o')\n",
      "(129, 3, 57, 'r\\nan arbitrary polygon location. Reference: Geoscience Australia, NOPIMS.\\n\\nfuture of energy. Strong, flexible technical skills will be needed\\nto explore for suitable carbon capture facilities, assess their\\nstorage, containment and injectivity capacities. ')\n",
      "(130, 3, 58, 'Meanwhile, the\\nnew energy industry will continue to gather, integrate and analyse\\nempirical data, whether it is on the reservoir, sub-surface or at\\nhydrocarbon or future hydrogen production facilities.\\n\\nWe have already seen a lot of data. It is up to us t')\n",
      "(131, 3, 59, 'o use the\\nright tools to read the earth better, and get a head start towards\\nnew energy.\\n\\nReferences\\n\\nGlobal CCS Institute (https://www.globalcesinstitute.com). CCS Facil-\\nities Database (https://co2re.co/) Geoscience Australia, NOPIMS\\n(http://www.ga.gov.')\n",
      "(132, 3, 60, 'aw/nopims).\\n\\nBolourinejad, P. and Herber, R. [2013]. Experimental and Modeling Study\\nof Salt Precipitation during Injection of CO2 Contaminated with H2S\\ninto Depleted Gas Fields in Northeast Netherlands - (SPE-164932),\\n75th EAGE Conference & Exhibition in')\n",
      "(133, 3, 61, 'corporating SPE EUROPEC\\n2013, London, UK.\\n\\nBattistelli, A., Giorgis, T. and Marzorati, D. [2005]. Modeling Halite Pre-\\ncipitation around CO2 Injection Wells in Depleted Gas Reservoirs,\\n67th EAGE Conference & Exhibition, Madrid, Spain.\\n\\nBroad, J., Ab Majid')\n",
      "(134, 3, 62, ', M.N., Ariffin, T., Hussain, A. and Basher, A.B.\\n[2007]. Deposition of “Asphaltenes” during CO2 Injection and\\nImplications for EOS Description and Reservoir Performance, IPT\\n2007: International Petroleum Technology Conference, Dubai, Unit-\\ned Arab Emirat')\n",
      "(135, 3, 63, 'es.\\n\\nDomitrovic, D., Tuschl, M. and Sunjerga, S. [2005]. CO2 Pilot Injection\\nat Ivanic Oil Field — Numerical Simulation, IOR 2005 - 13th Euro-\\npean Symposium on Improved Oil Recovery, Budapest, Hungary.\\n\\nGosselet, A.C. and Singh, §. [2006]. Elastic Full W')\n",
      "(136, 3, 64, 'aveform Inversion\\nfor CO2 Sequestration monitoring - ID Synthetic Data Investiga-\\ntions,68th EAGE Conference and Exhibition incorporating SPE\\nEUROPEC 2006\\n\\nGregersen, U.N., Johannessen, P., Kirby, G., Chadwick, A. and Holloway,\\nS. [2000]. Regional Study o')\n",
      "(137, 3, 65, 'f the Neogene Deposits in the Southem\\nViking Graben Area - a Site for Potential CO2 Storage,62nd EAGE\\nConference and Exhibition - Special Session on CO2, Glasgow, UK.\\n\\nHarsh, A.H. and Anne, V.A. [2014]. Carbon Dioxide Capture, Utilization\\nand Storage (CCU')\n",
      "(138, 3, 66, 'S),76th EAGE Conference and Exhibition 2014,\\nAmsterdam, Netherlands.\\n\\nLeeb, W. [1993]. Case study of CO2 disposal in aquifers - A solution\\nto reduce the greenhouse effect, 55th EAEG Meeting, Stavanger,\\nNorway.\\n\\nMehta, A., Hj-Kip, S. and Foo, J. [2008]. Ma')\n",
      "(139, 3, 67, 'naging Greenhouse Gas\\nEmissions in Upstream Operations in a Carbon-Constrained World,\\nIPTC 2008: International Petroleum Technology Conference, Kuala\\nLumpur, Malaysia\\n\\nRahim, M., Azran, A., Press, D., Lee, K-H., Phuat, C.T., Anis, L.,\\nDarman, N. and Othma')\n",
      "(140, 3, 68, 'n, M. [2012]. An Integrated Reservoir Sim-\\nulation-Geomechanical Study on Feasibility of CO2 Storage in M4\\nCarbonate Reservoir, Malaysia, IPTC 2012: Intemational Petroleum\\nTechnology Conference, Bangkok, Thailand.\\n\\nRaistrick, M. [2008]. Carbon capture and')\n",
      "(141, 3, 69, ' storage projects to challenge\\ngovernments, scientists, and engineers, First Break.\\n\\nWildenborg, A. G.H.and van der Meer L. [1996]. Potential\\nof CO2-disposal in deep reservoirs and aquifers of the Nether-\\nJands,58th EAGE Conference and Exhibition, Netherl')\n",
      "(142, 3, 70, 'ands.\\n\\nWildenborg, A., Floris, FD., van Wees, J. and Hendriks, C. [2000].\\nCosts of CO2 Sequestration by Underground Storage,62nd EAGE\\nConference and Exhibition - Special Session on CO2, Glasgow,\\nUK.\\n\\nSwatton, M.J.R., van Soest-Vercammen, E. and Klein Nage')\n",
      "(143, 3, 71, 'lvoort, R.\\n\\n, Breune:\\n\\n[2009]. Innovation and Integration in LNG Technology Solutions,\\nIPTC 2009: International Petroleum Technology Conference, Doha,\\nQatar.\\n\\n\\n')\n",
      "(144, 4, 1, \"\\nSCALING AND OPTIMIZING PERFORMANCE AND COST OF MACHINE\\n\\nLEARNING INGESTION ON UNSTRUCTURED DATA FOR\\nSUBSURFACE APPLICATIONS\\n\\nL.C.L. Panganiban’, F. Baillard', N.M. Hernandez!\\n\\n' Traya Energies\\n\\nSummary\\n\\nIn recent years, the energy industry has shifted th\")\n",
      "(145, 4, 2, 'eir attention into extracting additional values from\\ntheir in-house legacy datasets for shorter project turnaround and better decision making. Internal digital\\ntransformation initiatives and access to new technology such as cloud computing, machine learni')\n",
      "(146, 4, 3, 'ng and\\nmicroservices made it possible to shift towards a scalable ingestion platform.\\n\\nA modern scalable ingestion platform often includes 1) automated machine learning (ML) components\\narticulated around pipelines to parse and go through the data and extr')\n",
      "(147, 4, 4, 'act the needed information 2)\\nstorage component such Database, Datawarehouse and Datalake defining what data to be stored and\\nhow.\\n\\nIn this paper, we will provide a description of these different components, their modern implementation\\ninto a cloud enviro')\n",
      "(148, 4, 5, 'nment using microservices and some performance benchmark based on real world\\ndata examples.\\n\\n\\n\\nMADRID | SPAIN\\n\\nScaling and optimizing performance and cost of machine learning ingestion on unstructured\\ndata for subsurface applications\\n\\nIntroduction\\n\\nIn rec')\n",
      "(149, 4, 6, 'ent years, the energy industry has shifted their attention into extracting additional values from\\ntheir in-house legacy datasets for shorter project turnaround and better decision making. Internal digital\\ntransformation initiatives and access to new techn')\n",
      "(150, 4, 7, 'ology such as cloud computing, machine learning and\\nmicroservices made it possible to shift towards a scalable ingestion platform.\\n\\nA modern scalable ingestion platform often includes 1) automated machine learning (ML) components\\narticulated around pipeli')\n",
      "(151, 4, 8, 'nes to parse and go through the data and extract the needed information 2)\\nstorage component such Database, Datawarehouse and Datalake defining what data to be stored and\\nhow.\\n\\nIn this paper, we will provide a description of these different components, th')\n",
      "(152, 4, 9, 'eir modern implementation\\ninto a cloud environment using microservices and some performance benchmark based on real world\\ndata examples.\\n\\nScalable ingestion platform architecture\\n\\nThe vast majority of experimentation and testing of new ML application are ')\n",
      "(153, 4, 10, 'performed on notebooks\\non local machines leveraging on local hardware with the data and the code being stored locally-. Such\\na setup has the advantage of being lightweight allowing a fast turnaround between two ML iterations.\\nHowever the lack of traceabil')\n",
      "(154, 4, 11, 'ity, compatibility and hardware limitation makes it challenging to scale\\nsuch application, hence the requirement of a more scalable solution.\\n\\nIn comparison, a scalable ingestion platform is a type of system native able to handle current and future\\nworklo')\n",
      "(155, 4, 12, 'ads regardless of the amount of data ingested or users connecting to it, considering both scaling\\nin (shrinking resources) and scaling out (expanding resources). An example of such system can be seen\\non Figure 1. The architecture is made of of four compon')\n",
      "(156, 4, 13, 'ents namely pipeline, storage, compute and\\ninterfaces.\\n\\nINTERFACES,\\n\\nf Data Atelier\\n\\nImages\\n\\nCOMPUTE\\nProduction\\nRecords\\n\\nReparts,\\nPresentations\\n\\nAPI Interaction\\n\\nMaintenance\\nRecords\\n\\nFigure 1: Ingestion Platform Architecture\\n\\nPipeline or data pipeline is ')\n",
      "(157, 4, 14, 'the main driver in extracting and transforming data into a unified format.\\nThe typical ingestion workflow is based on an Extract-Transform-Load process with machine learning\\nworkflows able to accommodate the variety in sources and forms present in unstruc')\n",
      "(158, 4, 15, 'tured data\\n(Hernandez et al., 2019).\\n\\n\\n\\nMADRID | SPAIN\\n\\nThe storage component is where the data resides. Storage is often the least thought about in development\\nand architecture strategies, but it is one of the core contributors in terms of cost to the or')\n",
      "(159, 4, 16, 'ganization. The\\ncompute node component schedules and orchestrates the data pipelines, logic flows, and algorithms.\\nThe interface or the dashboard component provides the monitoring and observability capabilities. This\\npresents the events, statuses, logs, a')\n",
      "(160, 4, 17, 'nd other operational insights that can be used for decision making.\\nThese components have different ways to be scaled depending of 1) the environment of installation: on-\\npremise vs. cloud 2) the volume and type of data being processed 3) the early develo')\n",
      "(161, 4, 18, 'pment decision: all\\nout of the box cloud providers solution, opensource self maintained solution or hybrid.\\n\\nComponent’s optimization\\n\\nThe first metrics to consider for optimization is processing time and should be independent from the\\nvolume of data to b')\n",
      "(162, 4, 19, 'e processed by the pipeline. This optimization is achieved through parallelization,\\ndistributed computing and orchestration by scaling up or down the usage based on demand. Applications\\nand data pipelines are packaged into containers and then deployed int')\n",
      "(163, 4, 20, 'o a Kubernetes cluster in which it\\nhandles the scheduling, distribution, and allocation across different machines. Workflow managers (\\nWM) provide the platform to execute and orchestrate the jobs and tasks that are contained in a Pod/Pool\\n(Figure 2). Work')\n",
      "(164, 4, 21, 'flow managers also implement orchestration and scheduling though it handles the tasks\\nin the application layer where this determines if the data execution is successful\\n\\nFigure 2: Unstructured data pipeline with orchestration in place\\n\\nThe second metric t')\n",
      "(165, 4, 22, 'o consider is the extensibility metric. A single service or component can be used\\nbeyond what is originally intended. Thanks to the microservices, exposing your data via application\\nprogramming interfaces or APIs is a good practise (Figure 3). It provides')\n",
      "(166, 4, 23, ' a common language across\\nteams where implementation is unified across different data sources. An additional advantage of the use\\nof APIs is the additional level of abstraction for the storage of the data. Data are now accessible from\\nvarious mounting loc')\n",
      "(167, 4, 24, 'ations through a single call, allowing democratization and versioning of the data.\\n\\nAPI LINK\\n\\nAPI LINK\\n\\n\\n\\nMADRID | SPAIN\\n\\nFigure 3: Connecting applications using API links\\n\\nAs an example, a full-text search endpoint originally used to do searches, can als')\n",
      "(168, 4, 25, 'o be used to create\\naggregations models like heatmap and knowledge graphs (Baillard et Al., 2021) as seen on Figure 4.\\n\\n@ wees\\n\\nFy ‘eure 4 4; Heatmap (left) and Knowledge Graph (right)\\n\\nThe third metric to consider is the UI/UX responsivness and define th')\n",
      "(169, 4, 26, 'e optimal data representation for\\nthe user or the operator to QC the data and for the service to have still an acceptable response time. As\\nseen on Figure 4, the heat map and the knowledge graph are built on-top of 100,000 data points\\n(Mamador et al., 202')\n",
      "(170, 4, 27, '1). Interface and visualization scaling requires removing the dependency on the\\nvolume of data points. The amount of time visualizing 100 points should be the same as visualizing\\n100,000 points — in which development of aggregation and interpolation workf')\n",
      "(171, 4, 28, 'lows must be performed\\nin the backend and frontend to overcome this volume challenge.\\n\\nBenchmarks and testing\\n\\nTo see the performance of this architecture we can consider the following data. We have 3 buckets of\\ndata for this assessment. It is composed of')\n",
      "(172, 4, 29, ' geoscience documents that ranges from final well reports,\\ngeological report, regional studies, interpretations coming from various file formats, countries, and\\nlanguages. The data also includes images like thin sections, core, well logs, seismic. All the')\n",
      "(173, 4, 30, 'se data are\\naudited and stored into an object storage.\\n\\nThe following are the system that was used for this assessment:\\nBase case: 1-node with 4 cores and 16 GB of RAM from cloud provider without WM\\nized case: 5-nodes with 4 cores and 16 GB of RAM per nod')\n",
      "(174, 4, 31, 'e from cloud provider with WM\\n\\nBucket | Number | Duration Failure Duration | Failure | Language Region\\nof Pages (hours) Rate % (hours) Rate %\\nSingle node (Single Cluster (Cluster)\\nNode)\\n\\nee\\n~Woas/ af 38505 Tals | Osean\\n\\nne 531 Mixed South\\nAmerica\\n\\nTable 1')\n",
      "(175, 4, 32, ': Extraction Performance with 4-cores and 16 GB of RAM per node\\n\\nTable 1 shows the extraction performance. The extraction workload encompasses the data loading,\\nprocessing, and uploading. It was tested on a variety of datasets from different regions and l')\n",
      "(176, 4, 33, 'anguages.\\nFor a single node execution, the average number of pages per hour is around 244 pages and for a 5-node\\ncluster, the average number of pages per hour is 1000. Since workflow manager provide an auto-retry\\n\\n\\n\\nMADRID | SPAIN\\n\\nfunction, this reduces ')\n",
      "(177, 4, 34, 'the failure rate by a significant amount. This is due to tasks that are failing due to\\nnetwork or infrastructure issues to be retried or re-executed. The failure rate is now mostly on the data\\nsince we haveve removed the infrastructure constraint.\\n\\nAs one')\n",
      "(178, 4, 35, ' of the metrics that we have set earlier, we need to consider the cost and infrastructure usage.\\nUsing the same workloads, we can assess the cost and infrastructure optimization in Table 2.\\n\\na % Hardware % Hardware\\nPages usage Avg. usage - Avg.\\nSingle nod')\n",
      "(179, 4, 36, 'e Cluster\\n\\nTable 2: Extraction Infrastructure Utilization with 4-cores and 16GB of RAM\\n\\nTable 2 shows that we have a higher utilization in the cluster hence we are fully utilizing the server. In\\nthe case of single node, only 41% of the resources is utiliz')\n",
      "(180, 4, 37, 'ed vs 83% in the cluster approach. Both the\\nreduced failure rates and the hardware utilization illustratres the gain of efficency in deploying a scalable\\ningestion platform\\n\\nConclusions\\n\\nIn this paper, we have seen how to scale and optimize the ML ingesti')\n",
      "(181, 4, 38, 'on pipeline for subsurface\\napplications. We have shown that scaling and optimizing ML ingestion pipelines can lead to\\nimprovements in terms of time and cost. We have also demonstrated that the ingestion platform is\\nscalable to handle data from a variety o')\n",
      "(182, 4, 39, 'f regions and languages. Finally, we’ve seen the power of scaling\\nvisualizations and exposing the data via API links in which we can get more insight and enhance the\\nability of the team to extract knowledge.\\n\\nReferences\\n\\nBaillard F. and Hernandez N.: A Ca')\n",
      "(183, 4, 40, 'se Study of Understanding Bonaparte Basin using Unstructured\\nData Analysis with Machine Learning Techniques. 82nd EAGE Conference & Exhibition, 18-21\\nOctober 2021, Amsterdam.\\n\\nMamador C., Hernandez N., Baillard F.: Production-scale processing of EAGE’s Ea')\n",
      "(184, 4, 41, 'rthDoc data\\nto stimulate new insights in CO2 and new energy management. 82nd EAGE Conference &\\nExhibition worskhop on ML solutions at scale, 22 October 2021, Amsterdam.\\n\\nHernandez N., Lucajias P., Graciosa J.C., Mamador C., and Panganiban L. C. I., 2019: ')\n",
      "(185, 4, 42, 'Automated\\n\\ninformation retrieval from unstructured documents utilizing a sequence of smart machine learning\\n\\nmethods within a hybrid cloud container. EAGE Workshop on Big Data and Machine Learning for\\nE&P Efficiency 25 - 27 February.\\n\\n\\n')\n",
      "(186, 5, 1, \"\\nBalas Premie? Gensrience Event\\n\\nT. Looi', N.E. Arif', N.M. Hernandez?, F. Baillard?\\n' Traya Energies\\n\\nSummary\\n\\nIn the upstream oil and gas sector, the processes of data mining, which involves searching, extracting, and\\nvalidating information that sits wi\")\n",
      "(187, 5, 2, 'thin the technical documents, reports, presentations, and studies to understand\\nexploration history and geological parameters are often challenging and requires vast resources to be completed.\\nYet, many geological information that have already been mined,')\n",
      "(188, 5, 3, ' are stored in spreadsheets or niche databases,\\nthat limits their abilities to be recycled for multiple uses within the organization. Basin information such as\\nformation pressure, formation temperature, fracture pressure, drilling rate of penetration, tot')\n",
      "(189, 5, 4, 'al organic carbon\\n(TOC) and lithologies are some of the typical parameters that are crucial to understand the basin scale geology,\\nreservoir properties and identify opportunities within the area of interest and often needed to perform in depth\\nworkflows, ')\n",
      "(190, 5, 5, 'such as seismic reservoir characterization, basin modelling and geomechanical studies, which cover\\nmultiple cycles of exploration, development and site development of future carbon waste disposals. The research\\ndemonstrates the application of AI/ML techno')\n",
      "(191, 5, 6, 'logies coupled with interactive data visualization and API\\nconnectivity, that can significantly accelerate the extraction of knowledge that are sitting inside the reports and\\nensure sustainability in data mining activities.\\n\\nAPGCE 2022\\nKuala Lumpur, Malay')\n",
      "(192, 5, 7, 'sia | 28 — 29 November 2022\\n\\n\\n\\nIntroduction\\n\\nIn the upstream oil and gas sector, the processes of data mining, which involves searching, extracting,\\nand validating information that sits within the technical documents, reports, presentations, and studies\\nt')\n",
      "(193, 5, 8, 'o understand exploration history and geological parameters are often challenging and requires vast\\nresources to be completed. Yet, many geological information that have already been mined, are stored\\nin spreadsheets or niche databases, that limits their a')\n",
      "(194, 5, 9, 'bilities to be recycled for multiple uses within the\\norganization. Basin information such as formation pressure, formation temperature, fracture pressure,\\ndrilling rate of penetration, total organic carbon (TOC) and lithologies are some of the typical\\npar')\n",
      "(195, 5, 10, 'ameters that are crucial to understand the basin scale geology, reservoir properties and identify\\nopportunities within the area of interest and often needed to perform in depth workflows, such as\\nseismic reservoir characterization, basin modelling and geo')\n",
      "(196, 5, 11, 'mechanical studies, which cover multiple\\ncycles of exploration, development and site development of future carbon waste disposals.\\n\\nIn this paper, we are going to demonstrate on how we can improve on the traditional data mining\\nworkflows and enhance data ')\n",
      "(197, 5, 12, 'sustainability by focusing process improvement on three areas: a.)\\naccelerating the speed of geoscience parameter extraction by Artificial Intelligence/ Machine learning\\n(AI/ML) techniques, b.) increase data readability and integrity by effective visualiz')\n",
      "(198, 5, 13, 'ation of both\\nsource and output data, and c.) promote data reusability by enabling API access to extracted data.\\n\\nMethodology\\n\\nThe advancement in ML and AI with the support of advancement in cloud computing has made a\\nsignificant impact to the traditional')\n",
      "(199, 5, 14, ' data mining workflows. However, AI/ML workflows are typically\\nfocused only on the data extraction phase as a one-time effort, whereas an effective data mining\\nstrategy should also ensure data sustainability, which means the ability to visualize the data ')\n",
      "(200, 5, 15, 'to identify\\ntrends and patterns easily, and pass that high-integrity extracted information intact to multiple type of\\nusers within the organization.\\n\\nA sustainable data mining strategy is proposed to accelerate extraction with an automated pipeline\\nusing ')\n",
      "(201, 5, 16, 'Machine Learning techniques such as Natural Language Processing (NLP) or Deep\\nConvolutional Neural Network (DCNN) ingests all the unstructured data (Hernandez et al., 2019) in\\nsteps 1 to 3, followed by human-in-the loop quality control, visualization and ')\n",
      "(202, 5, 17, 'data trackability and\\nconnectivity in steps 4 and 5. (Figure 1):\\n\\nA vast amount of unstructured data such as final well report, technical reports, working files\\nthat varies from .pdf, .docx., .xlsx, .csv jpg, .png and .tif are used as the main source of\\ni')\n",
      "(203, 5, 18, 'nformation and feed into the production ready ML pipelines for audit, duplicates, and version\\ndetections.\\n\\nThe unstructured data ingestion starts with the digitalization of data using Optical Character\\nRecognition (OCR). Next, Deep Convolutional Neural Ne')\n",
      "(204, 5, 19, 'twork (DCNN) classifies the\\nextracted images into their respective geological categories such as map, seismic,\\nstratigraphic chart, SEM, thin section, core and well logs. Simultaneously, Natural Language\\nProcessing (NLP) pipeline performs automated extrac')\n",
      "(205, 5, 20, 'tion and tagging of metadata.\\n\\nFurther analysis and knowledge extraction are available once the unstructured data is\\ningested. Data Science analytical tool such as deep search with heat map density allows\\nadditional insights where the user can monitor the')\n",
      "(206, 5, 21, ' trend of a parameter regionally. In addition,\\ntables extracted from the reports are post-processed to retain the structure and extract the\\nvalues.\\n\\nMissing depth interpolation, units’ standardization and plotting of values on the gradient\\nisolines are pa')\n",
      "(207, 5, 22, 'rt of the data validation procedures during the Human in the Loop quality\\ncontrol.\\n\\nAPGCE 2022\\nKuala Lumpur, Malaysia | 28 — 29 November 2022\\n\\n\\n\\nThe last step is the discovery stage that allows shareable structured data among the team\\nmembers for further ')\n",
      "(208, 5, 23, 'interpretation and insights. The final shareable structured data allows\\ndata trackability within unstructured data, data export functionality, spatial filter to confine\\nthe search to the area of interest, depth filter and outliers’ identification. The typ')\n",
      "(209, 5, 24, 'ical outputs\\nof data mining exercise are the standard excel or csv as application agnostic format. In this\\nstage, we also enabled API access to allow for easier connectivity to other geoscience\\nplatforms or internally developed digital infrastructure syst')\n",
      "(210, 5, 25, 'ems.\\n\\nUnstructured Data ML/AI Pipeline and Human-in-the-Loop Quality Control\\n\\n1. Input 2. Unstructured Data Ingestion 3. Knowledge Extraction\\n\\nUnstructured Data Deep Convalutianal Neural Network (DCNN)\\n\\nvil\\n\\nExtracted\\nimages\\n\\nImages Images\\nclassification ')\n",
      "(211, 5, 26, 'aes\\n\\nNatural Language Pracessing (NLP) Convertable\\n\\n¥\\n\\n5. Discovery 4, Human-in-the-Loop Quality Control\\n\\nShareable Depth interpolation Units Standardization values Quatity Control\\nStructured Oata\\n\\n> Data trackatility\\nta1010 ca iterpolabon c1 ® Pressure k')\n",
      "(212, 5, 27, 'gem? to psi\\nGuoie ly | > Export data Functionality teterpolation of TOSS te tae Oe Potting extracted values\\n\\n> Spatial fuer and plat re-computation <—_— values using - radient ola\\nSrectonat sata : > Depth from TVD to TVDSS gradient wales\\n\\n> Depth Filter a')\n",
      "(213, 5, 28, 'nd plot re-computation\\n\\n> Depth from ft tom\\n> utters identification Depth from ftto\\n\\nFigure 1 Full implemented workflow of ingestion and analysis of unstructured data using ML/AI\\n\\nWe highlight the human-in-the-loop process during the data extraction proce')\n",
      "(214, 5, 29, 'ss in step 4 above, which\\nmeans there is a component of human interpretation during the geoscience parameter extraction\\nprocess. Since there could be conflicting understanding on what is considered right or relevant data at\\nthe time the extraction was don')\n",
      "(215, 5, 30, 'e, it is important to keep the sources of information intact, so these can\\nbe reviewed and updated when new additional data is available and the geological understanding of\\nthe basin of interest has evolved. The two additional steps introduced in the data')\n",
      "(216, 5, 31, ' mining process\\nincreases data integrity.\\n\\nResults\\n\\nIn this study, unstructured data from over 500 oil and gas wells are processed on a regional scale this\\nincludes a total of 300,000 pages and 140,000 images. Six geological parameters, formation pressure')\n",
      "(217, 5, 32, ',\\nformation temperature, fracture pressure, drilling rate of penetration, total organic carbon (TOC) and\\nlithologies were efficiently extracted, aggregated, validated, and finally visualized on scatter plots and\\npie charts. The output from the case study ')\n",
      "(218, 5, 33, 'shows notable knowledge analysis (Figure 2) that provides\\ninsights on the regional consistency and information distribution of the area of interest and can be\\nused as input into petroleum system modelling, reservoir characterization, idle wells review,\\nge')\n",
      "(219, 5, 34, 'omechanical studies or potential carbon storage studies.\\n\\nAPGCE 2022\\nKuala Lumpur, Malaysia | 28 — 29 November 2022\\n\\n\\n\\nFigure 2 Lithological pie chart distribution (left) and scatter plots of total organic carbon (TOC),\\nrate of penetration (ROP), formatio')\n",
      "(220, 5, 35, 'n temperature, fracture pressure and formation pressure (right)\\n\\nConclusions\\n\\nThe research demonstrates the application of AI/ML technologies coupled with interactive data\\nvisualization and API connectivity, that can significantly accelerate the extractio')\n",
      "(221, 5, 36, 'n of knowledge that\\nare sitting inside the reports and ensure sustainability in data mining activities. In the case study, we\\nhave presented a workflow on how six (6) geological parameters from over 500 wells were\\nsuccessfully extracted from unstructured ')\n",
      "(222, 5, 37, 'data using ML and AI pipelines that can be used by multi-\\nfaceted subsurface teams for more in-depth analysis within the area, resulting to the upcycling of\\ngeological data across the full life cycle of a basin.\\n\\nReferences\\n\\nHernandez, N. M., Lucafias, P.')\n",
      "(223, 5, 38, ' J., Mamador, C., & Panganiban, L. [2019]. Automated Information\\nRetrieval from Unstructured Documents Utilizing a Sequence of Smart Machine Learning Methods\\nwithin a Hybrid Cloud Container. EAGE Workshop on Big Data and Machine Learning for E&P\\nEfficienc')\n",
      "(224, 5, 39, 'y 25-27 February.\\n\\nMamador, C., Aranda, J. O., Arif, N. E., Hernandez, N. M., & Baillard, F. [2020]. A Geological\\nRegional Case Study for Pressure, Temperature, and Salinity for the GoM using Machine Learning\\nTechnology on Unstructured Data. AAPG Digital ')\n",
      "(225, 5, 40, 'Subsurface for Asia Pacific Conference. Kuala\\nLumpur, Malaysia.\\n\\nAPGCE 2022\\nKuala Lumpur, Malaysia | 28 — 29 November 2022\\n\\n\\n')\n",
      "(226, 6, 1, '\\nUtilizing Machine Learning to Gain Geological Insights through Unstructured Data for\\nSustainable Exploration Activities — Case Study Pre-Salt Brazil\\n\\nIntroduction\\n\\nUnderstanding the basin regional trends and identifying the anomalies is a crucial backgro')\n",
      "(227, 6, 2, 'und research\\nduring basin exploration activities. One way to gain a sound knowledge about the geology and the\\nexploration history is to analyse the vast amount of data accumulated over the years in an unstructured\\nmanner. A sustainable data driven strateg')\n",
      "(228, 6, 3, 'y leveraging on the latest advancement of Machine Learning\\n(ML) and Analytics is applied on vast amount of unstructured data. By highlighting the data driven\\nstrategy, the paper demonstrates such a strategy applied to pre-salt carbonates prospects located')\n",
      "(229, 6, 4, ' in the\\nCampos and Santos Basins, offshore Brazil. The interpretation framework consists of first step, to\\nidentify the regional first order trends and second step, to recognize the second order anomalies over\\nthe full area providing a holistic picture of')\n",
      "(230, 6, 5, ' the area of interest.\\n\\nMethodology\\n\\nThe unstructured data comprise of more than 48,000 documents, primarily in Portuguese language, for\\na total of 330,000 pages related to 50 years of exploration, covering the Campos and Santos Basins. The\\nmethodologies ')\n",
      "(231, 6, 6, 'are divided into two parts. In the part one methodology, the unstructured data is\\nprocessed using machine learning techniques such as Natural Language Processing (NLP) for name\\nentity recognition and language translation, and Deep Convolutional Neural Net')\n",
      "(232, 6, 7, 'work (DCNN) for auto-\\nimage recognition (Hernandez et al., 2019). In part two methodology, ML Analytics leverages the\\nvisualization for data relationships to give a holistic view of the whole corpus (Baillard et al., 2021).\\nThree steps study is used here,')\n",
      "(233, 6, 8, ' as explained below with illustration at Figure 1.\\n© Step 1: Deep Search through text is the ability to use keywords search within the whole corpus\\nand filter the wanted results. Filtered information is easily accessible for investigation. Deep\\nSearch is ')\n",
      "(234, 6, 9, 'also applied for images. DCNN image recognition and classification techniques classify\\nthe images into eight categories: thin section, core, well plot, seismic, stratigraphic structural\\nelements, map, table, and figure. A deep search allows user to search')\n",
      "(235, 6, 10, ' information tagged and\\nidentified in these images. This step is to identify the geological and exploration challenges\\nrelated to the area of interest.\\nStep 2: Heat Map highlights the “hot zones” on map based on the frequency of the keywords\\nfound. Drawin')\n",
      "(236, 6, 11, 'g a polygon on the map allows user to confine the search to focus only in the zone\\nof their interest. On the other hand, instant text search through the whole corpus of English and\\nPortuguese documents is possible with the automated translation. Users abl')\n",
      "(237, 6, 12, 'e to search through\\nPortuguese documents using English keywords.\\nStep 3: Contextual Knowledge Graph illustrates the connectivity of ‘related corpuses’ based on\\nwell name referencing. This is useful to obtain related information from different wells\\n(Herna')\n",
      "(238, 6, 13, 'ndez et al., 2019). Besides that, Intuition provides clustered images view, a great approach\\nto discover analogues for alike images such as thin section, core, SEM, and biomarker.\\n\\n« Deep Search within documents and * Information correlation using\\nexport ')\n",
      "(239, 6, 14, 'CSV Knowledge Graph\\n\\n—\\n/ Deep Search through images and\\nretrieve * Autometed translation of Portuguese * Analogs ieentfication using\\n: to English, to be able ta combine Image Clustering\\n\\nm\\n— information irom to languages\\n\\n2 py\\n\\nFigure I The data driven se')\n",
      "(240, 6, 15, 'arch strategy implementing the ML Analytics for visualization of data\\nrelationships for a holistic view of whole corpus\\n\\nGE Conference on D: 1 Innovat\\n\\nfor a Sustainable Future\\n\\n\\nCase study: Understanding the Pre-Salt Carbonate Regional Trends and Anomali')\n",
      "(241, 6, 16, 'es in Campos\\nand Santos Basins\\n\\nThe Campos and Santos Basins, located to the east offshore of Brazil, are some of the most prolific oil\\nand gas basins in the world with significant discoveries such as Tupi, Jupiter and Libra Fields. The\\ninvestigation of t')\n",
      "(242, 6, 17, 'he 50 years of pre-salt exploration history contained in the 48,000 documents processed\\nrevealed that most of the challenges during exploration are caused by 1. Fluid distribution 2. The\\nreservoir quality 3. CO2 and H2S presence 4. Overpressure patterns,\\n')\n",
      "(243, 6, 18, '\\n1. Campos and Santos Basins are showing a variable fluid distribution. The type and quality of\\nthe fluid trends are keys to define the best target for a sustainable development.\\n\\n2. The diagenesis affects the reservoir quality. A good visualization of th')\n",
      "(244, 6, 19, 'e lateral distribution of\\nsuch process allows a better estimation of the porosity and the volume in place.\\nThe regional gas issues, such as understanding the presence of CO2 and H2S is essential to\\ngauge the reservoir diagenesis properties as well as to p')\n",
      "(245, 6, 20, 'lan for production facilities or to avoid\\nregions of sour and hazardous gaseous.\\nThe irregularity in the thickness of the salt layer causes variability in the pressure regime with\\noverpressure over the zone of interest and affecting the drilling campaigns')\n",
      "(246, 6, 21, '.\\n\\nThese challenges are relevant to understand the geology and production issues encountered in distinct\\nparts of the basins to improve sustainable in the exploration risk and reducing CO? footprint.\\n\\nFor the pre-salt oil trendings, Campos pre-salt genera')\n",
      "(247, 6, 22, 'lly has lighter oil compared to Santos pre-salt. As\\nfor the anomalies, light oil or condensate discovery at Pau De Acucar, Seat and Gavea Fields in Campos\\npre-salt, while heavy mostly found in the post-salt in the Southern Campos. In Santos, heavy oil rep')\n",
      "(248, 6, 23, 'orted\\nin Jupiter Field. Note that heavy oil also discovered in Atlanta and Oliva Fields at post-salt. Illustration\\nin Figure 2.\\n\\n«Guarulhos\\n\\nMediuni dil\\nAP average\\n0\\n\\nFigure 2 Heat map highlights the wells with “heavy oil” information. The oil API delinea')\n",
      "(249, 6, 24, 'tion is based\\non Deep Search extraction from test reports for Santos (left map) and Campos (right map). Knowledge\\nGraph was analyzed to find a group of fields that share the light oil information — Gavea, Seat and Pao\\nde Acucar Fields.\\n\\nNext, we study the')\n",
      "(250, 6, 25, ' facies distribution at pre-salt carbonate. A collection of core and thin section images\\nare retrieved from the Deep Search through images. In general, it is observed that the reservoir\\nformation is in the shrub facies, microbiolites and coquina. For the ')\n",
      "(251, 6, 26, 'trendingss, the area with COQo,\\nleaching activities enhance the porosity, example in the Libra, Buzios Fields, going south to Tupi and\\nCarcara Fields in Santos. Fields proximal to the shore has poorer reservoir quality. One of the anomalies\\nobserved is th')\n",
      "(252, 6, 27, 'e hydrothermal activity can destroy the enhanced porosity by the leaching. The\\nhydrothermal activity is anticipated in Field Albacora, Carcara, based on the observation on the core.\\nIllustration in Figure 3.\\n\\nGE Conference on D: for a Sustainable Future\\n\\n')\n",
      "(253, 6, 28, '\\nMERO/LIBRA.\\n\\nMicrobial carbonates in\\nsag sequence and coquina\\nrift sequence\\n\\nITARPU\\nShrub facies’ss.\\n-cuaruitos\\nMEXILHAO-\\nPoor\\nreservoir\\nquality\\n\\nBUZIGS, ATAPU,SEPIA\\nbial carbonates in\\n\\nsag sequence and\\n\\ncoquina rift sequence\\n\\n) frame\\nFigure 3 Pre-salt c')\n",
      "(254, 6, 29, 'arbonate facies distribution based on core and thin sections collection from Deep\\nSearch through images. Analysing the diagenesis trend has an impact on reservoir quality\\ninterpretation. (core and thin section images are taken from BDEP-ANP reports and Co')\n",
      "(255, 6, 30, 're Lab study)\\n\\nThe following study is to investigate the regional gas issues. The trend is showing that Santos is\\nsuffering higher CO2 contamination compared to Campos, especially in the center deep-water Santos\\narea. Jupiter Field suffers from very high ')\n",
      "(256, 6, 31, 'concentration of CO2 gas, 79% recorded. Center deeper-water\\nSantos is suffering from CO2 contamination potentially near to the mantel magmatic activities\\nintercepted by deep-seated fault (Luca et al., 2017). Hazardous H2S gas presence in high amount\\n(exce')\n",
      "(257, 6, 32, 'eding OSHA safe limit 50 ppm) in the Buzios, Iara Fields of Santos and Xerelete, Albacora Fields\\nof Campos. Illustration in Figure 4.\\n\\neGuaruihos\\nSéo Paulo”\\n\\nSantg\\n\\n, ‘BACALFAU\\nBEM TE VI\\nABERE\\nOESTE\\nCO, 15%\\nFigure 4 Heat Map of “high CO2” information with')\n",
      "(258, 6, 33, ' delineation of CO2 concentration based on Deep\\n\\nSearch extraction from test reports in Santos (left map) and Campos (right map)\\n\\nLastly, is the study of formation pressure pattern. The formation data points are quickly extracted from\\nunstructured data ov')\n",
      "(259, 6, 34, 'er 80 wells using Deep Search. The points are then plotted on gradient psi/ft ranging\\nfrom 0.35 to 0.7 psi/ft. Based on the pressure gradient validation, wells in Carcara, Sagitario and\\nCorcovado Fields have exceptionally high formation pressure. An inter')\n",
      "(260, 6, 35, 'pretation of fullstack PSDM\\ncross-section shows thick salt area in Carcara and Sagitario, possible with faulting causes saline water\\nintrusion which contribute to high pressure zone. Irregularity in thickness of salt layer causes variability\\nin pressure r')\n",
      "(261, 6, 36, 'egime, such as overpressure area to take note as this will have an impact on seismic\\ninterpretation and drilling campaign. Illustration in Figure 5.\\n\\nEAGE Conference on Digital Innovation for a Sustainable Future\\n\\n\\nFormation Pressure, psi\\n10000 15000\\n\\nFig')\n",
      "(262, 6, 37, 'ure 5 Formation pressure extraction for over 80 wells (all data points taken from BDEP-ANP\\nreports). Exceptionally high pressure recorded in Guaratiba Group in Carcara, Sagitario and\\nCorcovado, possible due to high salt thickness and faulting causes salin')\n",
      "(263, 6, 38, 'e water. Fullstack PSDM cross\\nsection shows thick salt in area of Carcara and Sagitario (courtesy of Kattah et al., 2014).\\n\\nConclusion\\n\\nThe research shows the effectiveness of using ML/AI technologies and Analytics to mine through the\\nvast amount of unstr')\n",
      "(264, 6, 39, 'uctured data and gain insights related to the regional trends and anomalies of\\nimportant geological, reservoir and production parameters to minimize the risk of exploration and\\nreduce carbon footprint. New tools in ML/AI and Analytics provides a new explo')\n",
      "(265, 6, 40, 'ration frontier for\\nsubsurface experts allowing them to interrogate and visualize a vast amount of data previously scattered\\nin different format and location holistically.\\n\\nAcknowledgement\\n\\nWe would like to thank PETRONAS Petroleo Brasil LTDA for the coll')\n",
      "(266, 6, 41, 'aboration with Iraya Energies\\nto makes this paper possible. Our gratitude appreciation also goes to Banco de Dadoes Exploracao e\\nProducao (BDEP) of National Agency of Petroleum (ANP) for making the data source available for\\nthis study.\\n\\nReferences\\n\\nBailla')\n",
      "(267, 6, 42, 'rd, F., & Hernandez, N. (2021). A Case Study of Understand Bonarparte Basin using Unstructured\\nData Analysis with Machine Learning Techniques. EAGE Annual.\\n\\nHernandez, M., & Baillard, F. (2019). An effective G&G exploration strategy inspired by a wolfpack')\n",
      "(268, 6, 43, '.\\nForce workshop.\\n\\nHernandez, N., Lucafias, P., Graciosa, J, Mamador, C., & Panganiban, I. (2019). Automated\\nInformation Retrieval from Unstructured Documents Utilizing a Sequence of Smart Machine Learning.\\nEAGE Workshop on Big Data and Machine Learning f')\n",
      "(269, 6, 44, 'or E&P Efficiency 25 - 27 February.\\n\\nHydrogen Sulfide. (2022). Retrieved from Occupational Safety and Health Administration:\\nhttps://www.osha.gov/hydrogen-sulfide/hazards\\n\\nCore Lab [2022]. Pre-Salt Reservoirs of the Santos and Campos Basins, Brazil\\n\\nLuca,')\n",
      "(270, 6, 45, ' Pedro & Matias, Hugo & Carballo, Jose & Sineva, Diana & Pimentel, Gustavo & Tritlla, Jordi &\\nCerda, Mateu & Loma, Rubén & Jiménez, Ricardo & Pontet, Matthieu & Martinez, Pedro & Vega,\\nVictor. [2017]. Breaking Barriers and Paradigms in Presalt\\n\\nKattah, S.')\n",
      "(271, 6, 46, ', Balabekov, Y., [2014]. New opportunities evident in the Santos Basin. Hartenergy. 2\\nSeptember 2022. https://www.hartenergy.com/ep/exclusives/new-opportunities-evident-santos-basin-\\n174870\\n\\nEAGE Conference on Digital Innovation for a Sustainable Future\\n\\n')\n",
      "(272, 7, 1, '\\nVIENNA | AUSTRIA\\n\\nCO, emissions the elephant in the room: a pathway of reduction using digitalization and\\nunstructured data\\n\\nIntroduction\\n\\nIn this paper, we are exploring the challenges associated to climate change in the energy industry with\\nthe paradig')\n",
      "(273, 7, 2, 'm of extracting oil and gas in a low CO, environment to limit the effect of climate change\\nand provide the world with affordable source of energy for mobility and heat generation.\\n\\nWe will be discussing how carbon accounting allows to track direct and ind')\n",
      "(274, 7, 3, 'irect source of emissions,\\nits origins and the challenges associated to them.\\n\\nFinally, we will investigate how modern technology such as data mining can help mitigate direct and\\nindirect emissions by increasing operations efficiency, identifying operatio')\n",
      "(275, 7, 4, 'n flaws, and implementing\\nscalable Carbon Capture and Storage (CCS) implementation.\\n\\nCO) emission and world energy consumption\\n\\nRecently, the Intergovernmental Panel on Climate Change (IPCC) issued the sixth Assessment Report\\n(AR6) related to Climate Chan')\n",
      "(276, 7, 5, 'ge 2022: Impacts, Adaptation and Vulnerability which highlights\\nthe urgency of limiting the increase of temperature to 1.5°C to reduce the impact of climate change:\\n“Global warming, reaching 1.5°C in the near-term, would cause unavoidable increases in mul')\n",
      "(277, 7, 6, 'tiple\\nclimate hazards and present multiple risks to ecosystems and humans (very high confidence). [...] Near-\\nterm actions that limit global warming to close to 1.5°C would substantially reduce projected losses\\nand damages related to climate change in hum')\n",
      "(278, 7, 7, 'an systems and ecosystems, compared to higher warming\\nlevels, but cannot eliminate them all (very high confidence).” (IPCC, 2022).\\n\\nIn addition, the AR6 report linked to Climate Change 2022: Mitigation of Climate Change suggests\\nthat “All global modelled ')\n",
      "(279, 7, 8, 'pathways that limit warming to 1.5°C [...] involve rapid and deep and in\\nmost cases immediate GHG emission reductions in all sectors. Modelled mitigation strategies to\\nachieve these reductions include transitioning from fossil fuels without CCS to very lo')\n",
      "(280, 7, 9, 'w- or zero-carbon\\nenergy sources, such as renewables or fossil fuels with CCS, demand side measures and improving\\nefficiency, reducing non-CQ emissions” (IPCC, 2022).\\n\\nGlobal primary energy consumption by source\\nPrimary energy is calculated based on the ‘')\n",
      "(281, 7, 10, 'substitution method’ which takes account of the inefficiencies in fossil\\n\\nfuel production by converting non-fossil energy into the energy inputs required if they had the same conversion\\n\\nlosses as fossil fuels.\\n\\nOther\\n\\nenewables\\n160,000 TWh fodern biofuel')\n",
      "(282, 7, 11, 's\\n\\n140,000 TWh 7 Hydropower\\n— Nuclear\\n7 Gas\\n120,000 TWh\\n\\n100,000 TWh\\n80,000 TWh\\n60,000 TWh\\n40,000 TWh\\n\\n20,000 TWh\\n\\n__ Traditional\\n\\nOTWh biomass\\n1800 1850 1900 2019\\n\\n‘Source: Vaclav Smil (2017) & BP Statistical Review of World Energy OurWorldinData.org/ene')\n",
      "(283, 7, 12, 'rgy «CC BY\\n\\n\\n\\nVIENNA | AUSTRIA\\n\\nFigure 1: Global primary energy consumption by source. Fossil energies account for 80% respectively\\nCoal (25%), Oil (32%) and Gas (23%) (Source: Our World in Data - Energy)\\n\\nWhile limiting the reduction of CO2 to reduce the')\n",
      "(284, 7, 13, ' impact of climate change, the world is still highly\\ndependent on fossil fuels, with fossil energies accounting in 2019 for more than 80% in total and Oil/Gas\\nfor 60% alone (Figure 1). Combined with the need of powering the world and the challenges of cli')\n",
      "(285, 7, 14, 'mate\\nchange, the energy sector has a central play to significantly monitor and reduce its CO2 footprint.\\n\\nCarbon accounting\\n\\nCarbon accounting is the process which allows organization to quantify and monitor Greenhouse Gas\\n(GHG) emissions, By construction')\n",
      "(286, 7, 15, ', carbon accounting counts the direct and indirect emissions linked\\nto the activity of the organization through the full value chain.\\n\\nDirect emission are the emissions directly related to the own activity of the company such as oil/gas\\nextraction and pro')\n",
      "(287, 7, 16, 'duction and are often referred to scope 1 emissions. Indirect emission are the\\nemissions emitted considering the full value chain. In the case of the energy industry, this would\\nconsider all the necessary services contracted to perform the extraction of o')\n",
      "(288, 7, 17, 'il and gas from the\\nsubsurface and all the emissions related to the usage of the oil and gas as a molecule for the human\\nusage in mobility, industry usage and heat generation. These emissions are falling into the scope 2\\nassociated to the supply of energy')\n",
      "(289, 7, 18, ' (input) and the scope 3 linked to the oil and gas products sold (output).\\n\\nFigure 2 illustrates the breakdowns and evolution of four (4) representative Oil jor operators’\\nemissions until 2018. In average, 10% of the emissions are associated to direct emi')\n",
      "(290, 7, 19, 'ssion and 90% of\\nthem are linked to indirect emissions connected to hydrocarbon products sold. Considering oil and gas\\ncommitment in reducing carbon emission, this means that both direct and indirect emissions would need\\nto be tackled simultaneously.\\n\\nOil')\n",
      "(291, 7, 20, \" Majors' Carbon emissions\\n\\nWats ee ce peeaes se rsa betas\\nOperator A Operator B\\nScope |\\n\\nSeopel\\n\\nScope\\n\\nOperator C Operator D\\n\\nFigure 2: Evolution of direct and indirect emissions for four (4) Oil Majors. scope 1; Own operations\\n(direct emissions), scope \")\n",
      "(292, 7, 21, '2: Power supply (indirect emissions), scope 3: Indirect from oil and gas\\nproducts sold (indirect emissions) (Source: Modified from Reuters 2019)\\n\\nData mining technology\\n\\n\\n\\nVIENNA | AUSTRIA\\n\\nDecades of oil and gas operations associated to the exploration, ')\n",
      "(293, 7, 22, 'development and production of oil\\nfields have generated vast amount of data which provides a deep insight of constant optimization of\\ncosts and resources. The data are interpreted and compiled into unstructured data such as reports,\\npresentations and stud')\n",
      "(294, 7, 23, 'ies providing a carbon copy of the history of the operations. The unstructured\\ndata provides an immense potential of CO2 emissions reduction for both direct and indirect emissions.\\nNew technology such as Data Mining and Machine Learning technology helps t')\n",
      "(295, 7, 24, 'o process and retrieve\\ninformation at scale contained in the unstructured data in a pipeline called ingestion of unstructured\\ndata (Hernandez, 2019). The process involves automated pipeline of text identification, image\\nclassification, Name Entity Recogni')\n",
      "(296, 7, 25, 'tion (NER), Knowledge Graph and Heat Map analysis.\\n\\nFor the direct emissions, the ingestion of unstructured data gives the G&G experts a discovery\\nexperience allowing him to interrogate the full corpus of data instantly. Such ingestion platform reduces\\nth')\n",
      "(297, 7, 26, 'e time of information retrieval and provides a holistic view of the lateral extent for the parameters of\\ninterest. An example of such application is seen in Figure 3, where reservoir intervals with high CO2\\ncontent is highlighted for more than 500 wells a')\n",
      "(298, 7, 27, 'ssociated to the ingestion of over 45,000 unstructured\\ndocuments.\\n\\nResults Density\\n\\nLow mug High\\n— Main deep faut mes fgnoous rocks (Ranta, 2020)\\n> Taatane Gough fa (Matos, 2027) Crustal Domains (Zaién etal, 2018) MD Extrusions (Costa Comela, 2018}\\n Post-')\n",
      "(299, 7, 28, 'sat wel Ml Hyper Extended Crust (Wb btusions (Costa Comeia, 2019)\\n© Pre-tak wal 1 Btrached Tinned IB Iproous cock (Vier do Luc of a, 2017]\\nDepocenter 7 Resistate\\n\\nFigure 3: Regional maps covering 500 wells showing the presence of high CO: content in the r')\n",
      "(300, 7, 29, 'eservoir\\ninterval (Source: https://doi.org/10.1016/) jsames.2022, 103760)\\n\\nReducing the time of information retrieval provides a unique opportunity of fast-tracking studies, hence\\nreduce the CO2 emissions. An extended scope of the data ingestion workflow ')\n",
      "(301, 7, 30, 'is the identifying and\\ntracking the origin of operations flaws and best practices for potential improvement and reduction of\\nCO» emissions (Hernandez, 2021).\\n\\nThe reduction of indirect emissions involves large scale adoption and deployment of CCS capabili')\n",
      "(302, 7, 31, 'ties\\nworldwide. Such a pathway is possible by leveraging on current existing oil and gas assets which are\\nthe mature depleting fields. Extensive work and studies over decades generated a vast amount of data\\nsubsurface studies and production that are mined')\n",
      "(303, 7, 32, ' to rank the best opportunities for CCS based on the\\nfield maturation, intervention history and geological settings. Once the target reservoir identified CO2\\ninjection can then be monitored wit novel environmentally friendly methods such as using\\nnondisru')\n",
      "(304, 7, 33, 'ptive 4D seismic (Figure 4) to prove the potential. Such Data to Sink funnel provides the\\ntechnical scalability and the cost effectiveness to assess CCS potential in a large area of interest.\\n\\n\\n\\nVIENNA | AUSTRIA\\n\\nData mining of historical\\nunstructured dat')\n",
      "(305, 7, 34, 'a from 100% data sweep of\\ndepleting mature oil and mature fields\\n\\ngas fields -\\na\\n\\nData consolidation\\nof existing G&G\\nstructured data\\n\\n20% opportunities\\nidentified\\n\\nCO2 injection\\nand\\nmonitoring\\n\\nCCS operation\\n\\nFigure 4: Data to Sink funnel workflow powered')\n",
      "(306, 7, 35, ' by data mining, machine learning and lean 4D seismic\\nmonitoring.\\n\\nConclusions\\n\\nThe reduction of carbon emission at scale in the energy industry remains a challenge. In this paper we\\nhave demonstrated how digitalization applied on unstructured data can he')\n",
      "(307, 7, 36, 'lp reduce both direct and\\nindirect emissions.\\n\\nAcknowledgements\\n\\nWe would like to thank Iraya Energies for allowing us to publish this paper.\\n\\nReferences\\n\\nIPCC, 2022: Summary for Policymakers. In: Climate Change 2022: Mitigation of Climate Change.\\nContrib')\n",
      "(308, 7, 37, 'ution of Working Group III to the Sixth Assessment Report of the Intergovernmental Panel on\\nClimate Change [P.R. Shukla, J. Skea, R. Slade, A. Al Khourdajie, R. van Diemen, D. McCollum, M.\\nPathak, S. Some, P. Vyas, R. Fradera, M. Belkacemi, A. Hasija, G. ')\n",
      "(309, 7, 38, 'Lisboa, S. Luz, J. Malley, (eds.)].\\nCambridge University Press, Cambridge, UK and New York, NY, USA. doi:\\n10.1017/9781009157926.001\\n\\nIPCC, 2022: Summary for Policymakers [H.-O. Pértner, D.C. Roberts, E.S. Poloczanska, K.\\nMintenbeck, M. Tignor, A. Alegria,')\n",
      "(310, 7, 39, ' M. Craig, 8. Langsdorf, S. Léschke, V. Méller, A. Okem (eds.)].\\nIn: Climate Change 2022: Impacts, Adaptation, and Vulnerability. Contribution of Working Group II\\nto the Sixth Assessment Report of the Intergovernmental Panel on Climate Change [H.-O. Pértn')\n",
      "(311, 7, 40, 'er, D.C.\\nRoberts, M. Tignor, E.S. Poloczanska, K. Mintenbeck, A. Alegria, M. Craig, S. Langsdorf, S. Léschke,\\nV. Miller, A. Okem, B. Rama (eds.)]. Cambridge University Press. In Press.\\n\\nHernandez, N. M., Lucaiias, P. J., Mamador, C., & Panganiban, L. [201')\n",
      "(312, 7, 41, '9]. Automated Information\\nRetrieval from Unstructured Documents Utilizing a Sequence of Smart Machine Learning Methods\\nwithin a Hybrid Cloud Container. EAGE Workshop on Big Data and Machine Learning for E&P\\nEfficiency 25-27 February\\n\\nHernandez, N.M. and M')\n",
      "(313, 7, 42, 'aver, K.M. [2021]. ED2K Initiative launched to support UN 2050 Net Zero\\ngoals by reading the earth better, First Break, June 2021\\n\\n\\n')\n",
      "(314, 8, 1, '\\nVIENNA AUSTRIA\\n\\nDouble funnel approach for screening of potential CO2 storage opportunities in the Norwegian\\nContinental Shelf\\n\\nIntroduction\\n\\nCarbon capture and storage (CCS) is a key waste management strategy for reducing carbon dioxide (CO2)\\nemissions ')\n",
      "(315, 8, 2, 'and mitigating climate change. The Norwegian continental shelf has significant capacity for CCS,\\nas it has several depleted oil and gas fields that can be used for storage of CO2. The field of CCS has seen\\nsignificant growth in recent years, as the need t')\n",
      "(316, 8, 3, 'o reduce carbon CO2 emissions becomes increasingly\\nurgent. However, despite the increasing number of studies on CCS, there remains a lack of consensus on\\nthe most effective methods for accelerating and scaling up CCS projects.\\n\\nIn this study, the integrat')\n",
      "(317, 8, 4, 'ion of Machine Learning (ML) whereby the reports from the Norwegian Petroleum\\nDirectorate (NPD) are ingested into one platform creates potential cost-effective solution by screening\\nprevious knowledge gathered for depleting oil and gas fields and signific')\n",
      "(318, 8, 5, 'antly reduces the time of the\\nscreening, the evaluation and the ranking of CCS prospects. We investigate the feasibility of such a study\\non the Norwegian Continental Shelf by analyzing the geology and capacity of existing oil and gas fields.\\nThe analysis ')\n",
      "(319, 8, 6, 'is conducted on historical data from final well reports for 361 wells (NPD, 2023) which are\\nptiorly ingested using Machine Learning (ML) and Artificial Intelligence (AI) by indexing and tagging\\nmetadata from the documents, extracting, and classifying imag')\n",
      "(320, 8, 7, 'es and generating geological interpretable\\noutput such as heat maps or knowledge graphs. Our research includes a detailed characterization and\\ninterpretation of the subsurface geology, including the identification of potential storage formations, the\\nanal')\n",
      "(321, 8, 8, 'ysis of reservoir properties such as porosity and permeability and the evaluation of seal characteristics.\\nWe also conducted a comprehensive assessment of the capacity for CO2 storage, considering factors such\\nas injection rate and pressure buildup.\\n\\nMeth')\n",
      "(322, 8, 9, 'odology\\n\\nDepleting oil and gas fields in the Norwegian Continental Shelf with their massive amount of data being\\ncollected over decades of development and production are often considered good candidates for CCS\\nopportunities. Unfortunately the vast amount')\n",
      "(323, 8, 10, ' of knowledge come with the challenges associated to the lack\\nof normalization of the data and the diversity of the different format and template utilized making it difficult\\nto utilize the full potential of such data without allocating significant manual')\n",
      "(324, 8, 11, ' work.\\n\\nIn our case study, Machine learning pipelines are used to classify, cluster, and extract insights from such\\nan unstructured data. Priorly trained and G&G domain specific natural language processing (NLP)\\ntransformers are executed on the text to pe')\n",
      "(325, 8, 12, 'rform indexing, metadata tagging and topic modeling, when\\nDeep Convolutional Neural Network (DCNN) extract, classify and segment extracted images. Such an\\napproach has the advantage of significantly lessening manual human intervention allowing G&G experts')\n",
      "(326, 8, 13, '\\nto focus on the interpretation of the data itself using a front end deployed interface (Baillard et al., 2019).\\nAs seen in Figure 1 the data visualization and interpretation are performed through a suite of six analytical\\ntools: (1) summarizes the import')\n",
      "(327, 8, 14, 'ant attributes of the well automatically extracted from the document, (2)\\naids in portraying the well data on a map and visualizes the lateral distribution of search queries, (3)\\nprovides an in-depth search within all the corpus for the text and any tagge')\n",
      "(328, 8, 15, 'd associated metadata using\\nNLP, (4) correlates wells between each other’s to understand and interpret the semantic structure of the\\nbasin(5) searches the images extracted from DCNN into its respected geological categories, (6) quantifies\\nthe frequency of')\n",
      "(329, 8, 16, ' different lithologies present from the different wells.\\n\\n\\n\\nVIENNA AUSTRIA\\n\\nImage search module 4\\nDeep-search module Correlate findings with oe Lithotogy tab\\n6 Oe, nevevnape tase i\\nse\\nz\\n\\nFigure 1 Analytical tools used for the case study research strategy ')\n",
      "(330, 8, 17, 'for CO2 storage screening\\n\\nSuch a set of tools provides powerful means for understanding and interpreting large and complex sets of\\ndata. It can help to identify patterns, trends, and relationships that might not be immediately apparent from\\nraw data due ')\n",
      "(331, 8, 18, 'to the segregation of information in separate files for each well. By narrowing down the scope\\nof focus on selected wells, the exclusion of non-relevant well and time frame reduction of the process can\\nbe accomplished.\\n\\nIn this paper, we propose a new CCS')\n",
      "(332, 8, 19, ' screening workflow called Double Funnel Approach (DFA), seen on\\nFigure 2 which consists of a “data sweep” and a “data target”, The “data sweep” aims to reduce all findings\\nfrom all ingested data to key learnings and key wells over the area of interest, a')\n",
      "(333, 8, 20, 'llowing to review and rank\\nthe most suitable field candidates for potential CCS opportunities. The “data target” follows the “data\\nsweep” and focuses only on the field selected candidates and aims to refine and enhance the existing\\nunstructured data with ')\n",
      "(334, 8, 21, 'seismic, logs, interpretation and geomodel data, During this exercise, redundant and\\nirrelevant data are removed through efficient automated version indexing and cross-correlation with the\\nunstructured data. Finally, the data is now ready for screening fo')\n",
      "(335, 8, 22, 'r CO2 injection capacity and monitoring\\nanalysis.\\nUnstructured Data Interpretation\\n\\nKey learnings\\nKey wells.\\n\\n“Data Sweep” Key risks Target field for CO2\\nKey drivers\\n\\nBasin Mapping | area storage\\n\\n“Data Target”\\n\\nPlay Evaluation\\n\\nReservoir Properties |\\n\\nMo')\n",
      "(336, 8, 23, 'nitor Injection in\\n\\nSeal Properties Depleting fields review\\n\\nand ranking\\n\\nIdentify learning over Propagate learning\\nsedimentary basins over key depleting\\nfields\\n\\nFigure 2 Proposed Double Funnel Approach for CCS Screening Studies\\nCCS “data sweep” use case ')\n",
      "(337, 8, 24, 'offshore Norway\\n\\nThe ingestion of data for the case study comprises of 490,000 pages and 440,000 images, covering a total\\nof 361 wells within 5 basins in Norway consolidating 50 years of exploration, development, and production.\\nAll these data has been re')\n",
      "(338, 8, 25, 'trieved from the Norwegian Petroleum Directorate (NPD). The “data sweep” of\\nthe data was completed in 21 days which evaluated various hypothesis and converge on the key learnings,\\nkey wells, key risks, and key drivers.\\n\\n\\n\\nVIENNA AUSTRIA\\n\\nFigure 3 shows th')\n",
      "(339, 8, 26, 'e generated knowledge graph associated to the zone of interest. Knowledge graph is a\\nstructured way to represent and organize knowledge in a way that is easily queried and traversed across all\\nthe corpus of documents ingested. This makes it useful for a h')\n",
      "(340, 8, 27, 'olistic interpretation of the wells present in\\nthe area of interest, interpreting and ranking them based on their location and importance in the graph\\nrespectively as “alpha” or geological analogue, “scouts”, “pack or “lone-spirit” wells. As observed, the')\n",
      "(341, 8, 28, '\\nstructure of the knowledge graph does indicate a non-homogeneous distribution with 7 different clusters\\nbeing identified. Each cluster is centered around key wells acting as key geological analogues (“alpha”\\nwell) for the surrounded wells located within ')\n",
      "(342, 8, 29, 'the cluster. “Scouts” wells define the unique critical paths\\nbetween adjacent clusters, allowing geologists to deeper understand the geology and exploration history of\\nthe area of interest (Hernandez et al., 2019).\\n\\nBEM ue\\n\\nFigure 3 Knowledge graph with c')\n",
      "(343, 8, 30, 'lusters of wells from the Norwegian dataset\\n\\nBased on the recognized clusters, wells are further investigated by cross-correlating their respective post\\ndrill conclusion, formation penetration and keywords search associated to reservoir properties, seal\\nc')\n",
      "(344, 8, 31, 'haracteristics or a specific search allowing a deeper dive in the corpus. An example of such full corpus\\nsearch for ‘porosity’ detected from the well final well reports, within text, images and tables identifying the\\nrelevant values of the porosity and th')\n",
      "(345, 8, 32, 'eir associated formations. Auto-classified images can enhance the\\nanalysis by providing detailed information about the textures, layers, and structural characteristics of the\\nrocks through different scales, from field scale with seismic stacks or isochron')\n",
      "(346, 8, 33, 'e map, to microscopic scale\\nwith thin section images. Additionally, image analysis techniques such as pattern recognition can be used\\nto automatically extract features and classify rock formations.\\n\\nIn this example, the “data sweep” suggests suitable area')\n",
      "(347, 8, 34, 's for CCS in the Norwegian Sea corresponding to\\nHeidrun and Marulk fields. The study highlights the potential of Ile and Garn formation within the Fangst\\nGroup under the Heidrun Field. These intervals show good average depths for COQ2 storage for supercri')\n",
      "(348, 8, 35, 'tical\\nstorage, and are characterized by good porosity and permeability, with a significant net sand thickness. Seal\\nintegrity has been confirmed and validated. The interval above Ile and Garn are currently producing, and\\ntherefore has seismic and velocity')\n",
      "(349, 8, 36, ' data which allows precise CO2 injection monitoring through\\nmicroseismic. The upper Ile and Garn aquifers have good reservoirs in the southern part of the Froan Basin\\nwhich may indicate additional potential CCS storage in this area.\\n\\n\\n\\nVIENNA AUSTRIA\\n\\n650')\n",
      "(350, 8, 37, '7/ ean 7 a Tomm Moderate Claystone Sandstone\\n(ile Fm)\\n\\nFigure 4 Suneonine CO2 storage candidates based on lithology, average porosity, average permeability,\\nand seal characteristics.\\n\\nConclusion\\n\\nThe study showcases how a “Double Funnel Approach” through ')\n",
      "(351, 8, 38, 'an ML data ingestion pipeline can be an\\nefficient screening tool to analyze, review and rank CCS potential using readily available unstructured data.\\nIn this case, 490,000 pages of documents have been analyzed in 21 days to identify potential CCS\\nopportun')\n",
      "(352, 8, 39, 'ities below Heidrun producing field, extended across the Froan basin. Additional analysis through\\nthe “data target” may now be undertaken around Heidrun field on related wells, seismic and interpretation\\ndata.\\n\\nTo conclude, such an analysis suggests the s')\n",
      "(353, 8, 40, 'calability and the cost effectiveness of the methodology for\\nrapidly addressing the requirements of new CCS capabilities to mitigate the impact of the Climate Change.\\n\\nAcknowledgment\\n\\nThis paper utilizes the data from the Norwegian Petroleum Directorate (')\n",
      "(354, 8, 41, 'NPD) open dataset. Disclaimer of\\nthose interpretations from the study are from investigation and analysis of the authors alone.\\n\\nReferences\\n\\nBaillard, F., & Hernandez, N. (2021). A Case Study of Understanding the Bonaparte Basin using\\nUnstructured Data An')\n",
      "(355, 8, 42, 'alysis with Machine Learning Techniques. EAGE Annual.\\n\\nHernandez, M., & Baillard, F, (2019). An effective G&G exploration strategy inspired by a wolfpack.\\nFORCE Workshop.\\n\\nNorwegian Petroleum Directorate. (n.d.). 5 - The Norwegian Sea. Retrieved at Januar')\n",
      "(356, 8, 43, 'y 20, 2023 from\\nhttps://www.npd.no/en/facts/publications/co2-atlases/co2-atlas-for-the-norwegian-continental-shelf/5-the-\\n\\nnorwegian-sea/\\n\\nNorwegian Petroleum Directorate. (n.d.). 4 - The Norwegian North Sea. Retrieved at January 20, 2023\\nfrom https://www')\n",
      "(357, 8, 44, '.npd.no/en/facts/publications/co2-atlases/co2-atlas-for-the-norwegian-continental-\\nshelf/4-the-norwegian-north-sea/\\n\\n\\n')\n",
      "(358, 9, 1, '\\nVIENNA | AUSTRIA\\n\\nSand Production and Control Benchmarking through Unstructured Data Analysis with Machine\\nLearning in the North Sea\\n\\nIntroduction\\n\\nSand production has been serving as a bottleneck to the oil and gas industry, contributing to disruption\\no')\n",
      "(359, 9, 2, 'f daily production operations, casing deformation, erosion of well tubing, pipelines, and surface\\nequipment, expediting to significant non-productive time (NPT) costing millions of dollars in loss\\nannually. Conventional areal studies for sand production w')\n",
      "(360, 9, 3, 'ill only be limited to few wells and heavily\\ndependent on data availability, human-based interpretation, and time constraints. To administer a\\nholistic basin study for sand production comprising of hundreds of wells with conventional manual\\nmethod is cons')\n",
      "(361, 9, 4, 'idered complex and time consuming, hence sand mitigation best practices are typically\\nderived from localized reservoir and production engineering data only, and knowledge is organically\\nbuilt through accumulated expert experience in the area over multiple')\n",
      "(362, 9, 5, ' years of operatorship. Information\\nand reports may be derived from millions of pages of legacy well reports, documentations, or files from\\nover 40 years ranging from digitized medium to hand-written reports in countless formats.\\n\\nA sustainable strategy o')\n",
      "(363, 9, 6, 'f data-driven basis shall be leveraged to address the knowledge and information\\nmanagement issues utilizing the latest advancement of Machine Learning (ML) and data analytics to\\nmaximize the potential of unstructured data. Utilizing the intuitive data-dri')\n",
      "(364, 9, 7, 'ven approach, the paper will\\nhighlight the areal causation of sand production based on geological characteristics and the best\\npractices of sand control commenced by 8 operators in Norwegian Basins practically informative for\\nfuture exploration wells to b')\n",
      "(365, 9, 8, 'e developed nearby current wells. The study first creates a relationship\\nbetween the causation of sand production versus the sand control practices implied and best practices\\nare derived from the practices of multi-wells.\\n\\nMethodology\\n\\nUnstructured data i')\n",
      "(366, 9, 9, 'n nature is significantly sophisticated to be manually interpreted and skimmed\\nthrough by human-intervention. An intuitive approach embedded with Deep Convolutional Neural\\nNetwork (DCNN) for autonomous image recognition and Natural Language Processing (NL')\n",
      "(367, 9, 10, 'P) for texts\\nand entity processing and recognition has been a pioneering enterprise-scaled platform in managing\\nunstructured data (Hernandez et al., 2019). It will be capable to ingest “big data” for the case study\\ncomprising of 70,000 files with 490,000 ')\n",
      "(368, 9, 11, 'pages and 430,000 images inclusive of 361 wells over 5 basins\\nin Norway. 40 years of unstructured data for sand production case study is consolidated approximately\\nwithin 16 days of study period.\\n\\nWell Summary Tab Word Cloud Detaled search Correlate findi')\n",
      "(369, 9, 12, 'ngs with\\nKnowledge Graph\\n\\nplots /images/maps/stratigraphic\\n\\nOo Generic Search Heat Map @& Lithology tab Image search module\\nplots\\n\\nFigure 1 Data-driven case study research strategy for sand production in Norwegian Basins.\\n\\n\\n\\nVIENNA | AUSTRIA\\n\\nStep (1) is ')\n",
      "(370, 9, 13, 'a generic deep search of the sand production scope across the whole corpus. Step (2) leads\\nto discovering all wells significant parameters based on the files search results within well summary\\ntab. Step (3) portrays an early insight of the general idea of')\n",
      "(371, 9, 14, ' the document with word cloud. Step (4) heat\\nmap resembles the wells distribution in a GIS map based on colour density of corpus search frequency\\nmentioned in the documents. To uncover more questions along the research process and to obtain more\\nin-depth ')\n",
      "(372, 9, 15, 'information, step (5) is conducted in an iterative manner. Step (6) is to relate the lithology\\ndistribution by lithology count within each well document to the previous detailed search parameters.\\nStep (7) aims to find more representable images to support')\n",
      "(373, 9, 16, ' the case study through the automatically\\nclassified images through DCNN in the reports. After all significant parameters are obtained, well-to-\\nwell relationship is studied to get more details on further causation and best practices of sand production\\nma')\n",
      "(374, 9, 17, 'nagement.\\n\\nThe features of this intuitive knowledge management platform transform voluminous unstructured data\\ninto structured data that are ready to be consumed and utilised for production enhancement case study.\\nFour main ML analytical tools embedded in')\n",
      "(375, 9, 18, ' the platform are as presented below (Baillard et al.,2021):\\n\\ne Expeditious and intelligent search module by keyword-basis searching through hundreds of\\nthousands of pages of texts and texts embedded inside images.\\n\\ne Autonomous extraction of images from ')\n",
      "(376, 9, 19, 'documents and image segregation into respective image\\nclasses of tables, figures, well plots and maps with DCNN image detection algorithm.\\nKnowledge graph with contextual well name relationship portraying connectivity of ‘related\\ncorpuses’ to understand w')\n",
      "(377, 9, 20, 'ell-to-well relationship as described in their respective document corpus.\\nHeat Map illustrates the density of keywords by colour gradient on wells based on the search results\\non a map. Polygonal or square filter feature enable selective wells to be scree')\n",
      "(378, 9, 21, 'ned out for users\\nnarrowed search interest.\\n\\nCase Study: Preliminary Study on Sand Production and Developing Sand Control Benchmark of\\nNorwegian Basin with Unstructured Data\\n\\nThe study was conducted extensively throughout approximately 361 wells consuming')\n",
      "(379, 9, 22, ' 16 days of study\\nperiod covering the analysis and interpretation of sand production trends, causation and best practices\\nin Norwegian Basins. A total of 8 operators were participating in exploration phase of reservoirs\\nespecially in Voring and Northern N')\n",
      "(380, 9, 23, 'orth Sea basins.\\n\\nVoring Basin Wells\\n\\nFigure 2 Reservoir Performance Tests (RFT) for Voring Basin Wells\\n\\nSand production was reported in 7 wells and most discoveries of sanding were reported during Drill-\\nstem Testing (DST) and reported in completion repo')\n",
      "(381, 9, 24, 'rts and drilling program reports as in Figure 2. A\\n\\n\\n\\nVIENNA | AUSTRIA\\n\\nfew wells were reported to experience little to no sanding issues however pro\\ninformation in the scope of best practices and recommendations.\\n\\nUpper part - clean sandstone, fina grain')\n",
      "(382, 9, 25, 'ed, wall sorted 6608/10-2\\nand friable\\n\\nLower part —-medium to coarse grained, moderately\\n\\nSorted, friside to tose grains.\\n\\nModerately sorted, fine to very fine grain size, 6507/84\\npredominantly friable except the tight zones with\\nhard cementation.\\n\\nRaES ‘')\n",
      "(383, 9, 26, 'Sofft tertiasy clay stones wih sil and sand layers 640719-2\\n‘Sandstones, friable to very friable, moderately\\n\\nssoited, subrounded to rounded\\n\\n“Traces of sands (+-1% at 5000 STB/tay rate) | meee |\\n\\nGeologic Time Scale\\n\\nFigure 3 Chronostratigraphic evaluati')\n",
      "(384, 9, 27, 'on of Sand Prone Wells\\n\\nReferring to Figure 3, chronostratigraphic reports denote sufficient reasoning of sand production\\noccurrence throughout Norwegian basins as most sanding issues are prone in younger formations or\\ntertiary aged formations from Upper ')\n",
      "(385, 9, 28, 'Jurassic, Late Paleocene, Danian, Early Toracian, Sinemurian and\\nUpper Toracian. Cuttings and core samples obtained from different stratigraphy depths of sanding prone\\nformations; Tofte, Aldra, Froya and Top Heimdal were mostly described with friable, loo')\n",
      "(386, 9, 29, 'sely grained,\\ntraces of sands, soft tertiary claystone, little to no cementation and fine-grained characteristics\\ndominantly originating from sandstone, carbonate and claystone-sandstone mix lithology. Marginal\\nmarine and deltaic depositional environments')\n",
      "(387, 9, 30, ' leads to less cementation and loosely grained deposited\\n\\nsand characteristics.\\n\\nQuality of MOT wireline samples wes\\nquestioned due to plugging of the tool By\\n‘sand peoduction\\n\\n= Sand detection monitor did not indieate\\n‘any sand was being produced with th')\n",
      "(388, 9, 31, 'e\\n{uid stream and verified trough grind\\n‘outs which indicates only tracer of BSW.\\n\\n+ Unconsolidated sands stringers in Utsira\\nformation caused an increase of ROP rates\\nupto 270 meters per hour without ary\\n§W08 as the zone is primarily lose,\\nunconsolidated')\n",
      "(389, 9, 32, '.\\n\\n+ Prepacked screens were installed across\\nfeservoir interval to prevent sand\\nproduction fram unconsolidated formation\\n\\n‘+ Formation stability test - increase rate flow\\nSequence after the main buikdup, Sand\\nproduction and erosion is monitored by\\nSANDEC ')\n",
      "(390, 9, 33, 'system - record impact of sand\\ngrains on probe\\n\\n+ Formation stability testis constraint by low\\nermeabllty reservoir ~ not wanting to\\nflow the well approaching absolute open\\nflow\\n\\nNorthern North Sea Basin Wells\\nSand failure test (high-rate test- gradual\\ncr')\n",
      "(391, 9, 34, 'ease to high rate for 6 hours)\\nNo sand production observed\\n\\n= Wel was flowed for 5000 stb/d for 24\\nihours and choked back to 3960 stb/d when\\nsand production is above 1% for several\\nminutes (4/196 for S000 stb/d) - 141 psi\\ndrawdown\\n\\n+ Monitored with non-ln')\n",
      "(392, 9, 35, 'trusive sand\\ndetection sensor as well as manual\\n\\nsamoling\\n+ Ifsandis not produced in signi\\n‘quantities, the flow rate will be reduced\\n\\nprimary sand contro! with downhole wire\\nrapped screen run in tec string.\\n\\nSand production monitored with non-\\nintrusive ')\n",
      "(393, 9, 36, 'sand detection sensor as well as\\nmmanwal sampling\\n\\nRate should be reduced i sand production\\n>2.5% continues more than 15-20 minutes\\nBSEW samples should be taken’\\n\\nat early phase of rate build-up and before\\nand ater rate cronges\\n\\nFigure 4 Heat Map for sand')\n",
      "(394, 9, 37, ' production best practices — Voring Basin\\n\\nReservoir parameters analy:\\n\\nis was conducted to observe the sanding occurrence trends with respect to\\n\\nporosity, permeability, skin and perforation shots for each wells experiencing sand production issue.\\nStimul')\n",
      "(395, 9, 38, 'ated wells with negative skin value, significant high permeability and porosity values are\\n\\n\\n\\nVIENNA | AUSTRIA\\n\\narbitrarily associated to sanding issues. However, a few wells do highlight these characteristics but no\\nor little sanding occurred, and assump')\n",
      "(396, 9, 39, 'tions were made that inter-grain cementation are intact or sanding\\nprobably will occur soon in the later phases of the reservoir as sand production onset is distinct in each\\nwell. Perforation design does not lead primarily towards sand production as compa')\n",
      "(397, 9, 40, 'rison has been made\\nfor wells with the same perforation shots with significantly different reservoir parameters for\\ncomparative analysis. Pore pressure abnormalities attained from Knowledge Graph module possibly\\ncauses sand production problems specificall')\n",
      "(398, 9, 41, 'y reported in well 25/5-5 and 25/6-3 within Heimdal\\nformation interval, leading to depleted pressure gradient trends in both wells. Analysing the causation\\nof sanding creates an understanding in relation to the sand control practices conducted for each of')\n",
      "(399, 9, 42, ' the\\nwells. Wells describing sand production issues, sand control mitigation methods and other relatable\\ndescriptions of sand production were intensively analysed as Figure 4 above.\\n\\nConclusion\\n\\nManaging unstructured data into an intuitive structured data')\n",
      "(400, 9, 43, ' with embedded end-to-end ML\\nadvanced technology made it possible to interpret, analyze and make decisions with regards to\\nhandling “big data” and derive sand production causation and best practices across 490,000\\npages of public documents inclusive of 36')\n",
      "(401, 9, 44, '1 wells and 2 Norwegian basins in total. The novel\\napproach serves as a holistic study of sand management focused on unstructured “big data”\\nwhich combines multiple digitalization techniques currently applied in the petroleum industry.\\nMaximizing the pote')\n",
      "(402, 9, 45, 'ntial of underutilized unstructured data leads to opening of vast\\nopportunities for enhancement of production in existing oil and gas wells, and reduces\\ninvestment in the drilling of newer, more expensive wells, in alignment with a re-use, reduce,\\nup-cycl')\n",
      "(403, 9, 46, 'e mentality, towards sustainable energy transition for the industry.\\n\\nAcknowledgment\\n\\nThis paper utilizes the data from the Norwegian Petroleum Directorate (NPD) open dataset. Disclaimer\\nof those interpretations from the study are from investigation and a')\n",
      "(404, 9, 47, 'nalysis of the authors alone.\\n\\nReferences\\n\\nAcock, A. & ORourke, T. & Shirmboh, D. & Alexander, J. & Andersen, G. & Kaneko, T. &\\nVenkitaraman, A. & Lopez de Cardenas, Jorge & Nishi, M. & Numasawa, M. & Yoshioka, K. & Roy,\\nA. & Wilson, A. & Twynam, Allan. (')\n",
      "(405, 9, 48, '2004). Practical approaches to sand management. Oilfield\\nReview. 16. 10-27.\\n\\nBaillard, F., & Hernandez, N. (2021). A Case Study of Understand Bonaparte Basin using\\nUnstructured Data Analysis with Machine Learning Techniques. EAGE Annual.\\n\\nHernandez, M., &')\n",
      "(406, 9, 49, ' Baillard, F, (2019). An effective G&G exploration strategy inspired by a wolfpack.\\nForce workshop.\\n\\nHernandez, N., Lucafias, P., Graciosa, J., Mamador, C., & Panganiban, I. (2019). Automated\\nInformation Retrieval from Unstructured Documents Utilizing a S')\n",
      "(407, 9, 50, 'equence of Smart Machine\\nLearning. EAGE Workshop on Big Data and Machine Learning for E&P Efficiency 25 - 27 February.\\n\\nTiab, D. D., Erle C. (2012). Petrophysics - Theory and Practice of Measuring Reservoir Rock and\\nFluid Transport Properties (3rd Edition')\n",
      "(408, 9, 51, ') - 9.36 Porosity as Strength Indicator to Evaluate Sand\\nProduction. Elsevier.\\n\\nKim, 8.H., Sharma, M. M., and Harvey J. F. (2011). A Predictive Model for Sand Production in\\nPoorly Consolidated Sands. International Petroleum Technology Conference. Doi:\\nhtt')\n",
      "(409, 9, 52, 'ps://doi.org/10.2523/IPTC-15087-MS.\\n\\n\\n')\n",
      "(410, 10, 1, '\\nVIENNA | AUSTRIA\\n\\nUsing Machine Learning-Based Data Factory to Unlock Mining in Australia for Environmental,\\nSocial and Corporate Governance (ESG)\\n\\nIntroduction\\n\\nThe road to net zero requires a lot of raw materials from the mining industry. Renewable ene')\n",
      "(411, 10, 2, 'rgy systems\\nfor solar, hydro, and wind need to be built to support the transition. Among the many metals critical to\\ntechnology and infrastructure necessary for new energy, copper is highly sought after thanks to its\\nconductive efficiency making it an irr')\n",
      "(412, 10, 3, 'eplaceable element of any electrical equipment. Therefore, it is\\nprojected that by 2050, the demand for copper will reach more than 53 million metric tons. This is\\n“more than all the copper consumed in the world between 1900 and 2021”. Given the above, co')\n",
      "(413, 10, 4, 'pper\\nprice spikes, and copper supply challenges are to be expected (Bonakdarpour & Bailey, 2022). Hence,\\nit is crucial to optimize the way copper is mined in order to meet future demands, accelerate the energy\\ntransition and execute the plans of stakehold')\n",
      "(414, 10, 5, 'ers to achieve Environmental, Social and Corporate\\nGovernance (ESG) targets.\\n\\nOptimization of copper mining exploration and operations starts with the capability to easily make\\ndecisions and gain insights using the organizations’ data. However, this data ')\n",
      "(415, 10, 6, 'is often unstructured,\\nscattered, and unsearchable. To extract, manage and sustainably utilize all these unstructured data, a\\ndigital data factory composed of an orchestration of Machine Learning (ML) pipelines, data tracking,\\nand monitoring services, has')\n",
      "(416, 10, 7, ' been implemented on a subset of data from the Geological Survey of\\nQueensland (GSQ) in Australia. Utilizing the ML-based Data factory approach, this paper highlights\\nhow mining information from the GSQ can be analyzed, unlocked, and used in optimizing th')\n",
      "(417, 10, 8, 'e various\\nstages of the copper mining operation such as exploration, mining operation, copper ore processing,\\nreclamation and safety, health, and environmental control.\\n\\nMethodology\\n\\nUnstructured data from the GSQ contains scientific reports, borehole com')\n",
      "(418, 10, 9, 'pletion reports, publications,\\njournals, mining datasets, map collections, and mining records. The documents are highly technical and\\nspread over decades of mining operations making manual human interpretation and data extraction\\nchallenging. The dataset ')\n",
      "(419, 10, 10, 'covers 62 years of mining operation in Queensland and has been ingested in\\nthe data factory at a rate of 3,000 pages and 4,000 images per day through its scalable automated ML\\npipeline and big data capabilities. The steps of the processing include uploadi')\n",
      "(420, 10, 11, 'ng the data to the cloud,\\naudit of the data, text/image extraction, image classification, and table export capabilities as seen in\\nFigure 1. The features of this ML-based data factory transform voluminous unstructured data into\\nstructured data that are re')\n",
      "(421, 10, 12, 'adily accessible through a cloud-based application for text, image, and\\nknowledge search. The data factory’s features have applications that can be extended to all copper\\nmining stages.\\n\\neb Province Deposit\\nHON Qnsene\\nittle Evas\\nsit\\n\\nSearch Table OCR Imag')\n",
      "(422, 10, 13, 'e classification Word Cloud\\n\\nFigure 1 Transversal corpus search features of the digital data factory.\\nSeamless Search Tool\\n\\nTo have a firm grasp of the copper resource information covering the definitions, inferences,\\nindications, and compiled measurement')\n",
      "(423, 10, 14, 's, geologists and mining professionals involved in the\\n\\n\\n\\nVIENNA | AUSTRIA\\n\\nexploration stage of the copper mining projects would need to be able to gain new insights and search\\nthrough their unstructured data (OceanaGold Corporation, 2022). The ingestion')\n",
      "(424, 10, 15, ' and digestion process\\nmakes it possible to obtain new knowledge and insights, which is very difficult to achieve from the\\noriginal unstructured data. The ingested data is run through a Machine Learning-based pipeline that\\ntransforms the unstructured data')\n",
      "(425, 10, 16, ' into structured data with its elements made searchable (Mamador et\\nal., 2020). With the seamless search, geological, mineral and deposit information can be found\\nefficiently and fresh insights into the site mineralogy can be gained with relative ease (Ma')\n",
      "(426, 10, 17, 'ver et al.,\\n2021).\\n\\nCopper mineral deposit models can be correlated to their appropriate locations on geological maps and\\nsupported by visual evidence such as mineralogy descriptions in drill hole cores and geological maps\\nas displayed in Figure 2. Solid ')\n",
      "(427, 10, 18, 'geological inferences can be made regarding the characteristics of the\\ncopper ore deposit, which can then lead to feasible drilling and productive mining plans supported by\\nowned data.\\n\\nee iy pty\\n\\nFigure 2 Findings from deep corpus search of copper resour')\n",
      "(428, 10, 19, 'ce models and new geological insights\\nacross Queensland.\\n\\nFile, Domain and Image Tagging\\n\\nFile, domain, and image tagging are performed through the data factory. This allows for the\\nconsolidation of unstructured data, breaking data silos across documents ')\n",
      "(429, 10, 20, 'and disciplines, and making\\nall the relevant data during the copper mining operation accessible across organizations and contractors,\\nhence streamlining mining workflows and supporting cross-company collaboration (Maver et al., 2021).\\n\\nAn ongoing copper m')\n",
      "(430, 10, 21, 'ining operation would continuously produce various figurative and imagery data\\nsuch as resources and machinery management, schedules, rainfall, land survey information, engineering\\nsolutions, geology, and more. Some, if not all of these will be integrated')\n",
      "(431, 10, 22, ' or considered in the mining\\nplan or model (OceanaGold Corporation, 2022).\\n\\nThe continuous aggregation by domain experts and ingestion of unstructured data that happens during\\nthis stage of operation are improved via machine learning processes and scaled ')\n",
      "(432, 10, 23, 'suitably. This is\\nparticularly useful to track, reassess, visualize, and evaluate the mining plans or mining models at\\nvarious copper mining stages, such as tracking the progress of specific sub-blocks at a particular time.\\nInformation from various source')\n",
      "(433, 10, 24, 's would be integrated or correlated with these mining plans or models\\nto support decision-making associated with the site as shown in Figure 3. This process facilitates not\\nonly efficient and easy problem-solving conditions but supports planning processes')\n",
      "(434, 10, 25, ' and governance\\nstructures to be data-based and able to respond to ESG opportunities, risks and challenges (Maver et\\nal., 2021).\\n\\n\\n\\nVIENNA | AUSTRIA\\n\\nTICK HILL\\nMINE\\n\\nFigure 3 Important documents and varying information concerning the mining model at diffe')\n",
      "(435, 10, 26, 'rent\\nscales are accessible by various roles (mining engineers, operators, surveyors, geologists, etc.) across\\nthe organization involved.\\n\\nTable extraction\\n\\nEngineering, geoscience, and even metallurgic processes at the copper processing plant produce a va')\n",
      "(436, 10, 27, 'st\\nwealth of tables and numerical data (OceanaGold Corporation, 2022). Classifying tables to a particular\\nimage group is also tracked by the data factory. Optical character recognition (OCR) is used to identify\\nand locate individual and specific informati')\n",
      "(437, 10, 28, 'on which can be used in further analyses. By automatically\\nconverting each table image to a .csv file, valuable information becomes easily available, searchable,\\nand aggregated across various mining operation stages or copper processing plant processes as')\n",
      "(438, 10, 29, ' shown\\non Figure 4, Manual translation of the table to a .csv file can therefore be avoided, and information\\ntracked to the original location in the report.\\n\\npara\\nINDICATED os oa | 96 96\\n\\nwweenwed | oooe | 27 | a\\nTom [ose [as fos fo |\\n\\nFigure 4 Table imag')\n",
      "(439, 10, 30, 'e with numerical values such as tonnage and ore grades identified by the data\\nfactory’s OCR and extracted for external documents.\\n\\nBeing able to extract numerical values from tables is valuable to help track mining information such as\\nore grades, tonnage,')\n",
      "(440, 10, 31, ' production values, coordinates, rainfall, work hours, processing plant or laboratory\\nparameters.\\n\\nMapping of Similar Files and Word Cloud\\n\\nA data factory contains multiple tools that facilitate rapid comprehension and understanding of the\\ncontext of the ')\n",
      "(441, 10, 32, 'data. For example, the searchability of the elements in each document allows transverse\\ndocuments within the vast database with similar keywords to be grouped together through the search\\nresults. The word cloud associated with each document also allows ra')\n",
      "(442, 10, 33, 'pid comprehension of the whole\\ndocument briefly. Finding analogues, similarities, and historical issues is a problem that now has a\\nsolution. In the case of safety, health, and environmental control, incidents, lost time injury (LTD, and\\nreports of invest')\n",
      "(443, 10, 34, 'igation (RI) can be traced to specific documents or even specific pages in the original\\nreports,\\n\\n\\n\\nVIENNA | AUSTRIA\\n\\nEnvironmental, Social and Corporate Governance Targets in Mining\\n\\nThe data factory certainly allows the risks and opportunities related t')\n",
      "(444, 10, 35, 'o sustainability to be recognized,\\nevaluated and managed under a holistic framework pertaining to environmental, social and governance\\naspects. The data factory approach is an incentive that can add value and align the mining operation\\nwith broader Enviro')\n",
      "(445, 10, 36, 'nmental, Social and Corporate Governance (ESG) goals to limit environment\\nimpact. The data-supported holistic ecosystem from this approach is positioned to enhance cost-benefit\\nassessment of the ESG throughout the mining cycle.\\n\\nConclusion\\n\\nManaging unstr')\n",
      "(446, 10, 37, 'uctured data into structured data embedded with end-to-end ML/AI advanced\\ntechnology made it possible to explore, analyze and make fast decisions using big data. With this,\\norganizations involved in copper mining projects and more generally in the mining ')\n",
      "(447, 10, 38, 'industry are able to\\nprocess and present new mining information and knowledge from the dataset. Tools within the data\\nfactory such as deep search module, word cloud, table extraction, and image identification contribute\\nsignificantly to providing a compre')\n",
      "(448, 10, 39, 'hensive understanding across the full value chain for the copper\\ndeposit models, mining plans, copper treatment processes, rehabilitation plans, and safety, health and\\nenvironmental trends. Hence, maximizing the capability of unstructured data has proved ')\n",
      "(449, 10, 40, 'impactful in\\nterms of significantly reducing the consumption of research time and costs (Maver et al., 2021) and\\nalign mining operations with global ESG limiting the impact on the environment.\\n\\nAcknowledgment\\n\\nThis paper utilizes the data from the GSQ Ope')\n",
      "(450, 10, 41, 'n Data Portal database (geoscience.data.qld.gov.au). This\\ndatabase is owned by the Queensland Government and is open for public access. However, the\\ninterpretation and conclusion contained in this report are those of the authors alone.\\n\\nReferences\\n\\nBonakd')\n",
      "(451, 10, 42, 'arpour, M. & Bailey, T.M. (2022) The future of copper — Will the looming supply gap short-\\ncircuit the energy transition? S&P Global. JAS Markit.\\n\\nMamador, C., Aranda, J. O., Arif, N. E., Hernandez, N. M., & Baillard, F. (2020, September). A\\ngeological re')\n",
      "(452, 10, 43, 'gional case study for pressure, temperature, and salinity for the GoM using machine\\nlearning technology on unstructured data. In EAGE/AAPG digital subsurface for Asia Pacific\\nConference (Vol. 2020, No. 1, pp. 1-4). European Association of Geoscientists & ')\n",
      "(453, 10, 44, 'Engineers.\\n\\nMaver, K. G., Baillard, F., & Hernandez, N. M. (2021, May). Accelerating E&P Decisions by\\nApplying Artificial Intelligence and Big Data Analytics to Unstructured Data. In Digital Subsurface\\nConference in Latin America (Vol. 2021, No. 1, pp. 1-')\n",
      "(454, 10, 45, '5). European Association of Geoscientists &\\nEngineers.\\n\\nMaver, K. G., Hernandez, N. M., Baillard, F., & Cooper, R. (2020). Processing of unstructured\\ngeoscience and engineering information for instant access and extraction of new knowledge. First\\nBreak, 3')\n",
      "(455, 10, 46, '8(6), 59-64.\\n\\nOceanaGold Corporation (2022). The mining process. OceanaGold. Retrieved from\\nhttps://oceanagold.com/operation/macraes/the-mining-process/\\n\\n\\n')\n"
     ]
    }
   ],
   "source": [
    "# Execute a SELECT query\n",
    "query = \"SELECT * FROM chunks\"\n",
    "mycursor.execute(query)\n",
    "\n",
    "# Fetch all rows\n",
    "rows = mycursor.fetchall()\n",
    "\n",
    "# Print the results\n",
    "for row in rows:\n",
    "    print(row)  # You can format this output as needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate a dictionary from the paper\n",
    "As of 09/06/2024, the chatbot model uses the dictionary data type to look up information,\n",
    "so here I try to query the database and turn the paper we saved into a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute a query to select all the rows from the 'papers' table\n",
    "query = \"SELECT title, author, chunk FROM papers\"\n",
    "mycursor.execute(query)\n",
    "\n",
    "# Fetch all the rows\n",
    "rows = mycursor.fetchall()\n",
    "\n",
    "# Create a dictionary with the format you specified\n",
    "paper = {\n",
    "    \"title\": rows[0][0],\n",
    "    \"author\": rows[0][1],\n",
    "    \"content\": ''.join(row[2] for row in rows)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check our output\n",
    "We verify if the paper has indeed been loaded into a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'title': 'A CASE STUDY OF UNDERSTANDING THE BONAPARTE BASIN USING UNSTRUCTURED DATA ANALYSIS WITH MACHINE LEARNING TECHNIQUES', 'author': 'A.N.N. Sazali, N.M. Hernandez, F. Baillard, K.G. Maver', 'content': \"\\nA CASE STUDY OF UNDERSTANDING THE\\n\\nBONAPARTE BASIN USING UNSTRUCTURED DATA\\nANALYSIS WITH MACHINE LEARNING TECHNIQUES\\n\\nANN. Sazali!, N.M. Hernandez', F. Baillard', K.G. Maver!\\n\\n' Traya Energies\\n\\nSummary\\n\\nAs part of exploration and production the oil and gas industry produce substantial amounts of data\\nwithin different disciplines of which 80% are unstructured like reports, presentations, spreadsheets etc.\\nThe value of technical work is reduced due to the lack of time available for analysis and critical\\nthinking and the under-utilization of the data. To assist geoscientist and engineers, Machine Learning\\n(ML) and Artificial Intelligence (AI) technologies are applied to process the unstructured data from\\n440 wells from the Bonaparte Basin in Australia making it possible to perform more accurate analysis\\nand make faster decisions.\\n\\nBased on the play-based exploration pyramid concept, the time spent at the Basin Focus stage can be\\nreduced, and more time are available to focus on the other project stages. The explorationist will be\\nable to bring more value to the study.\\n\\nIt will be shown that potential issues encountered during exploration of the Bonaparte Basin can be\\nidentified. Based on a quick look and gathering of all information it can be concluded that most of the\\nproduction in the Bonaparte Basin is from Jurassic and Triassic with observed net pay of 18-60m\\nthickness, porosity of 11-29% and saturation of 11-55% Sw.\\n\\n\\nA Case Study of Understanding the Bonaparte Basin using Unstructured Data Analysis with\\nMachine Learning Techniques\\n\\nIntroduction\\n\\nAs part of exploration and production the oil and gas industry produce substantial amounts of data\\nwithin different disciplines of which 80% are unstructured like reports, presentations, spreadsheets etc\\nand it is expected to grow exponentially. As a result, geoscientists and engineers spend 50 to 80% of\\ntheir time searching and assembling data and only 1 to 5% of the data is fully utilized. The value of\\ntechnical work is therefore reduced due to the lack of time available for analysis and critical thinking\\nand the under-utilization of the data. To assist geoscientist and engineers, Machine Learning (ML)\\nand Artificial Intelligence (AI) technologies are applied to process the unstructured data making it\\npossible to perform more accurate analysis and make faster decisions.\\n\\nIn this case study the area of interest covers Bonaparte Basin, which is located north-west of\\nthe Australian continental margin (Figure 1). It joins the Money Shoal basin in the north-east and\\nthe Browse Basin in the south-west. Furthermore, the Timor Trough defines the northern boundary.\\nThe areal extent of the basin is approximately 270,000 sq. km. The objective of this study is to\\nunderstand and obtain meaningful insights into the Bonaparte Basin based on the substantial amount\\nof information available in previous studies, reports and presentations. The unstructured data of the\\nBonaparte Basin have been ingested in a Knowledge Container through consecutive ML and AI\\npipelines and analysed using big data analytics tools.\\n\\nJava Sea\\n\\nConsist of several structural elements :\\n@ Ashmore Platform  Malita Graben\\n Vulcan Sub-Basin  Sahul Platform\\n Londonderry High @ Flamingo High\\n Petrel Sub-basin @ Flamingo Syncline\\n Darwin Shelf  Sahul Syncline\\n@ Calder Graben  Nancar Trough\\n@ Troubadour Terrace  @)_ Laminaria High\\n\\nFigure 1 Location of the Bonaparte Basin within the Australian continental margin (left) and 14\\nstructural elements observed within the Bonaparte Basin (right).\\n\\nMethodology\\n\\nAs of 2021, the Bonaparte Basin encompasses 440 wells representing 58 years of exploration history\\nsummarized in over 270,000 pages of documents and in 250,000 images. It is estimated that billions of\\ndollars have been invested over the years to acquire and interprete the data, making it a substantial\\nsource of information for new exploration activities.\\n\\nThe Play Based Exploration (PBE) approach is often used as a traditional framework to refine the\\ngeoscientistss understanding from a broad basin level to a narrow prospect focus (Lottaroli et al., 2016).\\nAs a start such an approach often involves capturing the current state of knowledge with massive\\nbackground resources to understand and analyse the key features of the basin and the major risks\\nassociated to it. Such information is primarily available in unstructured data, requiring geoscientist and\\nengineers to process and ingest the information before focusing on a specific play and prospect using\\nstructured data. Therefore, we have modified the existing PBE pyramid to introduce an additional\\n\\n  \\n\\n\\ndimension associated with data science identifying the different types of data available at different\\nstages, allowing us to better define the best suited ML/AI strategy for a given stage (Figure 2).\\n\\nProspect Specific chance\\n\\nProspect focus\\n= image, Map, Evaluate\\n\\nSTRUCTURED chance that a panicular prospect will\\nbecome\\na discovery in case play works.\\n\\nPlay Focus\\n\\n' Play Chance\\n1 Identity imits ofthe single play elements 1 the chance hat a parteuler play\\nunsracres: Al eee wean | gy mesnereamecercett\\n\\\\ dbcare te 1 elements (e.g. reservoir, seal, source)\\neffectiveness of each element | of being present and effective over an\\n\\n(Commmon Risk Segment Mapping)\\n\\n@ Analyse play statistics. Seon Gey O44 a\\n\\nDetermination and description of the\\nRegional context and Basin\\nFramework\\nUnderstanding of the Petroleum\\nsystem(s)\\n\\nBasin Focus\\n\\n= Assess the possibility a play may\\nexists in a basin\\n\\nFigure 2 Customized Play Based Exploration (PBE) pyramid with ML technology (Modified from\\nLottaroli et al., 2016).\\n\\nFocusing on the unstructured data associated with the Basin and Play Analysis, all the data from the\\nBonaparte Basin have been processed through a succession of AI/ML automated pipeline such as\\nNatural Language Processing or Deep Convolutional Neural Network (Hernandez et al., 2019), (Figure\\n3). The sharable structured data is then further processed through deeper level of analytics to detect\\ntrends and anomalies present within the data. Machine assistance is heavily used in repetitive tasks early\\nin the process during the processing of the data and up to 95% of the tasks will be performed by the\\nmachine. This provides additional time for the specialist to focus on critical thinking and cognitive skills\\nto interpret the data.\\n\\nMACHINE LEARNING PIPELINE ANALYTICS, GEOLOGICAL INSIGHTS\\n\\n-inniogy an Early interpretation on\\nGeological environment\\n\\n* Text Search Data are geospatially\\n\\nExtracted image ea\\n+ Imoges. ~~ Image Classification  > nae |, distributed on maps for\\nDeep Convolutional ee trends and anomalies\\nUnstructured pecker hom Giants\\n Structured * Image Search\\nData ee\\na\\n\\n|, Extracted | Metadata Extraction |, Document\\nText and Tagging Tags\\n\\nNotural tanguage Processing\\n\\n._ Early trend can be observed\\n\\n> Heat Mi in\\nea MEe across the whole basin\\n\\n._ Identify well analogues and\\n\\nHEE oe relationship between wells\\n\\nMACHINE 4 on =\\n\\nAf. 50.%5 . i 60% 0%\\n\\nML/Al sequence automated with Analytics tools for data display Human high-level interpretation\\nhuman in the loop for QC\\n\\nFigure 3 Unstructured Big Data pipeline\\n\\nIn this case study, interpretation using the Big Data workflow was used to understand the exploration\\nhistory, how the basin developed, its petroleum system and the main issue of the dry wells occurrence\\nto avoid repeating the mistakes of the past and improve future decision making.\\n\\n\\n\\nBy analysing the data, five potential issues are identified i.e. (i) Discrepancies in Formation Tops, (ii)\\nLimited understanding of Lithology Distribution, (iii) Limited Mineral Composition Understanding,\\n(iv) Fluid Distribution, and (v) Pressure/Temperature Patterns. Each potential issue is tackled by\\nidentifying trends and anomalies across the basin using images, tables and plots extracted from the\\nunstructured data corpus.\\n\\nResults\\n\\nAs an example, the analysis of the (ii) Limited Understanding of Lithology Distribution, shown in\\nFigure 4, is performed using heatmaps. The heatmaps show the distribution of clastic and carbonates\\nacross the Bonaparte Basin and identify patterns and anomalies present in the area. The result can be\\nsupported by the stratigraphic chart where the carbonate environment occurs in the younger formation\\nfrom Cretaceous to Neogene period, whereas clastic environment is present in the older formations from\\nTriassic to Cretaceous.\\n\\nNe\\n\\nPALEOGENE\\neae\\n\\nEa\\n\\nCRETACEOUS\\n\\n$3233 3 3\\nJURASSIC\\n\\ntoy | Mee\\n\\nTing 5\\nwo\\n\\nBasal transgressive snadstone EEEEEE Limestone\\n\\nand marine shelf sand\\nMarine claystone and shale ES van\\n\\nModitied trom Frankowicz & McClay 2009\\n\\nFigure 4 Lithology distribution on heatmaps (left) and corresponding stratigraphic chart (right).\\n\\nThe analysis of the (iii) Limited Mineral Composition Understanding, shown in Figure 5, utilizes the\\nthin section automatically extracted using ML classification over the full area and suggests that:\\n\\n Quartz overgrowth and kaolinite are quite common in Bonaparte Basin\\n\\ne Mica mineral can be observed at the north-eastern part of the basin\\n\\ne Highly corroded, skeletal feldspar has been extensively dissolved, which forms secondary\\nporosity, and can be observed in the northern part of the basin\\n\\ne Some patchy siderites are also observed in the southern part of the basin\\n\\n  \\n\\n\\nFigure 5 Thin section images distributed on a map across the Bonaparte Basin.\\n\\nConclusion\\n\\nA regional understanding is critical and time consuming as it involves dealing with a very large data\\nvolume. Within a project time frame, based on PBE pyramid, the time spent at the Basin Focus stage\\ncan be reduced, and more time are available to focus on the other project stages. The explorationist will\\nbe able to bring more value to the study.\\n\\nML applications have proven to be able to play a crucial part in order to organize large unstructured\\ndata corpuses. This allows faster and accurate decision making within the fast-moving industry.\\n\\nIn this study, some potential issues encountered during exploration of the Bonaparte Basin can be\\nidentified. Based on a quick look and gathering of all information it can be concluded that most of the\\nproduction in the Bonaparte Basin is from Jurassic and Triassic with observed net pay ~18-60m\\nthickness, porosity ~11-29% and saturation ~11-55% Sw.\\n\\nReferences\\n\\nHernandez N., Lucafias P., Graciosa J.C., Mamador C., and Panganiban L. C. L, 2019: Automated\\ninformation retrieval from unstructured documents utilizing a sequence of smart machine learning\\nmethods within a hybrid cloud container. EAGE Workshop on Big Data and Machine Learning for E&P\\nEfficiency 25 - 27 February.\\n\\nLottaroli F., Craig J., Cozzi A., 2016: Evaluating a vintage play fairway exercise using subsequent\\nexploration results: did it work? Petroleum Geoscience, Vol 24, no 2, p. 159-171.\\n\\nMaver K.G., Hernandez N., Lucafias P., Graciosa J.C., Mamador C., Panganiban L.C.I., Yu C., and\\nMaver M.G., 2018: An automated information retrieval platform for unstructured well data smart\\nmachine learning algorithms within a hybrid cloud container. EAGE/PESGB Workshop on Machine\\nLearning, 29  30 November.\\n\\n\\n\"}\n"
     ]
    }
   ],
   "source": [
    "# Print the paper\n",
    "print(paper)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "streamlit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
