{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Database Notebook\n",
    "I made this notebook to explore the MySQL Python Connector. Markdown cells have\n",
    "been added for the team's future reference.\n",
    "### WARNING: Do not 'RUN ALL' cells! \n",
    "### This notebook contains cells that remove databases, papers, writes data, etc.\n",
    "### For exploration purposes only! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enter MySQL Password\n",
    "Password will be input this way to avoid being exposed in the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "password = input(\"Enter your database password: \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial Connection\n",
    "This cell connects us to MySQL. Change the host and username as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_db = mysql.connector.connect(\n",
    "    host=\"127.0.0.1\",\n",
    "    user=\"root\",\n",
    "    password=password,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initializing the MySQL cursor\n",
    "This cursor allows us to perform MySQL operations using Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mycursor = text_db.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a database\n",
    "This cell creates a new database. Change the database name as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mycursor.execute(\"CREATE DATABASE technical_database\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drop a database\n",
    "### (Be careful with this cell!)\n",
    "This cell removes an existing database. Change name as needed (the cell below outputs a list of existing databases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mycursor.execute(\"DROP DATABASE technical_database\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# List all existing databases\n",
    "This cell displays all MySQL databases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('information_schema',)\n",
      "('mysql',)\n",
      "('performance_schema',)\n",
      "('sakila',)\n",
      "('sys',)\n",
      "('technical',)\n",
      "('world',)\n"
     ]
    }
   ],
   "source": [
    "mycursor.execute(\"SHOW DATABASES\")\n",
    "for x in mycursor:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connecting to Database\n",
    "This connects us to a specific database. Change the database name as needed (you \n",
    "can choose from the list of databases output by the cell above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_db = mysql.connector.connect(\n",
    "    host=\"127.0.0.1\",\n",
    "    user=\"root\",\n",
    "    password=password,\n",
    "    database=\"technical_database\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mycursor = text_db.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drop a table from the database\n",
    "### (Be careful with this cell!)\n",
    "\n",
    "This removes a table from the database that we are connected to. Change the table name as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mycursor.execute(\"DROP TABLE papers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a sample table for papers\n",
    "This creates a database table called 'papers' with columns for primary key (auto incremented), title, author, and chunk (consisting of 255 chars at most)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mycursor.execute(\"\"\"\n",
    "    CREATE TABLE papers (\n",
    "        id INT AUTO_INCREMENT PRIMARY KEY,\n",
    "        title VARCHAR(255),\n",
    "        author VARCHAR(255),\n",
    "        chunk TEXT(255)\n",
    "    )\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show all tables in database\n",
    "This cell lists all the tables in the database that we're connected to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('chunks',)\n",
      "('papers',)\n"
     ]
    }
   ],
   "source": [
    "mycursor.execute(\"SHOW TABLES\")\n",
    "for x in mycursor:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# See current directory\n",
    "We're about to work with files (Tesseract output .txt files), so we need to check our current working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER\\Documents\\OJTChatbotBEIC\\MySQL\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upload an extracted paper into the database\n",
    "The paper is divided into chunks (up to length 255) and stored into the database, \n",
    "along with metadata such as title and author name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the entire file content\n",
    "with open('../Tesseract/Extracted.txt', 'r', encoding=\"utf-8\", errors='ignore') as file:\n",
    "    file_content = file.read()\n",
    "\n",
    "# Split the content into smaller strings (up to 255 characters)\n",
    "max_length = 255\n",
    "split_content = [file_content[i:i + max_length] for i in range(0, len(file_content), max_length)]\n",
    "\n",
    "title = \"A CASE STUDY OF UNDERSTANDING THE BONAPARTE BASIN USING UNSTRUCTURED DATA ANALYSIS WITH MACHINE LEARNING TECHNIQUES\"\n",
    "authors = \"A.N.N. Sazali, N.M. Hernandez, F. Baillard, K.G. Maver\"\n",
    "\n",
    "# Insert each smaller string into the database\n",
    "query = \"INSERT INTO papers (title, author, chunk) VALUES (%s, %s, %s)\"\n",
    "for content in split_content:\n",
    "    mycursor.execute(query, (title, authors, content))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Commit the changes into the database\n",
    "This updates the database, this time for real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_db.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Print all rows of the table\n",
    "Useful for checking the committed changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1, 1, \"\\nA CASE STUDY OF UNDERSTANDING THE\\n\\nBONAPARTE BASIN USING UNSTRUCTURED DATA\\nANALYSIS WITH MACHINE LEARNING TECHNIQUES\\n\\nAN.N. Sazali!, N.M. Hernandez, F. Baillard', K.G. Maver!\\n\\n'Traya Energies\\n\\nSummary\\n\\nAs part of exploration and production the oil and ga\")\n",
      "(2, 1, 2, 's industry produce substantial amounts of data\\nwithin different disciplines of which 80% are unstructured like reports, presentations, spreadsheets etc.\\nThe value of technical work is reduced due to the lack of time available for analysis and critical\\nthi')\n",
      "(3, 1, 3, 'nking and the under-utilization of the data. To assist geoscientist and engineers, Machine Learning\\n(ML) and Artificial Intelligence (AI) technologies are applied to process the unstructured data from\\n440 wells from the Bonaparte Basin in Australia making')\n",
      "(4, 1, 4, ' it possible to perform more accurate analysis\\nand make faster decisions.\\n\\nBased on the play-based exploration pyramid concept, the time spent at the Basin Focus stage can be\\nreduced, and more time are available to focus on the other project stages. The e')\n",
      "(5, 1, 5, 'xplorationist will be\\nable to bring more value to the study.\\n\\nIt will be shown that potential issues encountered during exploration of the Bonaparte Basin can be\\nidentified. Based on a quick look and gathering of all information it can be concluded that m')\n",
      "(6, 1, 6, 'ost of the\\nproduction in the Bonaparte Basin is from Jurassic and Triassic with observed net pay of 18-60m\\nthickness, porosity of 11-29% and saturation of 11-55% Sw.\\n\\n\\nA Case Study of Understanding the Bonaparte Basin using Unstructured Data Analysis with')\n",
      "(7, 1, 7, '\\nMachine Learning Techniques\\n\\nIntroduction\\n\\nAs part of exploration and production the oil and gas industry produce substantial amounts of data\\nwithin different disciplines of which 80% are unstructured like reports, presentations, spreadsheets etc\\nand it ')\n",
      "(8, 1, 8, 'is expected to grow exponentially. As a result, geoscientists and engineers spend 50 to 80% of\\ntheir time searching and assembling data and only 1 to 5% of the data is fully utilized. The value of\\ntechnical work is therefore reduced due to the lack of tim')\n",
      "(9, 1, 9, 'e available for analysis and critical thinking\\nand the under-utilization of the data. To assist geoscientist and engineers, Machine Learning (ML)\\nand Artificial Intelligence (AI) technologies are applied to process the unstructured data making it\\npossible')\n",
      "(10, 1, 10, ' to perform more accurate analysis and make faster decisions.\\n\\nIn this case study the area of interest covers Bonaparte Basin, which is located north-west of\\nthe Australian continental margin (Figure 1). It joins the Money Shoal basin in the north-east an')\n",
      "(11, 1, 11, 'd\\nthe Browse Basin in the south-west. Furthermore, the Timor Trough defines the northern boundary.\\nThe areal extent of the basin is approximately 270,000 sq. km. The objective of this study is to\\nunderstand and obtain meaningful insights into the Bonapart')\n",
      "(12, 1, 12, 'e Basin based on the substantial amount\\nof information available in previous studies, reports and presentations. The unstructured data of the\\nBonaparte Basin have been ingested in a Knowledge Container through consecutive ML and AI\\npipelines and analysed ')\n",
      "(13, 1, 13, 'using big data analytics tools.\\n\\nConsist of several structural elements :\\n@ Ashmore Platform © Maiita Graben\\n© Vulcan Sub-Basin © Sahui Platform\\n© Londonderry High @ Flamingo High\\n\\n@ Petrel Sub-basin @® Flamingo Syncline\\n© Darwin Shelf ® Sahui Syncline\\n© ')\n",
      "(14, 1, 14, 'Calder Graben ® Nancar Trough\\n\\n@ Troubadour Terrace Laminaria High\\n\\nFigure 1 Location of the Bonaparte Basin within the Australian continental margin (left) and 14\\nstructural elements observed within the Bonaparte Basin (right).\\n\\nMethodology\\n\\nAs of 2021, ')\n",
      "(15, 1, 15, 'the Bonaparte Basin encompasses 440 wells representing 58 years of exploration history\\nsummarized in over 270,000 pages of documents and in 250,000 images. It is estimated that billions of\\ndollars have been invested over the years to acquire and interpret')\n",
      "(16, 1, 16, 'e the data, making it a substantial\\nsource of information for new exploration activities.\\n\\nThe Play Based Exploration (PBE) approach is often used as a traditional framework to refine the\\ngeoscientists’s understanding from a broad basin level to a narrow ')\n",
      "(17, 1, 17, 'prospect focus (Lottaroli et al., 2016).\\nAs a start such an approach often involves capturing the current state of knowledge with massive\\nbackground resources to understand and analyse the key features of the basin and the major risks\\nassociated to it. Su')\n",
      "(18, 1, 18, 'ch information is primarily available in unstructured data, requiring geoscientist and\\nengineers to process and ingest the information before focusing on a specific play and prospect using\\nstructured data. Therefore, we have modified the existing PBE pyra')\n",
      "(19, 1, 19, 'mid to introduce an additional\\n\\na ——————_— ——————\\n\\n\\ndimension associated with data science identifying the different types of data available at different\\nstages, allowing us to better define the best suited ML/AI strategy for a given stage (Figure 2).\\n\\nSS')\n",
      "(20, 1, 20, 'LninEnEnSuDunDnTannDaranaparerecacararetaaretmrarntnrnrn armeerararetars tate smear eer eee\\n\\nProspect focus:\\na lmage, Mop, Evekste\\nProspects\\n\\nSTRUCTURED\\n\\nchance that particular prospect will\\n‘become\\na cascovery in case play works.\\n\\nRenee oS Sa\\n\\n7” Play Fo')\n",
      "(21, 1, 21, 'cus\\n2 Hoarty Enns of the single play eternenta\\n\\nPlay Chance\\n‘The chance thet a pecticuter play\\nworks, hence the chance of Its\\nelomania (¢.9. reservor. seal, source)\\n\\nUNSTRUCTURED\\nOf being present and effective over an\\n\\nnonsense\\n\\nsree (pay segment.\\n1 Deter')\n",
      "(22, 1, 22, 'mination and description of te\\n1 Regional context and Barn\\na Asseas Ihe possibilty a play may H Framework.\\nyy H i\\n% % cococcccoccacacccocad beeen ERRORS\\nNS\\nie\\nLan\\n\\nFigure 2 Customized Play Based Exploration (PBE) pyramid with ML technology (Modified from\\n')\n",
      "(23, 1, 23, 'Lottaroli et al., 2016).\\n\\nFocusing on the unstructured data associated with the Basin and Play Analysis, all the data from the\\nBonaparte Basin have been processed through a succession of AI/ML automated pipeline such as\\nNatural Language Processing or Deep')\n",
      "(24, 1, 24, ' Convolutional Neural Network (Hernandez et al., 2019), (Figure\\n3). The sharable structured data is then further processed through deeper level of analytics to detect\\ntrends and anomalies present within the data. Machine assistance is heavily used in repe')\n",
      "(25, 1, 25, 'titive tasks early\\nin the process during the processing of the data and up to 95% of the tasks will be performed by the\\nmachine. This provides additional time for the specialist to focus on critical thinking and cognitive skills\\nto interpret the data.\\n\\nMA')\n",
      "(26, 1, 26, 'CHINE LEARNING PIPELINE ANALYTICS GEOLOGICAL INSIGHTS\\n\\nEarly interpretation on\\n\\n> Uthiology Cloud Geological environment\\n\\n> Text Search; «= —— i\\nextracted _ me Data are geospatially\\nimages ~~ (age Classification - + 730 distributed on maps for\\nDeep Convol')\n",
      "(27, 1, 27, 'utional Sharable trends and anomalies\\nUnstructured i\\nNowra Neework Structured —-» mage Search observation\\nData\\nExtracted Metadata Extraction Document\\n» i . i ee ee Le Earty trend can be observed\\nText and Tagging Tees ete CD across the whole basin\\nNatural ')\n",
      "(28, 1, 28, 'Language Processing\\n. 2 _, Hdentify well analogues and\\nKnowledge Graph — ~ * etctionship between wells\\nacorn B EEG 00 ——9%—__\\nASSISTANCE 95%\\nMI/Al sequence automated with Analytics tools for data display Human high-level interpretation\\n\\nhuman in the loop ')\n",
      "(29, 1, 29, 'for QC\\nHUMAN -\\n(NTERVENTION Se -\\n\\nFigure 3 Unstructured Big Data pipeline\\n\\nIn this case study, interpretation using the Big Data workflow was used to understand the exploration\\nhistory, how the basin developed, its petroleum system and the main issue of t')\n",
      "(30, 1, 30, 'he dry wells occurrence\\nto avoid repeating the mistakes of the past and improve future decision making.\\n\\na ——————_— ——————\\n\\n\\nBy analysing the data, five potential issues are identified i.e. (i) Discrepancies in Formation Tops, (ii)\\nLimited understanding o')\n",
      "(31, 1, 31, 'f Lithology Distribution, (iii) Limited Mineral Composition Understanding,\\n(iv) Fluid Distribution, and (v) Pressure/Temperature Patterns. Each potential issue is tackled by\\nidentifying trends and anomalies across the basin using images, tables and plots ')\n",
      "(32, 1, 32, 'extracted from the\\nunstructured data corpus.\\n\\nResults\\n\\nAs an example, the analysis of the (ii) Limited Understanding of Lithology Distribution, shown in\\nFigure 4, is performed using heatmaps. The heatmaps show the distribution of clastic and carbonates\\nac')\n",
      "(33, 1, 33, 'ross the Bonaparte Basin and identify patterns and anomalies present in the area. The result can be\\nsupported by the stratigraphic chart where the carbonate environment occurs in the younger formation\\nfrom Cretaceous to Neogene period, whereas clastic env')\n",
      "(34, 1, 34, 'ironment is present in the older formations from\\nTriassic to Cretaceous.\\n\\na\\n\\nHr\\n343\\noes\\n\\nae | oom |S\\nhata\\n\\n\"carbonate!\\n\\ncave fun 674 meron 200 wal for “arbors\\n\\nBasal ranagressive enadstone EEEEE Limestone\\n\\nand marine shelf sand\\nMarine claystone and shale ')\n",
      "(35, 1, 35, 'ME vant\\n\\nModitied from Prankowlez & McClay 2009\\n\\nFigure 4 Lithology distribution on heatmaps (left) and corresponding stratigraphic chart (right).\\n\\nThe analysis of the (iii) Limited Mineral Composition Understanding, shown in Figure 5, utilizes the\\nthin s')\n",
      "(36, 1, 36, 'ection automatically extracted using ML classification over the full area and suggests that:\\n\\ne Quartz overgrowth and kaolinite are quite common in Bonaparte Basin\\n\\ne Mica mineral can be observed at the north-eastern part of the basin\\n\\ne Highly corroded, ')\n",
      "(37, 1, 37, 'skeletal feldspar has been extensively dissolved, which forms secondary\\nporosity, and can be observed in the northern part of the basin\\n\\ne Some patchy siderites are also observed in the southern part of the basin\\n\\na ——————_— ——————\\n\\n\\ntn i pt ma\\n\\n@ 14480 C')\n",
      "(38, 1, 38, 'ope Hoy Fm)\\n\\nFigure 5 Thin section images distributed on a map across the Bonaparte Basin.\\nConclusion\\n\\nA regional understanding is critical and time consuming as it involves dealing with a very large data\\nvolume. Within a project time frame, based on PBE ')\n",
      "(39, 1, 39, 'pyramid, the time spent at the Basin Focus stage\\ncan be reduced, and more time are available to focus on the other project stages. The explorationist will\\nbe able to bring more value to the study.\\n\\nML applications have proven to be able to play a crucial ')\n",
      "(40, 1, 40, 'part in order to organize large unstructured\\ndata corpuses. This allows faster and accurate decision making within the fast-moving industry.\\n\\nIn this study, some potential issues encountered during exploration of the Bonaparte Basin can be\\nidentified. Bas')\n",
      "(41, 1, 41, 'ed on a quick look and gathering of all information it can be concluded that most of the\\nproduction in the Bonaparte Basin is from Jurassic and Triassic with observed net pay ~18-60m\\nthickness, porosity ~11-29% and saturation ~11-55% Sw.\\n\\nReferences\\n\\nHern')\n",
      "(42, 1, 42, 'andez N., Lucafias P., Graciosa J.C., Mamador C., and Panganiban L. C. 1, 2019: Automated\\ninformation retrieval from unstructured documents utilizing a sequence of smart machine learning\\nmethods within a hybrid cloud container. EAGE Workshop on Big Data a')\n",
      "(43, 1, 43, 'nd Machine Learning for E&P\\nEfficiency 25 - 27 February.\\n\\nLottaroli F., Craig J., Cozzi A., 2016: Evaluating a vintage play fairway exercise using subsequent\\nexploration results: did it work? Petroleum Geoscience, Vol 24, no 2, p. 159-171.\\n\\nMaver K.G., He')\n",
      "(44, 1, 44, 'rnandez N., Lucafias P., Graciosa J.C., Mamador C., Panganiban L.C.L, Yu C., and\\nMaver M.G., 2018: An automated information retrieval platform for unstructured well data smart\\nmachine learning algorithms within a hybrid cloud container. EAGE/PESGB Worksho')\n",
      "(45, 1, 45, 'p on Machine\\nLearning, 29 — 30 November.\\n\\na ——————_— ——————\\n\\n')\n",
      "(46, 2, 1, \"\\nML P17\\n\\nN.M. Hernandez’, P.J. Lucafias', J.C. Graciosa', C. Mamador', L. Caezar', I. Panganiban!, C. Yu', K.G.\\nMaver’*, M.G. Maver’\\n'Traya Energies, 7 KGM geoconsulting\\n\\nSummary\\n\\nThere is a large amount of historic and valuable well information available\")\n",
      "(47, 2, 2, ' stored either on paper and more\\nrecently as digital documents and reports in the oil and gas industry especially by national data management\\nsystems and oil companies, These technical documents contain valuable information from disciplines like\\ngeoscienc')\n",
      "(48, 2, 3, 'e and engineering and are in general stored in a unstructured format. To extract and utilize all this well\\ndata, a machine learning-enabled platform, consisting of a carefully selected sequence of algorithms, has been\\ndeveloped as a hybrid cloud container')\n",
      "(49, 2, 4, ' that automatically reads and understands the technical documents with little\\nhuman supervision. The user can upload raw data to the platform, which are stored on a private local server. The\\nmachine learning algorithms are activated and implement the nece')\n",
      "(50, 2, 5, 'ssary processing and workflows. Structured\\ndata is generated as output, which are pushed through to a search engine that is accessible to the user in the cloud.\\nThe aim of the platform is to ease the identification of important parts of the technical docu')\n",
      "(51, 2, 6, 'ments, automatically\\nextract relevant information and visualize it for the user, so they can easily do further analysis, share it with\\ncolleagues or agnostically port it to other platforms as input.\\n\\nFirst EAGE/PESGB Workshop on Machine Learning\\n\\nANA ANAT')\n",
      "(52, 2, 7, '... ANIO tT ..43.. mH\\n\\n\\nIntroduction\\n\\nThere is a large amount of historic well information available stored either on paper and more recently\\nas digital documents and reports in the oil and gas industry. These technical documents contain\\nvaluable informat')\n",
      "(53, 2, 8, 'ion from diverse disciplines such as geology, geophysics, petrophysics, reservoir\\nengineering, drilling and other subject matters and are in general stored in a unstructured format.\\n\\nEspecially national data management systems and oil companies hosts thes')\n",
      "(54, 2, 9, 'e large amounts of very\\nvaluable historical well data, which contain information such as reservoir metadata, images, texts, and\\nprocessed information, such as lithology, geology, shows, drilling risks etc. Due to the large volume,\\nvintage variety, and non')\n",
      "(55, 2, 10, '-standard formats, extraction of valuable information, which can be used as\\ninput for further work, is an arduous task as the manual nature of data mining is very time-consuming.\\n\\nTo extract and utilize all this well data, a machine learning-enabled platf')\n",
      "(56, 2, 11, 'orm has been developed as a\\nhybrid cloud container that automatically reads and understands hundreds or thousands of technical\\ndocuments with little human supervision. The aim of the platform is to ease the identification of\\nimportant parts of the technic')\n",
      "(57, 2, 12, 'al documents, automatically extract relevant information and visualize it\\nfor the user, so they can easily do further analysis, share it with colleagues or agnostically port it to\\nother platforms as input.\\n\\nMethodology\\n\\nThe platform utilizes a hybrid data')\n",
      "(58, 2, 13, ' service architecture, which leverages the 2-tier strength of both\\ncloud and private servers. The hybrid architecture serves to:\\n\\nEnhance the platform’s security and data privacy by storing raw data locally\\nIncrease data shareability in real-time by utili')\n",
      "(59, 2, 14, 'zing a cloud solution\\n\\nReduce data redundancy and increase data integrity among users\\n\\nProvide a pragmatic solution to optimize data storage costs\\n\\nThe user can upload raw data to the platform, which are stored on a private local server. The machine\\nlearn')\n",
      "(60, 2, 15, 'ing algorithms are activated and implement the necessary processing and workflows. Structured\\ndata is generated as output, which are pushed through to a search engine that is accessible to the user\\nin the cloud (Figure 1).\\n\\nFigure 1 The hybrid architectur')\n",
      "(61, 2, 16, 'e of platform (ElasticDocs) utilizing the 2-tier strength of local and\\ncloud sever applications for data security, integrity and shareability. Carefully selected machine\\nlearning sequence for automated text and image analysis include: optical character re')\n",
      "(62, 2, 17, 'cognition, deep\\nconvolutional neural network and image clustering.\\n\\nFirst EAGE/PESGB Workshop on Machine Learning\\n\\nANA ANAT... ANIO tT ..43.. mH\\n\\n\\nThe platform capitalizes on the machine learning algorithms that automatically process the\\nunstructured data')\n",
      "(63, 2, 18, ' into a condensed format in which only pre-selected information are stored. The\\nmachine learning algorithms employs a unique sequence of separate steps, which are set-up to mimic\\nthe human experience of processing unstructured documents.\\n\\nWorkflow\\n\\nA Norw')\n",
      "(64, 2, 19, 'egian dataset consisting of 400 well reports (58,000 pages) and an Australian well database\\nconsisting of 6,000 pages have been used as training data for generating structured data.\\n\\nFor the unstructured data the first machine learning step is the digitiz')\n",
      "(65, 2, 20, 'ation and conversion of .pdf or\\n.docx file formats into an editable format. This conversion uses Optical Character Recognition (OCR),\\nwhere the machine identifies each character in the image.\\n\\nAfter the documents are digitized important information has to')\n",
      "(66, 2, 21, ' be identified. This metadata extraction\\nand tagging utilizes Natural Language Processing (NLP) to tokenize each digitized text and identify\\nterms of significant value. Named Entity Recognition (NER) is then performed to create a model to\\nextract the meta')\n",
      "(67, 2, 22, 'data like well name, basin, permit, operator, well classification, latitude, longitude,\\nspudding date, kelly bushing etc.\\n\\nFor the images extracted by the digitization process, a modified VGG-16 neural network is used to\\nautomatically classify tables, cha')\n",
      "(68, 2, 23, 'rts, stratigraphic chart images, maps, seismic, core samples and\\nscanning electron microscope images within each document (Simonyan ef al., 2014)\\n\\nFor the visualization of the images an at-Distributed Stochastic Neighbor Embedding (t-SNE)\\nalgorithm is use')\n",
      "(69, 2, 24, 'd to quantify the similarity of each image, which has been developed to visualize\\nhigh-dimensional datasets and reveal clustering within the datasets (van der Maaten et al., 2008).\\n\\nThe output from the machine learning sequence is then exposed to the user')\n",
      "(70, 2, 25, 's through the platform to\\nease the work of identifying important information and perform analysis in a more efficient way. The\\nextracted information is outputted in an agnostic format, which can be efficiently loaded to other\\nplatforms or used as is, ic. ')\n",
      "(71, 2, 26, 'X, Y or Latitude/Longitude, formation tops in csv or excel format,\\ndigitized maps as shapefile for loading into GIS software.\\n\\nDiscussion and conclusion\\n\\nWells provide key information about the subsurface in oil and gas exploration and production but at a')\n",
      "(72, 2, 27, '\\nsubstantial cost. As this valuable information associated with a well is often stored as unstructured\\ndata, it is difficult to do further analysis or apply additional artificial intelligence processing to the\\nwell database to enable geoscientists to gain')\n",
      "(73, 2, 28, ' new insights and extract new relationships.\\n\\nThe carefully selected sequence of machine learning algorithms in the workflow deals with these\\nlarge unstructured datasets, is housed within a hybrid cloud platform to automatically extract relevant\\ninformati')\n",
      "(74, 2, 29, 'on within technical documents and convert the unstructured data into a shareable structured\\ndataset.\\n\\nReferences\\n\\nSimonyan, K. & Zisserman, A., 2014: Very Deep Convolutional Networks for Large-scale Image\\nRecognition. arXiv preprint arXiv: 1409.1556\\n\\nvan ')\n",
      "(75, 2, 30, 'der Maaten, L.J.P. & Hinton G.E., 2008]: Visualizing High-Dimensional Data using t-SNE.\\nJournal of Machine Learning Research, 9, 2576-2605.\\n\\nFirst EAGE/PESGB Workshop on Machine Learning\\n\\nANA ANAT... ANIO tT ..43.. mH\\n\\n')\n",
      "(76, 3, 1, '\\nSupporting the UN 2050 Net Zero goals by reading\\n\\nthe earth better\\n\\nNina Marie Hernandez\", Kim Gunn Maver and Charmyne Mamador present the ED2K\\ninitiative, providing multivariate earth data to support UN climate change goals.\\n\\nIntroduction\\n\\nAgainst the b')\n",
      "(77, 3, 2, 'ackdrop of the current global pandemic, the UN\\n2050 net zero goals call for global greenhouse emissions to be cut\\nby half by 2030 and reach net zero no later than 2050 to achieve\\nthe goal of limiting global warming to 1.5 Celsius above pre-in-\\ndustrial le')\n",
      "(78, 3, 3, 'vels. The EU has pledged to become the first carbon.\\nneutral continent by 2050, and more than 110 other countries\\nhave pledged carbon neutrality by this time. Several energy com-\\npanies have laid out their medium-to-long-term plans towards\\nthis objective,')\n",
      "(79, 3, 4, ' which includes acquisition of renewables assets,\\nand developing competitive technologies for carbon capture and\\nstorage (CCS) and hydrogen production. Among the companies\\nthat have set zero-emissions targets are BP, Shell, Total, Repsol,\\nEquinor and Petr')\n",
      "(80, 3, 5, 'onas. This energy pivot will require significant\\ncapital spending to reach the goals.\\n\\nTo determine the technical and economic feasibility of these\\nnew energy technologies and at the same time achieve sustainable\\ndevelopment goals, multivariate earth data')\n",
      "(81, 3, 6, ', both existing and\\nnew, are required and are key to making the right management\\nand investment decisions.\\n\\nEarthDoc pointing to the future\\n\\nTo this end, more than 39 years of conference proceedings and\\npublications are already available from EAGE through')\n",
      "(82, 3, 7, ' Earth-\\nDoc, which aggregates a wealth of subsurface information from\\nresearch institutions, energy companies, service companies\\nand dedicated professionals. The 70,000 scientific publications\\nfocus on conventional topics within geoscience and engineering')\n",
      "(83, 3, 8, '\\nespecially in relation to oil and gas extraction. This subsurface\\ninformation can be upcycled to provide highly valuable insights\\nfor new energy technologies. The reuse of existing oil and\\ngas data reduces data acquisition costs, which translate into a\\nr')\n",
      "(84, 3, 9, 'eduction in research and development costs.\\n\\nThrough a collaboration between Iraya Energies and EAGE, a\\nnew database initiative has been launched with EarthDoc’s repos-\\nitory of 70,000 scientific publications being processed using the\\nlatest in machine le')\n",
      "(85, 3, 10, 'arning and artificial intelligence techniques\\nand initially available to institutional and corporate subscribers.\\nThe whole data corpus is made instantly accessible and provides\\nnew tools to search and retrieve the diversity of information that\\none is loo')\n",
      "(86, 3, 11, 'king for across any technical discipline.\\n\\n‘raya Energies\\n* Corresponding author, E-mail: nmh@irayaenergies.com\\nDOI: 10.3997/1365-2397.fb2021045\\n\\nWith Big Data analytics applied to the entire data corpus of\\n70,000 scientific publications, additional in-de')\n",
      "(87, 3, 12, 'pth and advanced\\nnavigation options are now available.\\n\\nTo extract information on a large scale, the ElasticDocs AI\\npipeline is applied to the EarthDoc corpus. This pipeline consists\\nof a set of algorithms which are used to identify blocks/segments\\nwithin')\n",
      "(88, 3, 13, ' the document corpus. Optical Character Recognition\\n(OCR) is applied to the text segments to convert them into\\nprocessable text. A Deep Convolutional Neural Network (DCNN)\\nalgorithm pipeline classifies the images into various generic and\\ngeological image ')\n",
      "(89, 3, 14, 'classes, including tables, seismic, map, well\\nplots, stratigraphic charts, core, thin sections, image logs, and\\nrose diagrams. Untagged images are generically categorized as\\nfigures and remain accessible to the user.\\n\\nThe ingested documents are now availa')\n",
      "(90, 3, 15, 'ble as structured\\ninformation for analysis, which is possible in different ways:\\n\\n+ Metadata extraction of relevant information such as locations,\\n\\nnames etc.\\n\\nEfficient inter and intra-search of the global text corpus for\\n\\nquantitative textual analysis o')\n",
      "(91, 3, 16, 'f document contents to create\\n\\nautomated and standardized geoscience or engineering content\\n\\nsummary.\\n\\nAutomated heatmaps to visualize density of information\\n\\nwithin a basin or country.\\n\\n+ Image extraction of similar image classes for efficient identifi-\\n')\n",
      "(92, 3, 17, 'cation of analogues, duplicates and clusters.\\n\\n.\\n\\n.\\n\\nSome key functionality that has a significant impact on utilizing\\nthe scientific publications is that not only are images classified\\naccording to type, but it is possible to do a search on image\\nembedde')\n",
      "(93, 3, 18, 'd text making the search capabilities far more advanced\\nthan just a normal search-and-find option. The search results of\\nthis database are exportable as .csv files making statistical work\\nand analysis instantly possible across data points.\\n\\nProprietary co')\n",
      "(94, 3, 19, 'rporate data meets published\\nscientific knowledge.\\n\\nRecognizing that energy companies hold valuable information in\\ntheir repositories accumulated throughout many decades of oper-\\nations, the data kept internally can now be easily integrated with\\npublished')\n",
      "(95, 3, 20, ' geoscience and engineering data. The combination of\\n\\n\\nmp (219 Source Tray allows access of mulaple databases\\nincluding public data, infsrinaton.\\nand CarthDor public ations\\na search Revorts .\\neantenee | SD\\nsce rs e-\\ninal_Well_maport pas\\nance, ver\\nSrewtuae')\n",
      "(96, 3, 21, ' ore) =”\\n\\nFinal Well_Report_Basic_Vol_2_of 2. 10003551.pdt\\nlit tr tain WE fewer Energy Py Li ve: Grommets Cyt Mo: ACH\\n{auras transfered na AES7ae masetvePreusute:2047-20R3 Pal RoRAOd Py\\n\\n$90-10807 sampling Deptt: 1\\nFinal_Well_Report_Basic_vol_2_of_2_10003')\n",
      "(97, 3, 22, '551.pdt on sou\\n{cbene Ker Mone Shek AuNEEnecRy Py Lid Hel 1-1 cxtma Naz Re\\n\\netoe transfered 1 ACS 1423-09 N {2047-2089 pea Bevereie\\n“Terperrtue: WO“89°7 Sampling Oeoe: 1378\\n\\nMAP\\n\\nKNOWLEDGE GRAPH\\n\\nFigure 1 Data source tray in the new database allows\\naccess')\n",
      "(98, 3, 23, ' to multiple databases, including, but not\\nlimited to, public data, proprietary data, and EarthDoc\\ncorpus. Reference: Geoscience Australia, NOPIMS.\\n\\nFigure 2 Earth readability tools are available in the\\nnew database dashboard (Rahim ef al., 2012).\\n\\n1a Fib')\n",
      "(99, 3, 24, \"er Opte Technology for Reservar Surveillance,\\n\\nOperational Excellence in Qatar's Fist Successful\\n©, Finas Opt Sensing for enproved Welbore\\nInwgroie Approaen to Opemize Moral teeeoane= nnn\\n\\nEngmaenng Success mts Wireine Operations i.\\n\\n© Dew Ineetigert Comp\")\n",
      "(100, 3, 25, 'letion Well Design For.\\n\\n(@ Massive nydraube Fracture Semulanon wn South,\\n\\n(2 Integrated Ave.\\n\\noo\\n\\n(© Stratigraphic Architecture ofthe Latest Jowassic\\n\\n(© fatural Fracture interaction with Hydraulic G2ESHEEE Jucassic bo Earty Barren an Parken\\n\\n© Breaking ')\n",
      "(101, 3, 26, 'On Recovery Lanet m Malaysian.\\n\\ndatabase results in a two-way enrichment process between public\\nand private information. Scientific studies from peers in related\\nfields offer additional information that either validates internal\\ncompany studies, or offer ')\n",
      "(102, 3, 27, 'alternative technical perspectives from\\nindustry experts.\\n\\nIn the Figure 1 example above, we show how exploring\\ntemperature information available in a Final Well Reports repos-\\nitory that is commonly considered as proprietary corporate data,\\nis combined w')\n",
      "(103, 3, 28, 'ith published EarthDoc contents. (Data source:\\nNOPIMS)\\n\\n@ Pugtications Figure 3 Visualization of knowledge graph illustrates\\n\\nrelated geological and engineering concepts.\\n\\nSeveral Earth readability tools are deployed in ED2K to\\namplify EarthDoc capabiliti')\n",
      "(104, 3, 29, 'es. This includes access to digital\\ntextual content, the ability to quality control OCR results and\\nread in multiple languages via machine-translate. Word clouds are\\nsimple context clues which provide a quick summary of content\\nof the articles.\\n\\nThe full ')\n",
      "(105, 3, 30, 'ED2K corpus is geotagged to more than 800\\ngeological basins around the world. The geotagging is one of the\\nmost complex machine learning tasks in this implementation,\\nbecause the scientific articles contain both location of the\\n\\n\\ngeological area of intere')\n",
      "(106, 3, 31, 'st, as well as the location of confer-\\nences where the publications are presented. Often, these two\\nreference locations are different and introduce ambiguity for the\\nsystem.\\n\\nAnother feature that is implemented is the knowledge graph\\nvisualization. It ill')\n",
      "(107, 3, 32, 'ustrates the connectivity of ‘related concepts’\\nbased on publication references. In the example above, it shows\\n‘operational excellence’, ‘optimization’ and ‘engineering suc-\\ncess’ within the same network (Figure 3). Similarly, ‘hydraulic\\nfracture stimula')\n",
      "(108, 3, 33, 'tion’, ‘natural fracture interaction’, and ‘Jurassic\\ncarbonates’ show connectivity. In theory, a knowledge graph can\\nbe built in multiple ways by the user.\\n\\nUtilizing ED2K to reach the zero-emission goal\\n\\nThe advanced access in the new database makes poss')\n",
      "(109, 3, 34, 'ible a new\\nuse of the highly valuable subsurface information and facilitates\\ncross-discipline usage.\\n\\nMany of the new cross-function usages of the existing\\nscientific publication repository are geothermal energy, hydrogen.\\nenergy, CCS and windmill foundat')\n",
      "(110, 3, 35, 'ion derisking.\\n\\nA query for ‘carbon capture and storage’ generates an\\ninformation heat map captured in Figure 4. The map shows the\\ngeographical distribution of the resulting publications either\\nbased on country or basin.\\n\\nFigure 5 maps out the major carbo')\n",
      "(111, 3, 36, 'n capture projects around\\nthe world vis-a-vis needs requirement. Europe and US show high\\nactivity in CCS initiatives, which are driven by government poli-\\ncy. Comparing Figure 4 and Figure 5 (left), it may be incidental,\\nalthough not entirely surprising t')\n",
      "(112, 3, 37, 'hat where there is a significant\\namount of data to aid technical and management decision mak-\\ning, CCS implementations are also active.\\n\\nMAP KNOWLEDGE GRAPH\\n\\nResults Density\\n\\ncountries @\\n\\nThe new database contains climate change and greenhouse\\ngases indus')\n",
      "(113, 3, 38, 'try discussion materials spanning over three decades.\\nAlready between 1990 and 2000, the possibility of disposing\\ncarbon dioxide (CO,) is discussed in papers such as J. Leeb. W,\\n(1993), and Wildenborg, F.B., et. al., (1996), in conjunction with\\nthe use of')\n",
      "(114, 3, 39, ' CO, for improved oil recovery methods (IOR).\\n\\nBetween 2001 and 2010, the discussions tackled issues in\\nestablishing a geological storage hub (Espie, 2000) and various\\npotential site feasibility studies (Gregersen et. al, 2000), costs\\n(Wildenborg et. al, ')\n",
      "(115, 3, 40, '2000), use of seismic monitoring (Benson,\\n2003), (Gosselet et. al., 2006), pilot and numerical simulations\\n(Domitrovie et. al., 2005), (Battistelli et.al, 2005), reservoir\\nperformance (Broad et.al, 2007) and improving facilities perfor-\\nmance to reduce op')\n",
      "(116, 3, 41, 'erating costs in CO, and H,S contaminated\\nfields (Swatton et. al, 2009).\\n\\nFrom 2011 up to the present, with the advancements in\\nseismic methods, reservoir modelling techniques and laboratory\\nexperiments (Bolourinejad, 2013} many more complex analyses\\non t')\n",
      "(117, 3, 42, 'he subject of carbon storage were performed. Combined with\\nenhanced oil recovery experiments (EOR), the amount of data\\nmodelling CO, behavior underground has multiplied ten-fold,\\n\\nIn areas where it is not possible to implement subsurface\\ncarbon capture, u')\n",
      "(118, 3, 43, 'tilization strategies are discussed by Harsh, A.\\net. al (2014) on the industrial usage of CO, including, but not\\nlimited to, polymer processing and chemicals production.\\n\\nFor a deeper dive in the corpus, we draw an arbitrary areal\\npolygon, indicated by th')\n",
      "(119, 3, 44, 'e yellow box in Figure 5, around South\\nEast Asia. Our new database reveals some of the strategies\\nthat have been identified by an operator to manage greenhouse\\nemissions in its operations in Malaysia (Mehta et.al.,2008).\\nThis includes, among others, endin')\n",
      "(120, 3, 45, 'g continuous gas flaring\\n\\nFigure 4 Indicative geolocation of global knowledge\\nabout ‘carbon capture and storage’ between 2008\\nfo 2020.\\n\\nFigure 5 Location of major carbon capture projects\\naround the world (left) and the requirement index\\nbased on fossil fu')\n",
      "(121, 3, 46, 'el production and consumption\\n(right). Reference: Global CCS Institute.\\n\\n\\nand minimizing gas venting, improving energy efficiency in\\nthe design of assets and production operations, accounting for\\nthe cost of emitting greenhouse gases in investment decisio')\n",
      "(122, 3, 47, 'ns,\\nsupporting development of CCS infrastructures, and policy\\nadvocacy.\\n\\nThe rich diversity of data available in the new database\\nare illustrated in Figures 6 and 7. These include graphical\\ninformation of PVT analyses, miscibility, flow rates, and time-\\nl')\n",
      "(123, 3, 48, 'apse pressure profiles, which are useful for reservoir simulation\\nstudies focused on the interaction of reservoir rocks with CO,\\nduring injection. Also available are petrography data that makes\\nit easier to interpret reservoir modelling results by being a')\n",
      "(124, 3, 49, 'ble\\nto look at the structural fabric of the storage rocks down to\\nmicroscopic levels.\\n\\nNew energy from old data\\nWith this data-driven strategy it will be possible to facilitate the\\npivot to new energy from valuable existing data. No part of the\\ndata is le')\n",
      "(125, 3, 50, 'ft unprocessed. It may be that not all relevant informa-\\ntion will exist within the 70,000 scientific publications, but this\\ncan be confirmed instantly saving valuable time and resources\\ndoing data exploration. On the other hand, if the information is\\nava')\n",
      "(126, 3, 51, 'ilable, it will be immediately accessible, trackable and put\\ninto context with other relevant information and geographically.\\nFor example, the geothermal gradient is a key parameter of\\ninterest in relation to geothermal energy. The temperature data in\\n\\nGH')\n",
      "(127, 3, 52, 'EE = © 0 wo mmo we\\n\\nthe new database has been acquired by energy companies mostly\\nfor the purpose of understanding the hydrocarbon generation\\nwindow, petrophysical interpretation and reservoir modelling\\nanalyses. They can be relooked at for further explor')\n",
      "(128, 3, 53, 'atory geo-\\nthermal applications. It currently excludes temperature data from\\ngeothermal companies.\\n\\nWe are barely scratching the surface on the data and insights\\navailable — multiple data stories are waiting to be reimagined,\\nreconnected and retold in the')\n",
      "(129, 3, 54, ' context of the future of energy.\\n\\nAccelerating internal digitalization initiatives\\n\\nAll the elements of the new database are stored and structured\\nin a digital data warehouse. They will be optionally available\\nas an API link to be used for additional geo')\n",
      "(130, 3, 55, 'logical analysis,\\ndata analytics, or machine learning experimentations. Already\\nin structured format, they can be fed into additional natural lan-\\nguage processing or image segmentation processing for in-house\\nexperimentation.\\n\\nOpportunity for the energy ')\n",
      "(131, 3, 56, 'geoscientists and\\nengineers of the future\\n\\nWhile the energy industry has faced significant headwinds, it is\\nnow moving faster than ever towards new, cleaner energy pro-\\nduction. It is possible to see that multiple opportunities remain,\\nas already pointed ')\n",
      "(132, 3, 57, 'out by Raistrick (2008), and remain relevant in\\n2021, for the geoscientists and engineers who are looking at the\\n\\nFigure 6 Experimental engineering data of CO,\\nbehaviours in enhanced oil recovery operations of\\nmature fields can be transferable to carbon s')\n",
      "(133, 3, 58, 'torage\\ndesign and monitoring.\\n\\nser tach ES S| | | | | | | Figure 7 Combination of carbonate petrography data\\n\\nand information extracted from well reports.\\n\\n\\nResults Density\\n\\nFigure 8 Locations of relatively *high geothermal gradient areas’ based on existi')\n",
      "(134, 3, 59, 'ng\\ncorpus, data acquired by oil and gas companies. Data excludes information from\\ngeothermal companies.\\n\\nFigure 9 Compiled graphical temperature information filtered by country, basin or\\nan arbitrary polygon location. Reference: Geoscience Australia, NOPI')\n",
      "(135, 3, 60, 'MS.\\n\\nfuture of energy. Strong, flexible technical skills will be needed\\nto explore for suitable carbon capture facilities, assess their\\nstorage, containment and injectivity capacities. Meanwhile, the\\nnew energy industry will continue to gather, integrate ')\n",
      "(136, 3, 61, 'and analyse\\nempirical data, whether it is on the reservoir, sub-surface or at\\nhydrocarbon or future hydrogen production facilities.\\n\\nWe have already seen a lot of data. It is up to us to use the\\nright tools to read the earth better, and get a head start t')\n",
      "(137, 3, 62, 'owards\\nnew energy.\\n\\nReferences\\n\\nGlobal CCS Institute (https://www.globalcesinstitute.com). CCS Facil-\\nities Database (https://co2re.co/) Geoscience Australia, NOPIMS\\n(http://www.ga.gov.au/nopims).\\n\\nBolourinejad, P. and Herber, R. [2013]. Experimental and ')\n",
      "(138, 3, 63, 'Modeling Study\\nof Salt Precipitation during Injection of CO2 Contaminated with H2S\\ninto Depleted Gas Fields in Northeast Netherlands - (SPE-164932),\\n75th EAGE Conference & Exhibition incorporating SPE EUROPEC\\n2013, London, UK.\\n\\nBattistelli, A., Giorgis, T')\n",
      "(139, 3, 64, '. and Marzorati, D. [2005]. Modeling Halite Pre-\\ncipitation around CO2 Injection Wells in Depleted Gas Reservoirs,\\n67th EAGE Conference & Exhibition, Madrid, Spain.\\n\\nBroad, J., Ab Majid, M.N., Ariffin, T., Hussain, A. and Basher, A.B.\\n[2007]. Deposition o')\n",
      "(140, 3, 65, 'f “Asphaltenes” during CO2 Injection and\\nImplications for EOS Description and Reservoir Performance, IPTC\\n2007: Intemational Petroleum Technology Conference, Dubai, Unit-\\ned Arab Emirates.\\n\\nDomitrovic, D., Tuschl, M. and Sunjerga, S. [2005]. CO2 Pilot Inj')\n",
      "(141, 3, 66, 'ection\\nat Ivanic Oil Field — Numerical Simulation, IOR 2005 - 13th Euro-\\npean Symposium on Improved Oil Recovery, Budapest, Hungary.\\n\\nGosselet, A.C. and Singh, S. [2006]. Elastic Full Waveform Inversion\\nfor CO2 Sequestration monitoring - 1D Synthetic Data')\n",
      "(142, 3, 67, ' Investiga-\\ntions,68th EAGE Conference and Exhibition incorporating SPE\\nEUROPEC 2006\\n\\nGregersen, U.N., Johannessen, P., Kirby, G., Chadwick, A. and Holloway,\\nS. [2000]. Regional Study of the Neogene Deposits in the Southem.\\nViking Graben Area - a Site for')\n",
      "(143, 3, 68, ' Potential CO2 Storage,62nd EAGE\\nConference and Exhibition - Special Session on CO2, Glasgow, UK.\\n\\nHarsh, A.H. and Anne, V.A. [2014]. Carbon Dioxide Capture, Utilization.\\nand Storage (CCUS),76th EAGE Conference and Exhibition 2014,\\nAmsterdam, Netherlands.')\n",
      "(144, 3, 69, '\\n\\nLeeb, W. [1993]. Case study of CO2 disposal in aquifers - A solution\\nto reduce the greenhouse effect, 55th EAEG Meeting, Stavanger,\\nNorway.\\n\\nMehta, A., Hj-Kip, S. and Foo, J. [2008]. Managing Greenhouse Gas\\nEmissions in Upstream Operations in a Carbon-C')\n",
      "(145, 3, 70, 'onstrained World,\\nIPTC 2008: International Petroleum Technology Conference, Kuala\\nLumpur, Malaysia\\n\\nRahim, M., Azran, A., Press, D., Lee, K.H., Phuat, C.T., Anis, L.,\\nDanman, N. and Othman, M. [2012]. An Integrated Reservoir Sim-\\nulation-Geomechanical Stu')\n",
      "(146, 3, 71, 'dy on Feasibility of CO2 Storage in M4\\nCarbonate Reservoir, Malaysia, IPTC 2012: International Petroleum\\nTechnology Conference, Bangkok, Thailand.\\n\\nRaistrick, M. [2008]. Carbon capture and storage projects to challenge\\ngovernments, scientists, and enginee')\n",
      "(147, 3, 72, 'rs, First Break.\\n\\nWildenborg, A.N., Breunese, J.G.H.and van der Meer L, [1996]. Potential\\nof CO2-disposal in deep reservoirs and aquifers of the Nether-\\nlands,58th EAGE Conference and Exhibition, Netherlands.\\n\\nWildenborg, A., Floris, F.D., van Wees, J. an')\n",
      "(148, 3, 73, 'd Hendriks, C. [2000].\\nCosts of CO2 Sequestration by Underground Storage,62nd EAGE\\nConference and Exhibition - Special Session on CO2, Glasgow,\\nUK,\\n\\nSwatton, M.J.R., van Soest-Vercammen, E. and Klein Nagelvoort, R.\\n[2009]. Innovation and Integration in LN')\n",
      "(149, 3, 74, 'G Technology Solutions,\\nIPTC 2009: International Petroleum Technology Conference, Doha,\\nQatar.\\n\\n')\n",
      "(150, 4, 1, \"\\nAmes MS Ree\\n\\nPtah\\n7 MADRID | SPAIN\\n\\nSCALING AND OPTIMIZING PERFORMANCE AND COST OF MACHINE\\nLEARNING INGESTION ON UNSTRUCTURED DATA FOR\\n\\nSUBSURFACE APPLICATIONS\\n\\nL.C.I. Panganiban!, F. Baillard!, N.M. Hernandez!\\n\\n' Traya Energies\\n\\nSummary\\n\\nIn recent years\")\n",
      "(151, 4, 2, ', the energy industry has shifted their attention into extracting additional values from\\ntheir in-house legacy datasets for shorter project turnaround and better decision making. Internal digital\\ntransformation initiatives and access to new technology suc')\n",
      "(152, 4, 3, 'h as cloud computing, machine learning and\\nmicroservices made it possible to shift towards a scalable ingestion platform.\\n\\nA modern scalable ingestion platform often includes 1) automated machine learning (ML) components\\narticulated around pipelines to pa')\n",
      "(153, 4, 4, 'rse and go through the data and extract the needed information 2)\\nstorage component such Database, Datawarehouse and Datalake defining what data to be stored and\\nhow.\\n\\nIn this paper, we will provide a description of these different components, their moder')\n",
      "(154, 4, 5, 'n implementation\\ninto a cloud environment using microservices and some performance benchmark based on real world\\ndata examples.\\n\\n2 ——————_— ——————\\n\\n\\nScaling and optimizing performance and cost of machine learning ingestion on unstructured\\ndata for subsurf')\n",
      "(155, 4, 6, 'ace applications\\n\\nIntroduction\\n\\nIn recent years, the energy industry has shifted their attention into extracting additional values from\\ntheir in-house legacy datasets for shorter project turnaround and better decision making. Internal digital\\ntransformati')\n",
      "(156, 4, 7, 'on initiatives and access to new technology such as cloud computing, machine learning and\\nmicroservices made it possible to shift towards a scalable ingestion platform.\\n\\nA modern scalable ingestion platform often includes 1) automated machine learning (ML')\n",
      "(157, 4, 8, ') components\\narticulated around pipelines to parse and go through the data and extract the needed information 2)\\nstorage component such Database, Datawarehouse and Datalake defining what data to be stored and\\nhow.\\n\\nIn this paper, we will provide a descrip')\n",
      "(158, 4, 9, 'tion of these different components, their modern implementation\\ninto a cloud environment using microservices and some performance benchmark based on real world\\ndata examples.\\n\\nScalable ingestion platform architecture\\n\\nThe vast majority of experimentation ')\n",
      "(159, 4, 10, 'and testing of new ML application are performed on notebooks\\non local machines leveraging on local hardware with the data and the code being stored locally-. Such\\na setup has the advantage of being lightweight allowing a fast turnaround between two ML ite')\n",
      "(160, 4, 11, 'rations.\\nHowever the lack of traceability, compatibility and hardware limitation makes it challenging to scale\\nsuch application, hence the requirement of a more scalable solution.\\n\\nIn comparison, a scalable ingestion platform is a type of system native ab')\n",
      "(161, 4, 12, 'le to handle current and future\\nworkloads regardless of the amount of data ingested or users connecting to it, considering both scaling\\nin (shrinking resources) and scaling out (expanding resources). An example of such system can be seen\\non Figure 1. The ')\n",
      "(162, 4, 13, 'architecture is made of of four components namely pipeline, storage, compute and\\ninterfaces.\\n\\nWTERFACES,\\nData Atelier\\n\\nCOMPUTE\\n\\nLLASTICOOCS\\n\\n$\\niv)\\ni\\no\\n=\\na\\n<\\n\\nFigure 1: Ingestion Platform Architecture\\n\\nPipeline or data pipeline is the main driver in extrac')\n",
      "(163, 4, 14, 'ting and transforming data into a unified format.\\nThe typical ingestion workflow is based on an Extract-Transform-Load process with machine learning\\nworkflows able to accommodate the variety in sources and forms present in unstructured data\\n(Hernandez et ')\n",
      "(164, 4, 15, 'al., 2019).\\n\\na ————_— ——————\\n\\n\\nttt te ch\\n7 MADRID | SPAIN\\n\\nThe storage component is where the data resides. Storage is often the least thought about in development\\nand architecture strategies, but it is one of the core contributors in terms of cost to the')\n",
      "(165, 4, 16, ' organization. The\\ncompute node component schedules and orchestrates the data pipelines, logic flows, and algorithms.\\nThe interface or the dashboard component provides the monitoring and observability capabilities. This\\npresents the events, statuses, logs')\n",
      "(166, 4, 17, ', and other operational insights that can be used for decision making.\\nThese components have different ways to be scaled depending of 1) the environment of installation: on-\\npremise vs. cloud 2) the volume and type of data being processed 3) the early dev')\n",
      "(167, 4, 18, 'elopment decision: all\\nout of the box cloud providers solution, opensource self maintained solution or hybrid.\\n\\nComponent’s optimization\\n\\nThe first metrics to consider for optimization is processing time and should be independent from the\\nvolume of data t')\n",
      "(168, 4, 19, 'o be processed by the pipeline. This optimization is achieved through parallelization,\\ndistributed computing and orchestration by scaling up or down the usage based on demand. Applications\\nand data pipelines are packaged into containers and then deployed ')\n",
      "(169, 4, 20, 'into a Kubernetes cluster in which it\\nhandles the scheduling, distribution, and allocation across different machines. Workflow managers (\\nWM) provide the platform to execute and orchestrate the jobs and tasks that are contained in a Pod/Pool\\n(Figure 2). W')\n",
      "(170, 4, 21, 'orkflow managers also implement orchestration and scheduling though it handles the tasks\\nin the application layer where this determines if the data execution is successful or not.\\n\\nFiles\\n\\nThe second metric to consider is the extensibility metric. A single')\n",
      "(171, 4, 22, ' service or component can be used\\nbeyond what is originally intended. Thanks to the microservices, exposing your data via application\\nprogramming interfaces or APIs is a good practise (Figure 3). It provides a common language across\\nteams where implementa')\n",
      "(172, 4, 23, 'tion is unified across different data sources. An additional advantage of the use\\nof APIs is the additional level of abstraction for the storage of the data. Data are now accessible from\\nvarious mounting locations through a single call, allowing democrati')\n",
      "(173, 4, 24, 'zation and versioning of the data.\\n\\nAPI LINK:\\n\\nAPTUNK\\n\\nAPILUNK\\n\\na ————_— ——————\\n\\n\\n|\\nFigure 3: Connecting applications using API links\\n\\nAs an example, a full-text search endpoint originally used to do searches, can also be used to create\\naggregations model')\n",
      "(174, 4, 25, 's like heatmap and knowledge graphs (Baillard et Al., 2021) as seen on Figure 4.\\n\\nroy @ wees\\n\\nFigure 4: Heatmap (left) and Knowledge Graph (right)\\n\\nThe third metric to consider is the UI/UX responsivness and define the optimal data representation for\\nthe ')\n",
      "(175, 4, 26, 'user or the operator to QC the data and for the service to have still an acceptable response time. As\\nseen on Figure 4, the heat map and the knowledge graph are built on-top of 100,000 data points\\n(Mamador et al., 2021). Interface and visualization scalin')\n",
      "(176, 4, 27, 'g requires removing the dependency on the\\nvolume of data points. The amount of time visualizing 100 points should be the same as visualizing\\n100,000 points — in which development of aggregation and interpolation workflows must be performed\\nin the backend ')\n",
      "(177, 4, 28, 'and frontend to overcome this volume challenge.\\n\\nBenchmarks and testing\\n\\nTo see the performance of this architecture we can consider the following data. We have 3 buckets of\\ndata for this assessment. It is composed of geoscience documents that ranges from')\n",
      "(178, 4, 29, ' final well reports,\\ngeological report, regional studies, interpretations coming from various file formats, countries, and\\nlanguages. The data also includes images like thin sections, core, well logs, seismic. All these data are\\naudited and stored into an')\n",
      "(179, 4, 30, ' object storage.\\n\\nThe following are the system that was used for this assessment:\\nBase case: 1-node with 4 cores and 16 GB of RAM from cloud provider without WM\\n© Optimized case: 5-nodes with 4 cores and 16 GB of RAM per node from cloud provider with WM\\n\\n')\n",
      "(180, 4, 31, 'Bucket | Number | Duration Failure Duration | Failure | Language Region\\nof Pages (hours) Rate % (hours) Rate %\\nSingle node (Single Cluster (Cluster)\\nNode)\\n\\n1 4,403 18 15 4 5 Mixed Europe\\n2 40,565 170.25 11 38.5 0.5 English Oceania\\n\\n3 62,531 250 12 60 0.01')\n",
      "(181, 4, 32, ' Mixed South\\nAmerica\\n\\nTable 1: Extraction Performance with 4-cores and 16 GB of RAM per node\\n\\nTable 1 shows the extraction performance. The extraction workload encompasses the data loading,\\nprocessing, and uploading. It was tested on a variety of datasets')\n",
      "(182, 4, 33, ' from different regions and languages.\\nFor a single node execution, the average number of pages per hour is around 244 pages and for a 5-node\\ncluster, the average number of pages per hour is 1000. Since workflow manager provide an auto-retry\\n\\na ————_— ———')\n",
      "(183, 4, 34, '———\\n\\n\\nttt te ch\\n7 MADRID | SPAIN\\n\\nfunction, this reduces the failure rate by a significant amount. This is due to tasks that are failing due to\\nnetwork or infrastructure issues to be retried or re-executed. The failure rate is now mostly on the data\\nsince')\n",
      "(184, 4, 35, ' we haveve removed the infrastructure constraint.\\n\\nAs one of the metrics that we have set earlier, we need to consider the cost and infrastructure usage.\\nUsing the same workloads, we can assess the cost and infrastructure optimization in Table 2.\\n\\nBucket ')\n",
      "(185, 4, 36, 'Number of % Hardware % Hardware\\nPages usage Avg. usage - Avg.\\nSingle node Cluster\\n1 4,403 42% 84%\\n2 40,565 40% 83%\\n3 62,531 41% 83%\\n\\nTable 2: Extraction Infrastructure Utilization with 4-cores and 16GB of RAM\\n\\nTable 2 shows that we have a higher utilizati')\n",
      "(186, 4, 37, 'on in the cluster hence we are fully utilizing the server. In\\nthe case of single node, only 41% of the resources is utilized vs 83% in the cluster approach. Both the\\nreduced failure rates and the hardware utilization illustratres the gain of efficency in ')\n",
      "(187, 4, 38, 'deploying a scalable\\ningestion platform\\n\\nConclusions\\n\\nIn this paper, we have seen how to scale and optimize the ML ingestion pipeline for subsurface\\napplications. We have shown that scaling and optimizing ML ingestion pipelines can lead to\\nimprovements in')\n",
      "(188, 4, 39, ' terms of time and cost. We have also demonstrated that the ingestion platform is\\nscalable to handle data from a variety of regions and languages. Finally, we’ve seen the power of scaling\\nvisualizations and exposing the data via API links in which we can ')\n",
      "(189, 4, 40, 'get more insight and enhance the\\nability of the team to extract knowledge.\\n\\nReferences\\n\\nBaillard F. and Hernandez N.: A Case Study of Understanding Bonaparte Basin using Unstructured\\nData Analysis with Machine Learning Techniques. 82nd EAGE Conference & E')\n",
      "(190, 4, 41, 'xhibition, 18-21\\nOctober 2021, Amsterdam.\\n\\nMamador C., Hernandez N., Baillard F.: Production-scale processing of EAGE’s EarthDoc data\\nto stimulate new insights in CO2 and new energy management. 82nd EAGE Conference &\\nExhibition worskhop on ML solutions at')\n",
      "(191, 4, 42, ' scale, 22 October 2021, Amsterdam.\\n\\nHernandez N., Lucaiias P., Graciosa J.C., Mamador C., and Panganiban L. C. I., 2019: Automated\\n\\ninformation retrieval from unstructured documents utilizing a sequence of smart machine learning\\n\\nmethods within a hybrid ')\n",
      "(192, 4, 43, 'cloud container. EAGE Workshop on Big Data and Machine Leaming for\\nE&P Efficiency 25 - 27 February.\\n\\na ————_— ——————\\n\\n')\n",
      "(193, 5, 1, \"\\nAPGCE /stescitnce\\n\\nKalaa Premier Geestiance Event’\\n\\n169\\n\\nT. Looi!, N.E. Arif’, N.M. Hernandez}, F. Baillard?\\n\\n' Traya Energies\\n\\nSummary\\n\\nIn the upstream oil and gas sector, the processes of data mining, which involves searching, extracting, and\\nvalidatin\")\n",
      "(194, 5, 2, 'g information that sits within the technical documents, reports, presentations, and studies to understand\\nexploration history and geological parameters are often challenging and requires vast resources to be completed.\\nYet, many geological information tha')\n",
      "(195, 5, 3, 't have already been mined, are stored in spreadsheets or niche databases,\\nthat limits their abilities to be recycled for multiple uses within the organization. Basin information such as\\nformation pressure, formation temperature, fracture pressure, drillin')\n",
      "(196, 5, 4, 'g rate of penetration, total organic carbon\\n(TOC) and lithologies are some of the typical parameters that are crucial to understand the basin scale geology,\\nreservoir properties and identify opportunities within the area of interest and often needed to pe')\n",
      "(197, 5, 5, 'rform in depth\\nworkflows, such as seismic reservoir characterization, basin modelling and geomechanical studies, which cover\\nmultiple cycles of exploration, development and site development of future carbon waste disposals. The research\\ndemonstrates the a')\n",
      "(198, 5, 6, 'pplication of AI/ML technologies coupled with interactive data visualization and API\\nconnectivity, that can significantly accelerate the extraction of knowledge that are sitting inside the reports and\\nensure sustainability in data mining activities.\\n\\nAPGC')\n",
      "(199, 5, 7, 'E 2022\\nKuala Lumpur, Malaysia | 28 — 29 November 2022\\n\\n\\nAPGCE) aiid\\n\\nKelana Premier @\\n\\nIntroduction\\n\\nIn the upstream oil and gas sector, the processes of data mining, which involves searching, extracting,\\nand validating information that sits within the te')\n",
      "(200, 5, 8, 'chnical documents, reports, presentations, and studies\\nto understand exploration history and geological parameters are often challenging and requires vast\\nresources to be completed. Yet, many geological information that have already been mined, are stored')\n",
      "(201, 5, 9, '\\nin spreadsheets or niche databases, that limits their abilities to be recycled for multiple uses within the\\norganization. Basin information such as formation pressure, formation temperature, fracture pressure,\\ndrilling rate of penetration, total organic ')\n",
      "(202, 5, 10, 'carbon (TOC) and lithologies are some of the typical\\nparameters that are crucial to understand the basin scale geology, reservoir properties and identify\\nopportunities within the area of interest and often needed to perform in depth workflows, such as\\nsei')\n",
      "(203, 5, 11, 'smic reservoir characterization, basin modelling and geomechanical studies, which cover multiple\\ncycles of exploration, development and site development of future carbon waste disposals.\\n\\nIn this paper, we are going to demonstrate on how we can improve on')\n",
      "(204, 5, 12, ' the traditional data mining\\nworkflows and enhance data sustainability by focusing process improvement on three areas: a.)\\naccelerating the speed of geoscience parameter extraction by Artificial Intelligence/ Machine learning\\n(AI/ML) techniques, b.) incre')\n",
      "(205, 5, 13, 'ase data readability and integrity by effective visualization of both\\nsource and output data, and c.) promote data reusability by enabling API access to extracted data.\\n\\nMethodology\\n\\nThe advancement in ML and AI with the support of advancement in cloud co')\n",
      "(206, 5, 14, 'mputing has made a\\nsignificant impact to the traditional data mining workflows. However, AI/ML workflows are typically\\nfocused only on the data extraction phase as a one-time effort, whereas an effective data mining\\nstrategy should also ensure data sustai')\n",
      "(207, 5, 15, 'nability, which means the ability to visualize the data to identify\\ntrends and patterns easily, and pass that high-integrity extracted information intact to multiple type of\\nusers within the organization.\\n\\nA sustainable data mining strategy is proposed to')\n",
      "(208, 5, 16, ' accelerate extraction with an automated pipeline\\nusing Machine Learning techniques such as Natural Language Processing (NLP) or Deep\\nConvolutional Neural Network (DCNN) ingests all the unstructured data (Hernandez et al., 2019) in\\nsteps 1 to 3, followed ')\n",
      "(209, 5, 17, 'by human-in-the loop quality control, visualization and data trackability and\\nconnectivity in steps 4 and 5. (Figure 1):\\n\\n1. A vast amount of unstructured data such as final well report, technical reports, working files\\nthat varies from pdf, .docx., xlsx,')\n",
      "(210, 5, 18, ' .csv jpg, .png and .tif are used as the main source of\\ninformation and feed into the production ready ML pipelines for audit, duplicates, and version\\ndetections.\\n\\n2. The unstructured data ingestion starts with the digitalization of data using Optical Cha')\n",
      "(211, 5, 19, 'racter\\nRecognition (OCR). Next, Deep Convolutional Neural Network (DCNN) classifies the\\nextracted images into their respective geological categories such as map, seismic,\\nstratigraphic chart, SEM, thin section, core and well logs. Simultaneously, Natural ')\n",
      "(212, 5, 20, 'Language\\nProcessing (NLP) pipeline performs automated extraction and tagging of metadata.\\n\\n3. Further analysis and knowledge extraction are available once the unstructured data is\\ningested. Data Science analytical tool such as deep search with heat map de')\n",
      "(213, 5, 21, 'nsity allows\\nadditional insights where the user can monitor the trend of a parameter regionally. In addition,\\ntables extracted from the reports are post-processed to retain the structure and extract the\\nvalues.\\n\\n4. Missing depth interpolation, units’ stan')\n",
      "(214, 5, 22, 'dardization and plotting of values on the gradient\\nisolines are part of the data validation procedures during the Human in the Loop quality\\ncontrol.\\n\\nAPGCE 2022\\nKuala Lumpur, Malaysia | 28 — 29 November 2022\\n\\n\\nAPGCE) same\\n\\n5. The last step is the discover')\n",
      "(215, 5, 23, 'y stage that allows shareable structured data among the team\\nmembers for further interpretation and insights. The final shareable structured data allows\\ndata trackability within unstructured data, data export functionality, spatial filter to confine\\nthe s')\n",
      "(216, 5, 24, 'earch to the area of interest, depth filter and outliers’ identification. The typical outputs\\nof data mining exercise are the standard excel or csv as application agnostic format. In this\\nstage, we also enabled API access to allow for easier connectivity ')\n",
      "(217, 5, 25, 'to other geoscience\\nplatforms or internally developed digital infrastructure systems.\\n\\nUnstructured Data ML/AI Pipeline and Human-in-the-Loop Quality Control\\n\\n1. Input 2. Unstructured Data Ingestion 3. Knowledge Extraction\\n\\nUnstructured Data\\n\\nOeep Convolu')\n",
      "(218, 5, 26, 'tional Neural Network (OCNN)\\n\\nOigitalization Extracted Pei]\\n‘of Date. images anil b>\\ncastle stion ng\\nMetadata entraction Cocument\\n= Sod tapeng tgs\\nos. =.=\\ncoca\\nNatural Language Processing (NLP)\\n5. Discovery 4, Human-in-the-Loop Quality Control\\n\\n‘Shareabi\\n')\n",
      "(219, 5, 27, 'goats iS eo Depth Interpolation Units Standardization Values Quality Control\\n\\n> Data teackabitity\\n191010 7 . > Pressure. kgem2 to ps!\\nOuBI0 ‘> Export data functionality 9)) Interpolation of TVDSS Ly pepth from MD to TV05S\\n> Spatial filter and piot re-comp')\n",
      "(220, 5, 28, 'utation —_— values using es Sao\\n2 > Depth Fter and pot re-computation rectional data z\\n> Depth from ft tom\\n> Outliers identification\\n\\nPlotting extracted values.\\non gradient isolines\\n\\nFigure 1 Full implemented workflow of ingestion and analysis of unstruct')\n",
      "(221, 5, 29, 'ured data using ML/AI\\n\\nWe highlight the human-in-the-loop process during the data extraction process in step 4 above, which\\nmeans there is a component of human interpretation during the geoscience parameter extraction\\nprocess. Since there could be conflic')\n",
      "(222, 5, 30, 'ting understanding on what is considered right or relevant data at\\nthe time the extraction was done, it is important to keep the sources of information intact, so these can\\nbe reviewed and updated when new additional data is available and the geological u')\n",
      "(223, 5, 31, 'nderstanding of\\nthe basin of interest has evolved. The two additional steps introduced in the data mining process\\nincreases data integrity.\\n\\nResults\\n\\nIn this study, unstructured data from over 500 oil and gas wells are processed on a regional scale this\\ni')\n",
      "(224, 5, 32, 'ncludes a total of 300,000 pages and 140,000 images. Six geological parameters, formation pressure,\\nformation temperature, fracture pressure, drilling rate of penetration, total organic carbon (TOC) and\\nlithologies were efficiently extracted, aggregated, ')\n",
      "(225, 5, 33, 'validated, and finally visualized on scatter plots and\\npie charts. The output from the case study shows notable knowledge analysis (Figure 2) that provides\\ninsights on the regional consistency and information distribution of the area of interest and can b')\n",
      "(226, 5, 34, 'e\\nused as input into petroleum system modelling, reservoir characterization, idle wells review,\\ngeomechanical studies or potential carbon storage studies.\\n\\nAPGCE 2022\\nKuala Lumpur, Malaysia | 28 — 29 November 2022\\n\\n\\n\\nEEPEGE EER EE\\n\\nPEEUREEDGHR\\nBEGET EB\\n\\nF')\n",
      "(227, 5, 35, 'igure 2 Lithological pie chart distribution (left) and scatter plots of total organic carbon (TOC),\\nrate of penetration (ROP), formation temperature, fracture pressure and formation pressure (right)\\n\\nConclusions\\n\\nThe research demonstrates the application ')\n",
      "(228, 5, 36, 'of AI/ML technologies coupled with interactive data\\nvisualization and API connectivity, that can significantly accelerate the extraction of knowledge that\\nare sitting inside the reports and ensure sustainability in data mining activities. In the case stud')\n",
      "(229, 5, 37, 'y, we\\nhave presented a workflow on how six (6) geological parameters from over 500 wells were\\nsuccessfully extracted from unstructured data using ML and AI pipelines that can be used by multi-\\nfaceted subsurface teams for more in-depth analysis within the')\n",
      "(230, 5, 38, ' area, resulting to the upcycling of\\ngeological data across the full life cycle of a basin.\\n\\nReferences\\n\\nHernandez, N. M., Lucajfias, P. J., Mamador, C., & Panganiban, L. [2019]. Automated Information\\nRetrieval from Unstructured Documents Utilizing a Sequ')\n",
      "(231, 5, 39, 'ence of Smart Machine Learning Methods\\nwithin a Hybrid Cloud Container. EAGE Workshop on Big Data and Machine Learning for E&P\\nEfficiency 25-27 February.\\n\\nMamador, C., Aranda, J. O., Arif, N. E., Hernandez, N. M., & Baillard, F. [2020]. A Geological\\nRegio')\n",
      "(232, 5, 40, 'nal Case Study for Pressure, Temperature, and Salinity for the GoM using Machine Learning\\nTechnology on Unstructured Data. AAPG Digital Subsurface for Asia Pacific Conference. Kuala\\nLumpur, Malaysia.\\n\\nAPGCE 2022\\nKuala Lumpur, Malaysia | 28 — 29 November 2')\n",
      "(233, 5, 41, '022\\n\\n')\n",
      "(234, 6, 1, '\\n—_—ae eee\\n\\nUtilizing Machine Learning to Gain Geological Insights through Unstructured Data for\\nSustainable Exploration Activities — Case Study Pre-Salt Brazil\\n\\nIntroduction\\n\\nUnderstanding the basin regional trends and identifying the anomalies is a cruc')\n",
      "(235, 6, 2, 'ial background research\\nduring basin exploration activities. One way to gain a sound knowledge about the geology and the\\nexploration history is to analyse the vast amount of data accumulated over the years in an unstructured\\nmanner. A sustainable data dri')\n",
      "(236, 6, 3, 'ven strategy leveraging on the latest advancement of Machine Learning\\n(ML) and Analytics is applied on vast amount of unstructured data. By highlighting the data driven\\nstrategy, the paper demonstrates such a strategy applied to pre-salt carbonates prospe')\n",
      "(237, 6, 4, 'cts located in the\\nCampos and Santos Basins, offshore Brazil. The interpretation framework consists of first step, to\\nidentify the regional first order trends and second step, to recognize the second order anomalies over\\nthe full area providing a holistic')\n",
      "(238, 6, 5, ' picture of the area of interest.\\n\\nMethodology\\n\\nThe unstructured data comprise of more than 48,000 documents, primarily in Portuguese language, for\\na total of 330,000 pages related to 50 years of exploration, covering the Campos and Santos Basins. The\\nmet')\n",
      "(239, 6, 6, 'hodologies are divided into two parts. In the part one methodology, the unstructured data is\\nprocessed using machine learning techniques such as Natural Language Processing (NLP) for name\\nentity recognition and language translation, and Deep Convolutional')\n",
      "(240, 6, 7, ' Neural Network (DCNN) for auto-\\nimage recognition (Hernandez et al., 2019). In part two methodology, ML Analytics leverages the\\nvisualization for data relationships to give a holistic view of the whole corpus (Baillard et al., 2021).\\nThree steps study is')\n",
      "(241, 6, 8, ' used here, as explained below with illustration at Figure 1.\\n© Step 1: Deep Search through text is the ability to use keywords search within the whole corpus\\nand filter the wanted results. Filtered information is easily accessible for investigation. Deep')\n",
      "(242, 6, 9, '\\nSearch is also applied for images. DCNN image recognition and classification techniques classify\\nthe images into eight categories: thin section, core, well plot, seismic, stratigraphic structural\\nelements, map, table, and figure. A deep search allows use')\n",
      "(243, 6, 10, 'r to search information tagged and\\nidentified in these images. This step is to identify the geological and exploration challenges\\nrelated to the area of interest.\\n© Step 2: Heat Map highlights the “hot zones” on map based on the frequency of the keywords\\n')\n",
      "(244, 6, 11, 'found. Drawing a polygon on the map allows user to confine the search to focus only in the zone\\nof their interest. On the other hand, instant text search through the whole corpus of English and\\nPortuguese documents is possible with the automated translati')\n",
      "(245, 6, 12, 'on. Users able to search through\\nPortuguese documents using English keywords.\\n© Step 3: Contextual Knowledge Graph illustrates the connectivity of ‘related corpuses’ based on\\nwell name referencing. This is useful to obtain related information from differe')\n",
      "(246, 6, 13, 'nt wells\\n(Hernandez et al., 2019). Besides that, Intuition provides clustered images view, a great approach\\nto discover analogues for alike images such as thin section, core, SEM, and biomarker.\\n\\n+ fnformaticn cerrelation using\\nKnowledge Graph\\n\\ni\\n\\n+ Deep ')\n",
      "(247, 6, 14, 'Search within documents and\\n\\nport\\n\\nf Portuguese: ion using\\n\\ncernbine\\n\\nFigure 1 The data driven search strategy implementing the ML Analytics for visualization of data\\nrelationships for a holistic view of whole corpus\\n\\nEAGE Conference on Digital Innovation')\n",
      "(248, 6, 15, ' for a Sustainable Future\\n\\n49) 415 Ok LL ANAA IT... 11. Mod\\n\\n\\n—_—ae eee\\n\\nCase study: Understanding the Pre-Salt Carbonate Regional Trends and Anomalies in Campos\\nand Santos Basins\\n\\nThe Campos and Santos Basins, located to the east offshore of Brazil, are ')\n",
      "(249, 6, 16, 'some of the most prolific oil\\nand gas basins in the world with significant discoveries such as Tupi, Jupiter and Libra Fields. The\\ninvestigation of the 50 years of pre-salt exploration history contained in the 48,000 documents processed\\nrevealed that most')\n",
      "(250, 6, 17, ' of the challenges during exploration are caused by 1. Fluid distribution 2. The\\nreservoir quality 3. CO2 and H2S presence 4. Overpressure patterns.\\n\\n1. Campos and Santos Basins are showing a variable fluid distribution. The type and quality of\\nthe fluid ')\n",
      "(251, 6, 18, 'trends are keys to define the best target for a sustainable development.\\n\\n2. The diagenesis affects the reservoir quality. A good visualization of the lateral distribution of\\nsuch process allows a better estimation of the porosity and the volume in place.')\n",
      "(252, 6, 19, '\\n\\n3. The regional gas issues, such as understanding the presence of CO2 and H2S is essential to\\ngauge the reservoir diagenesis properties as well as to plan for production facilities or to avoid\\nregions of sour and hazardous gaseous.\\n\\n4. The irregularity ')\n",
      "(253, 6, 20, 'in the thickness of the salt layer causes variability in the pressure regime with\\noverpressure over the zone of interest and affecting the drilling campaigns.\\n\\nThese challenges are relevant to understand the geology and production issues encountered in di')\n",
      "(254, 6, 21, 'stinct\\nparts of the basins to improve sustainable in the exploration risk and reducing COz footprint.\\n\\nFor the pre-salt oil trendings, Campos pre-salt generally has lighter oil compared to Santos pre-salt. As\\nfor the anomalies, light oil or condensate dis')\n",
      "(255, 6, 22, 'covery at Pau De Acucar, Seat and Gavea Fields in Campos\\npre-salt, while heavy mostly found in the post-salt in the Southern Campos. In Santos, heavy oil reported\\nin Jupiter Field. Note that heavy oil also discovered in Atlanta and Oliva Fields at post-sa')\n",
      "(256, 6, 23, 'lt. Illustration\\nin Figure 2.\\n\\n~ .Guaruines S s\\n\\naot\\n\\n*\\n\\nFigure 2 Heat map highlights the wells with “heavy oil” information. The oil API delineation is based\\non Deep Search extraction from test reports for Santos (left map) and Campos (right map). Knowle')\n",
      "(257, 6, 24, 'dge\\nGraph was analyzed to find a group of fields that share the light oil information — Gavea, Seat and Pao\\nde Acucar Fields.\\n\\nNext, we study the facies distribution at pre-salt carbonate. A collection of core and thin section images\\nare retrieved from th')\n",
      "(258, 6, 25, 'e Deep Search through images. In general, it is observed that the reservoir\\nformation is in the shrub facies, microbiolites and coquina. For the trendingss, the area with COz,\\nleaching activities enhance the porosity, example in the Libra, Buzios Fields, ')\n",
      "(259, 6, 26, 'going south to Tupi and\\nCarcara Fields in Santos. Fields proximal to the shore has poorer reservoir quality. One of the anomalies\\nobserved is the hydrothermal activity can destroy the enhanced porosity by the leaching. The\\nhydrothermal activity is anticip')\n",
      "(260, 6, 27, 'ated in Field Albacora, Carcara, based on the observation on the core.\\nIllustration in Figure 3.\\n\\nEAGE Conference on Digital Innovation for a Sustainable Future\\n\\n49) 415 Ok LL ANAA IT... 11. Mod\\n\\n\\n—_—ae eee\\n\\nMERO/LIBRA.\\n\\nMicrobial carbonates in\\nsag sequen')\n",
      "(261, 6, 28, 'ce and coquina\\nrift sequence\\n\\nshows good porosity due\\nto leaching\\nMEXILHAO.\\nPoor\\nreservoir\\n\\nquality\\n\\nBUZIGS, ATAPU,SEPIA.\\nMicrobial carbonates in\\nsag sequence and\\ncoquina rift sequence\\n\\n=~\\n\\n. Micobiolte Joratety SPherulitestone\\nshowingmaderstely Jom good\\n')\n",
      "(262, 6, 29, '\\ngoodlesched and 8\\nframework Gareny\\n\\nFigure 3 Pre-salt carbonate facies distribution based on core and thin sections collection from Deep\\nSearch through images. Analysing the diagenesis trend has an impact on reservoir quality\\ninterpretation. (core and th')\n",
      "(263, 6, 30, 'in section images are taken from BDEP-ANP reports and Core Lab study)\\n\\nThe following study is to investigate the regional gas issues. The trend is showing that Santos is\\nsuffering higher CO2 contamination compared to Campos, especially in the center deep-')\n",
      "(264, 6, 31, 'water Santos\\narea. Jupiter Field suffers from very high concentration of CO2 gas, 79% recorded. Center deeper-water\\nSantos is suffering from CO, contamination potentially near to the mantel magmatic activities\\nintercepted by deep-seated fault (Luca et al.')\n",
      "(265, 6, 32, ', 2017). Hazardous H2S gas presence in high amount\\n(exceeding OSHA safe limit 50 ppm) in the Buzios, Iara Fields of Santos and Xerelete, Albacora Fields\\nof Campos. Illustration in Figure 4.\\n\\neGuarulites\\n\\nOESTE\\n\\nFigure 4 Heat Map of “high CO2” information ')\n",
      "(266, 6, 33, 'with delineation of CO2 concentration based on Deep\\nSearch extraction from test reports in Santos (left map) and Campos (right map)\\n\\nLastly, is the study of formation pressure pattern. The formation data points are quickly extracted from\\nunstructured data')\n",
      "(267, 6, 34, ' over 80 wells using Deep Search. The points are then plotted on gradient psi/ft ranging\\nfrom 0.35 to 0.7 psi/ft. Based on the pressure gradient validation, wells in Carcara, Sagitario and\\nCorcovado Fields have exceptionally high formation pressure. An in')\n",
      "(268, 6, 35, 'terpretation of fullstack PSDM\\ncross-section shows thick salt area in Carcara and Sagitario, possible with faulting causes saline water\\nintrusion which contribute to high pressure zone. Irregularity in thickness of salt layer causes variability\\nin pressur')\n",
      "(269, 6, 36, 'e regime, such as overpressure area to take note as this will have an impact on seismic\\ninterpretation and drilling campaign. Illustration in Figure 5.\\n\\nEAGE Conference on Digital Innovation for a Sustainable Future\\n\\n49) 415 Ok LL ANAA IT... 11. Mod\\n\\n\\n\\n—_')\n",
      "(270, 6, 37, '—ae eee\\n\\nFormation Pressure, psi\\n0 S000 10000 15000 20000\\n\\n—Grad-035 psifit\\n— Grad=0.43 nsiftt\\n——Grad-050 psifft\\n— Grad=0.50 psifft\\n— Grad-0.70 psifit\\n\\nTVDSS,m\\n\\n8288 68 § §\\n\\nFigure 5 Formation pressure extraction for over 80 wells (all data points taken f')\n",
      "(271, 6, 38, 'rom BDEP-ANP\\nreports). Exceptionally high pressure recorded in Guaratiba Group in Carcara, Sagitario and\\nCorcovado, possible due to high salt thickness and faulting causes saline water. Fullstack PSDM cross\\nsection shows thick salt in area of Carcara and ')\n",
      "(272, 6, 39, 'Sagitario (courtesy of Kattah et al., 2014).\\n\\nConclusion\\n\\nThe research shows the effectiveness of using ML/AI technologies and Analytics to mine through the\\nvast amount of unstructured data and gain insights related to the regional trends and anomalies of')\n",
      "(273, 6, 40, '\\nimportant geological, reservoir and production parameters to minimize the risk of exploration and\\nreduce carbon footprint. New tools in ML/AI and Analytics provides a new exploration frontier for\\nsubsurface experts allowing them to interrogate and visual')\n",
      "(274, 6, 41, 'ize a vast amount of data previously scattered\\nin different format and location holistically.\\n\\nAcknowledgement\\n\\nWe would like to thank PETRONAS Petroleo Brasil LTDA for the collaboration with Iraya Energies\\nto makes this paper possible. Our gratitude appr')\n",
      "(275, 6, 42, 'eciation also goes to Banco de Dadoes Exploracao e\\nProducao (BDEP) of National Agency of Petroleum (ANP) for making the data source available for\\nthis study.\\n\\nReferences\\n\\nBaillard, F., & Hernandez, N. (2021). A Case Study of Understand Bonarparte Basin us')\n",
      "(276, 6, 43, 'ing Unstructured\\nData Analysis with Machine Learning Techniques. EAGE Annual.\\n\\nHernandez, M., & Baillard, F. (2019). An effective G&G exploration strategy inspired by a wolfpack.\\nForce workshop.\\n\\nHernandez, N., Lucafias, P., Graciosa, J, Mamador, C., & Pa')\n",
      "(277, 6, 44, 'nganiban, I. (2019). Automated\\nInformation Retrieval from Unstructured Documents Utilizing a Sequence of Smart Machine Learning.\\nEAGE Workshop on Big Data and Machine Learning for E&P Efficiency 25 - 27 February.\\n\\nHydrogen Sulfide. (2022). Retrieved from ')\n",
      "(278, 6, 45, 'Occupational Safety and Health Administration:\\nhttps://www.osha.gov/hydrogen-sulfide/hazards\\n\\nCore Lab [2022]. Pre-Salt Reservoirs of the Santos and Campos Basins, Brazil\\n\\nLuca, Pedro & Matias, Hugo & Carballo, Jose & Sineva, Diana & Pimentel, Gustavo & T')\n",
      "(279, 6, 46, 'ritlla, Jordi &\\nCerda, Mateu & Loma, Rubén & Jiménez, Ricardo & Pontet, Matthieu & Martinez, Pedro & Vega,\\nVictor. [2017]. Breaking Barriers and Paradigms in Presalt\\n\\nKattah, S., Balabekov, Y., [2014]. New opportunities evident in the Santos Basin. Harten')\n",
      "(280, 6, 47, 'ergy. 2\\nSeptember 2022. https://www.hartenergy.com/ep/exclusives/new-opportunities-evident-santos-basin-\\n174870\\n\\nEAGE Conference on Digital Innovation for a Sustainable Future\\n\\n49) 415 Ok LL ANAA IT... 11. Mod\\n\\n')\n",
      "(281, 7, 1, '\\nVIENNA | AUSTRIA\\n\\nCO: emissions the elephant in the room: a pathway of reduction using digitalization and\\nunstructured data\\n\\nIntroduction\\n\\nIn this paper, we are exploring the challenges associated to climate change in the energy industry with\\nthe paradig')\n",
      "(282, 7, 2, 'm of extracting oil and gas in a low CQz environment to limit the effect of climate change\\nand provide the world with affordable source of energy for mobility and heat generation.\\n\\nWe will be discussing how carbon accounting allows to track direct and ind')\n",
      "(283, 7, 3, 'irect source of emissions,\\nits origins and the challenges associated to them.\\n\\nFinally, we will investigate how modern technology such as data mining can help mitigate direct and\\nindirect emissions by increasing operations efficiency, identifying operatio')\n",
      "(284, 7, 4, 'n flaws, and implementing\\nscalable Carbon Capture and Storage (CCS) implementation.\\n\\nCO: emission and world energy consumption\\n\\nRecently, the Intergovernmental Panel on Climate Change (IPCC) issued the sixth Assessment Report\\n(AR6) related to Climate Chan')\n",
      "(285, 7, 5, 'ge 2022: Impacts, Adaptation and Vulnerability which highlights\\nthe urgency of limiting the increase of temperature to 1.5°C to reduce the impact of climate change:\\n“Global warming, reaching 1.5°C in the near-term, would cause unavoidable increases in mul')\n",
      "(286, 7, 6, 'tiple\\nclimate hazards and present multiple risks to ecosystems and humans (very high confidence). [...] Near-\\nterm actions that limit global warming to close to 1.5°C would substantially reduce projected losses\\nand damages related to climate change in hum')\n",
      "(287, 7, 7, 'an systems and ecosystems, compared to higher warming\\nlevels, but cannot eliminate them all (very high confidence).” (IPCC, 2022).\\n\\nIn addition, the AR6 report linked to Climate Change 2022: Mitigation of Climate Change suggests\\nthat “All global modelled ')\n",
      "(288, 7, 8, 'pathways that limit warming to 1.5°C [...] involve rapid and deep and in\\nmost cases immediate GHG emission reductions in all sectors. Modelled mitigation strategies to\\nachieve these reductions include transitioning from fossil fuels without CCS to very lo')\n",
      "(289, 7, 9, 'w- or zero-carbon\\nenergy sources, such as renewables or fossil fuels with CCS, demand side measures and improving\\nefficiency, reducing non-CQ? emissions” (IPCC, 2022).\\n\\nGlobal primary energy consumption by source\\n\\nPrimary energy is calculated based on the')\n",
      "(290, 7, 10, ' ‘substitution method’ which takes account of the inefficiencies in fossil\\nfuel production by converting non-fossil energy into the energy inputs required if they had the same conversion\\nlosses as fossil fuels.\\n\\n=| Other\\n\\nrenewables\\n160,000 TWh Modem biof')\n",
      "(291, 7, 11, 'uels\\n\\nSolar\\n\\nWind\\n140,000 TWh Hydropower\\n\\n— Nuclear\\n7 Gas\\n\\n120,000 TWh\\n\\n100,000 TWh\\n80,000 TWh\\n60,000 TWh\\n40,000 TWh\\n\\n20,000 TWh\\n\\nTraditional\\nOTWh biomass\\n\\n1800 1850 1900 2019\\n\\nSource: Vaclav Smil (2017) & BP Statistical Review of World Energy OurWorldinD')\n",
      "(292, 7, 12, 'ata.org/energy * CC BY\\n\\n\\n\\nVIENNA | AUSTRIA\\n\\nFigure 1: Global primary energy consumption by source. Fossil energies account for 80% respectively\\nCoal (25%), Oil (32%) and Gas (23%) (Source: Our World in Data - Energy)\\n\\nWhile limiting the reduction of CO2 t')\n",
      "(293, 7, 13, 'o reduce the impact of climate change, the world is still highly\\ndependent on fossil fuels, with fossil energies accounting in 2019 for more than 80% in total and Oil/Gas\\nfor 60% alone (Figure 1). Combined with the need of powering the world and the chall')\n",
      "(294, 7, 14, 'enges of climate\\nchange, the energy sector has a central play to significantly monitor and reduce its CO2 footprint.\\n\\nCarbon accounting\\n\\nCarbon accounting is the process which allows organization to quantify and monitor Greenhouse Gas\\n(GHG) emissions. By ')\n",
      "(295, 7, 15, 'construction, carbon accounting counts the direct and indirect emissions linked\\nto the activity of the organization through the full value chain.\\n\\nDirect emission are the emissions directly related to the own activity of the company such as oil/gas\\nextrac')\n",
      "(296, 7, 16, 'tion and production and are often referred to scope 1 emissions. Indirect emission are the\\nemissions emitted considering the full value chain. In the case of the energy industry, this would\\nconsider all the necessary services contracted to perform the ext')\n",
      "(297, 7, 17, 'raction of oil and gas from the\\nsubsurface and all the emissions related to the usage of the oil and gas as a molecule for the human\\nusage in mobility, industry usage and heat generation. These emissions are falling into the scope 2\\nassociated to the supp')\n",
      "(298, 7, 18, 'ly of energy (input) and the scope 3 linked to the oil and gas products sold (output).\\n\\nFigure 2 illustrates the breakdowns and evolution of four (4) representative Oil major operators’\\nemissions until 2018. In average, 10% of the emissions are associated')\n",
      "(299, 7, 19, ' to direct emission and 90% of\\nthem are linked to indirect emissions connected to hydrocarbon products sold. Considering oil and gas\\ncommitment in reducing carbon emission, this means that both direct and indirect emissions would need\\nto be tackled simult')\n",
      "(300, 7, 20, \"aneously.\\n\\nOil Majors' Carbon emissions\\n\\nOperator A Operator B\\n\\nOperator C Operator D\\n\\nFigure 2: Evolution of direct and indirect emissions for four (4) Oil Majors. scope 1; Own operations\\n(direct emissions), scope 2: Power supply (indirect emissions), sc\")\n",
      "(301, 7, 21, 'ope 3: Indirect from oil and gas\\nproducts sold (indirect emissions) (Source: Modified from Reuters 2019)\\n\\nData mining technology\\n\\n— —————_— ——————\\n\\n\\nVIENNA | AUSTRIA\\n\\nDecades of oil and gas operations associated to the exploration, development and product')\n",
      "(302, 7, 22, 'ion of oil\\nfields have generated vast amount of data which provides a deep insight of constant optimization of\\ncosts and resources. The data are interpreted and compiled into unstructured data such as reports,\\npresentations and studies providing a carbon ')\n",
      "(303, 7, 23, 'copy of the history of the operations. The unstructured\\ndata provides an immense potential of CO2 emissions reduction for both direct and indirect emissions.\\nNew technology such as Data Mining and Machine Learning technology helps to process and retrieve\\n')\n",
      "(304, 7, 24, 'information at scale contained in the unstructured data in a pipeline called ingestion of unstructured\\ndata (Hernandez, 2019). The process involves automated pipeline of text identification, image\\nclassification, Name Entity Recognition (NER), Knowledge G')\n",
      "(305, 7, 25, 'raph and Heat Map analysis.\\n\\nFor the direct emissions, the ingestion of unstructured data gives the G&G experts a discovery\\nexperience allowing him to interrogate the full corpus of data instantly. Such ingestion platform reduces\\nthe time of information r')\n",
      "(306, 7, 26, 'etrieval and provides a holistic view of the lateral extent for the parameters of\\ninterest. An example of such application is seen in Figure 3, where reservoir intervals with high CO2\\ncontent is highlighted for more than 500 wells associated to the ingest')\n",
      "(307, 7, 27, 'ion of over 45,000 unstructured\\ndocuments.\\n\\n650% 4 SW aS\\nSt og z\\n\\nResults Density\\n\\nLow es a High\\n\\nuit mrs taneous rocks (Ran sta, 2020)\\n\\n+ Totan-Gough beat (Matos, 2027) Crustal Domains (Zalén etal, 2018) Ml Extrusions (Costa Comeia, 2018)\\n\\nPost sa wel Hi')\n",
      "(308, 7, 28, 'l Hyper Extended Crust IB ftnisions (Costa Comeia, 2019)\\n\\n© Pretak wal (a SvectedThinned IS tproous rock (Wloka do Luca ef a, 2017}\\nDepocenter Resistate\\n\\na\\nFigure 3: Regional maps covering 500 wells showing the presence of high CO2 content in the reservoi')\n",
      "(309, 7, 29, 'r\\ninterval (Source: https://doi.org/10.1016/) jsames.2022, 103760)\\n\\nReducing the time of information retrieval provides a unique opportunity of fast-tracking studies, hence\\nreduce the CO. emissions. An extended scope of the data ingestion workflow is the ')\n",
      "(310, 7, 30, 'identifying and\\ntracking the origin of operations flaws and best practices for potential improvement and reduction of\\nCOQ emissions (Hernandez, 2021).\\n\\nThe reduction of indirect emissions involves large scale adoption and deployment of CCS capabilities\\nwo')\n",
      "(311, 7, 31, 'rldwide. Such a pathway is possible by leveraging on current existing oil and gas assets which are\\nthe mature depleting fields. Extensive work and studies over decades generated a vast amount of data\\nsubsurface studies and production that are mined to ran')\n",
      "(312, 7, 32, 'k the best opportunities for CCS based on the\\nfield maturation, intervention history and geological settings. Once the target reservoir identified CO2\\ninjection can then be monitored wit novel environmentally friendly methods such as using\\nnondisruptive 4')\n",
      "(313, 7, 33, 'D seismic (Figure 4) to prove the potential. Such Data to Sink funnel provides the\\ntechnical scalability and the cost effectiveness to assess CCS potential in a large area of interest.\\n\\n— —————_— ——————\\n\\n\\nVIENNA | AUSTRIA\\n\\nData mining of historical\\nunstru')\n",
      "(314, 7, 34, 'ctured data from\\n6 depleting mature oil and\\n\\ngas fields\\n\\ndata sweep of\\nature fields\\n\\nK4\\n2\\n. . w\\nPERE cone Isetiien 20% opportunities e\\nof existing G&G A os\\nidentified Pd\\nstructured data Ee\\na\\nCO2 injection\\nand\\n\\nmonitoring\\n\\nCCS operation\\n\\nFigure 4; Data to ')\n",
      "(315, 7, 35, 'Sink funnel workflow powered by data mining, machine learning and lean 4D seismic\\nmonitoring.\\n\\nConclusions\\n\\nThe reduction of carbon emission at scale in the energy industry remains a challenge. In this paper we\\nhave demonstrated how digitalization applied')\n",
      "(316, 7, 36, ' on unstructured data can help reduce both direct and\\nindirect emissions.\\n\\nAcknowledgements\\nWe would like to thank Iraya Energies for allowing us to publish this paper.\\nReferences\\n\\nIPCC, 2022: Summary for Policymakers. In: Climate Change 2022: Mitigation ')\n",
      "(317, 7, 37, 'of Climate Change.\\nContribution of Working Group III to the Sixth Assessment Report of the Intergovernmental Panel on\\nClimate Change [P.R. Shukla, J. Skea, R. Slade, A. Al Khourdajie, R. van Diemen, D. McCollum, M.\\nPathak, S. Some, P. Vyas, R. Fradera, M.')\n",
      "(318, 7, 38, ' Belkacemi, A. Hasija, G. Lisboa, S. Luz, J. Malley, (eds.)].\\nCambridge University Press, Cambridge, UK and New York, NY, USA. doi:\\n10.1017/9781009157926.001\\n\\nIPCC, 2022: Summary for Policymakers [H.-O. Pértner, D.C. Roberts, E.S. Poloczanska, K.\\nMintenbe')\n",
      "(319, 7, 39, 'ck, M. Tignor, A. Alegria, M. Craig, S. Langsdorf, S. Léschke, V. Méller, A. Okem (eds.)].\\nIn: Climate Change 2022: Impacts, Adaptation, and Vulnerability. Contribution of Working Group II\\nto the Sixth Assessment Report of the Intergovernmental Panel on C')\n",
      "(320, 7, 40, 'limate Change [H.-O. Portner, D.C.\\nRoberts, M. Tignor, E.S. Poloczanska, K. Mintenbeck, A. Alegria, M. Craig, S. Langsdorf, S. Lschke,\\nV. Miller, A. Okem, B. Rama (eds.)]. Cambridge University Press. In Press.\\n\\nHernandez, N. M., Lucaiias, P. J., Mamador, ')\n",
      "(321, 7, 41, 'C., & Panganiban, L. [2019]. Automated Information\\nRetrieval from Unstructured Documents Utilizing a Sequence of Smart Machine Learning Methods\\nwithin a Hybrid Cloud Container. EAGE Workshop on Big Data and Machine Learning for E&P\\nEfficiency 25-27 Februa')\n",
      "(322, 7, 42, 'ry\\n\\nHernandez, N.M. and Maver, K.M. [2021]. ED2K Initiative launched to support UN 2050 Net Zero\\ngoals by reading the earth better, First Break, June 2021\\n\\n— —————_— ——————\\n\\n')\n",
      "(323, 8, 1, '\\nVIENNA AUSTRIA\\n\\nDouble funnel approach for screening of potential CO2 storage opportunities in the Norwegian\\nContinental Shelf\\n\\nIntroduction\\n\\nCarbon capture and storage (CCS) is a key waste management strategy for reducing carbon dioxide (CO2)\\nemissions ')\n",
      "(324, 8, 2, 'and mitigating climate change. The Norwegian continental shelf has significant capacity for CCS,\\nas it has several depleted oil and gas fields that can be used for storage of CO2. The field of CCS has seen\\nsignificant growth in recent years, as the need t')\n",
      "(325, 8, 3, 'o reduce carbon CO2 emissions becomes increasingly\\nurgent. However, despite the increasing number of studies on CCS, there remains a lack of consensus on\\nthe most effective methods for accelerating and scaling up CCS projects.\\n\\nIn this study, the integrat')\n",
      "(326, 8, 4, 'ion of Machine Learning (ML) whereby the reports from the Norwegian Petroleum\\nDirectorate (NPD) are ingested into one platform creates potential cost-effective solution by screening\\nprevious knowledge gathered for depleting oil and gas fields and signific')\n",
      "(327, 8, 5, 'antly reduces the time of the\\nscreening, the evaluation and the ranking of CCS prospects. We investigate the feasibility of such a study\\non the Norwegian Continental Shelf by analyzing the geology and capacity of existing oil and gas fields.\\nThe analysis ')\n",
      "(328, 8, 6, 'is conducted on historical data from final well reports for 361 wells (NPD, 2023) which are\\nptiorly ingested using Machine Learning (ML) and Artificial Intelligence (AI) by indexing and tagging\\nmetadata from the documents, extracting, and classifying imag')\n",
      "(329, 8, 7, 'es and generating geological interpretable\\noutput such as heat maps or knowledge graphs. Our research includes a detailed characterization and\\ninterpretation of the subsurface geology, including the identification of potential storage formations, the\\nanal')\n",
      "(330, 8, 8, 'ysis of reservoir properties such as porosity and permeability and the evaluation of seal characteristics.\\nWe also conducted a comprehensive assessment of the capacity for CO2 storage, considering factors such\\nas injection rate and pressure buildup.\\n\\nMeth')\n",
      "(331, 8, 9, 'odology\\n\\nDepleting oil and gas fields in the Norwegian Continental Shelf with their massive amount of data being\\ncollected over decades of development and production are often considered good candidates for CCS\\nopportunities. Unfortunately the vast amount')\n",
      "(332, 8, 10, ' of knowledge come with the challenges associated to the lack\\nofnormalization of the data and the diversity of the different format and template utilized making it difficult\\nto utilize the full potential of such data without allocating significant manual ')\n",
      "(333, 8, 11, 'work.\\n\\nIn our case study, Machine learning pipelines are used to classify, cluster, and extract insights from such\\nan unstructured data. Priorly trained and G&G domain specific natural language processing (NLP)\\ntransformers are executed on the text to per')\n",
      "(334, 8, 12, 'form indexing, metadata tagging and topic modeling, when\\nDeep Convolutional Neural Network (DCNN) extract, classify and segment extracted images. Such an\\napproach has the advantage of significantly lessening manual human intervention allowing G&G experts\\n')\n",
      "(335, 8, 13, 'to focus on the interpretation of the data itself using a front end deployed interface (Baillard et al., 2019).\\nAs seen in Figure 1 the data visualization and interpretation are performed through a suite of six analytical\\ntools: (1) summarizes the importa')\n",
      "(336, 8, 14, 'nt attributes of the well automatically extracted from the document, (2)\\naids in portraying the well data on a map and visualizes the lateral distribution of search queries, (3)\\nprovides an in-depth search within all the corpus for the text and any tagged')\n",
      "(337, 8, 15, ' associated metadata using\\nNLP, (4) correlates wells between each other’s to understand and interpret the semantic structure of the\\nbasin(5) searches the images extracted from DCNN into its respected geological categories, (6) quantifies\\nthe frequency of ')\n",
      "(338, 8, 16, 'different lithologies present from the different wells.\\n\\nQA RAGE Annnal Mnnference & Evhikitian\\n\\n\\nS| VIENNA AUSTRIA\\n\\nKnowledge Graph Se ariea\\n\\nimage search module\\nCorreiste findings with Meciaasnacgaae  Q@) Uthotogy tao\\npete\\n\\nFigure 1 Analytical tools use')\n",
      "(339, 8, 17, 'd for the case study research strategy for CO2 storage screening\\n\\nSuch a set of tools provides powerful means for understanding and interpreting large and complex sets of\\ndata. It can help to identify patterns, trends, and relationships that might not be ')\n",
      "(340, 8, 18, 'immediately apparent from\\nraw data due to the segregation of information in separate files for each well. By narrowing down the scope\\nof focus on selected wells, the exclusion of non-relevant well and time frame reduction of the process can\\nbe accomplishe')\n",
      "(341, 8, 19, 'd.\\n\\nIn this paper, we propose a new CCS screening workflow called Double Funnel Approach (DFA), seen on\\nFigure 2 which consists of a “data sweep” and a “data target”. The “data sweep” aims to reduce all findings\\nfrom all ingested data to key learnings and')\n",
      "(342, 8, 20, ' key wells over the area of interest, allowing to review and rank\\nthe most suitable field candidates for potential CCS opportunities. The “data target” follows the “data\\nsweep” and focuses only on the field selected candidates and aims to refine and enhan')\n",
      "(343, 8, 21, 'ce the existing\\nunstructured data with seismic, logs, interpretation and geomodel data. During this exercise, redundant and\\nirrelevant data are removed through efficient automated version indexing and cross-correlation with the\\nunstructured data. Finally,')\n",
      "(344, 8, 22, ' the data is now ready for screening for CO2 injection capacity and monitoring\\nanalysis.\\n\\nUnstructured Data Interpretation\\nKey learmings yt Gat? nett\\nKey wells pater pesunda een\\n“ ” i “Data Target” nett\\nPEE SmEay ane 9 Target field for CO2\\nBasin Mapping ¥')\n",
      "(345, 8, 23, ' area storage\\nPlay Evaluation\\nReservoir Properties\\nMonitor injection in\\nSeal Properties Depletingficlds review 0, CCS wells\\n\\nandranking pa\\n\\nIdentify learning over Propagate learning\\nsedimentary basins over key depleting\\nfields\\n\\nFigure 2 Proposed Double Fu')\n",
      "(346, 8, 24, 'nnel Approach for CCS Screening Studies\\nCCS “data sweep” use case offshore Norway\\n\\nThe ingestion of data for the case study comprises of 490,000 pages and 440,000 images, covering a total\\nof 361 wells within 5 basins in Norway consolidating 50 years of ex')\n",
      "(347, 8, 25, 'ploration, development, and production.\\nAll these data has been retrieved from the Norwegian Petroleum Directorate (NPD). The “data sweep” of\\nthe data was completed in 21 days which evaluated various hypothesis and converge on the key learnings,\\nkey wells')\n",
      "(348, 8, 26, ', key risks, and key drivers.\\n\\nQA RAGE Annnal Mnnference & Evhikitian\\n\\n\\nVIENNA AUSTRIA\\n\\nFigure 3 shows the generated knowledge graph associated to the zone of interest. Knowledge graph is a\\nstructured way to represent and organize knowledge in a way that ')\n",
      "(349, 8, 27, 'is easily queried and traversed across all\\nthe corpus of documents ingested. This makes it useful for a holistic interpretation of the wells present in\\nthe area of interest, interpreting and ranking them based on their location and importance in the graph')\n",
      "(350, 8, 28, '\\nrespectively as “alpha” or geological analogue, “scouts”, “pack or “lone-spirit” wells. As observed, the\\nstructure of the knowledge graph does indicate a non-homogeneous distribution with 7 different clusters\\nbeing identified. Each cluster is centered ar')\n",
      "(351, 8, 29, 'ound key wells acting as key geological analogues (“alpha”\\nwell) for the surrounded wells located within the cluster. “Scouts” wells define the unique critical paths\\nbetween adjacent clusters, allowing geologists to deeper understand the geology and explo')\n",
      "(352, 8, 30, 'ration history of\\nthe area of interest (Hernandez et al., 2019).\\n\\n2\\n\\nFigure 3 Knowledge graph with clusters of wells from the Norwegian dataset\\n\\nBased on the recognized clusters, wells are further investigated by cross-correlating their respective post\\ndr')\n",
      "(353, 8, 31, 'ill conclusion, formation penetration and keywords search associated to reservoir properties, seal\\ncharacteristics or a specific search allowing a deeper dive in the corpus. An example of such full corpus\\nsearch for ‘porosity’ detected from the well final')\n",
      "(354, 8, 32, ' well reports, within text, images and tables identifying the\\nrelevant values of the porosity and their associated formations. Auto-classified images can enhance the\\nanalysis by providing detailed information about the textures, layers, and structural cha')\n",
      "(355, 8, 33, 'racteristics of the\\nrocks through different scales, from field scale with seismic stacks or isochrone map, to microscopic scale\\nwith thin section images. Additionally, image analysis techniques such as pattern recognition can be used\\nto automatically extr')\n",
      "(356, 8, 34, 'act features and classify rock formations.\\n\\nIn this example, the “data sweep” suggests suitable areas for CCS in the Norwegian Sea corresponding to\\nHeidrun and Marulk fields. The study highlights the potential of Ile and Garn formation within the Fangst\\nG')\n",
      "(357, 8, 35, 'roup under the Heidrun Field. These intervals show good average depths for CO2 storage for supercritical\\nstorage, and are characterized by good porosity and permeability, with a significant net sand thickness. Seal\\nintegrity has been confirmed and validat')\n",
      "(358, 8, 36, 'ed. The interval above Ile and Garn are currently producing, and\\ntherefore has seismic and velocity data which allows precise CO2 injection monitoring through\\nmicroseismic. The upper Ile and Garn aquifers have good reservoirs in the southern part of the F')\n",
      "(359, 8, 37, 'roan Basin\\nwhich may indicate additional potential CCS storage in this area.\\n\\nQA RAGE Annnal Mnnference & Evhikitian\\n\\n\\nVIENNA AUSTRIA\\n\\nWell Depth Field Formations Po Re pes, ity Seal Uthology\\n6507/7-6 capes ~ elgun fuerm | cooacase |Verycood Claystone San')\n",
      "(360, 8, 38, 'dstone\\n6507/2-2 | 3670 - 3695 baie ui Garn Fm Moderate Claystone Sandstone\\n6507/7-10 ooo, 5 eae Garn Fm Fair to Good fae dae Sandstone\\n6507/7-5 ee Helcrun fuerm | cooaczae | Saadtso Claystone Sandstone\\n6507/8-1 ooo. 5 re een ion ia Moderate Good Claystone')\n",
      "(361, 8, 39, ' Sandstone\\n\\nFigure 4 Screening CO2 storage candidates based on lithology, average porosity, average permeability,\\nand seal characteristics.\\n\\nConclusion\\n\\nThe study showcases how a “Double Funnel Approach” through an ML data ingestion pipeline can be an\\neff')\n",
      "(362, 8, 40, 'icient screening tool to analyze, review and rank CCS potential using readily available unstructured data.\\nIn this case, 490,000 pages of documents have been analyzed in 21 days to identify potential CCS\\nopportunities below Heidrun producing field, extend')\n",
      "(363, 8, 41, 'ed across the Froan basin. Additional analysis through\\nthe “data target” may now be undertaken around Heidrun field on related wells, seismic and interpretation\\ndata.\\n\\nTo conclude, such an analysis suggests the scalability and the cost effectiveness of th')\n",
      "(364, 8, 42, 'e methodology for\\nrapidly addressing the requirements of new CCS capabilities to mitigate the impact of the Climate Change.\\n\\nAcknowledgment\\n\\nThis paper utilizes the data from the Norwegian Petroleum Directorate (NPD) open dataset. Disclaimer of\\nthose inte')\n",
      "(365, 8, 43, 'rpretations from the study are from investigation and analysis of the authors alone.\\n\\nReferences\\n\\nBaillard, F., & Hernandez, N. (2021). A Case Study of Understanding the Bonaparte Basin using\\nUnstructured Data Analysis with Machine Learning Techniques. EA')\n",
      "(366, 8, 44, 'GE Annual.\\n\\nHernandez, M., & Baillard, F. (2019). An effective G&G exploration strategy inspired by a wolfpack.\\nFORCE Workshop.\\n\\nNorwegian Petroleum Directorate. (n.d.). 5 - The Norwegian Sea. Retrieved at January 20, 2023 from\\nhttps://www.npd.no/en/facts')\n",
      "(367, 8, 45, '/publications/co2-atlases/co2-atlas-for-the-norwegian-continental-shelf/5-the-\\n\\nnorwegian-sea/\\n\\nNorwegian Petroleum Directorate. (n.d.). 4 - The Norwegian North Sea. Retrieved at January 20, 2023\\nfrom https://www.npd.no/en/facts/publications/co2-atlases/c')\n",
      "(368, 8, 46, 'o2-atlas-for-the-norwegian-continental-\\nshelf/4-the-norwegian-north-sea/\\n\\nQA RAGE Annnal Mnnference & Evhikitian\\n\\n')\n",
      "(369, 9, 1, '\\nVIENNA | AUSTRIA\\n\\nSand Production and Control Benchmarking through Unstructured Data Analysis with Machine\\nLearning in the North Sea\\n\\nIntroduction\\n\\nSand production has been serving as a bottleneck to the oil and gas industry, contributing to disruption\\no')\n",
      "(370, 9, 2, 'f daily production operations, casing deformation, erosion of well tubing, pipelines, and surface\\nequipment, expediting to significant non-productive time (NPT) costing millions of dollars in loss\\nannually. Conventional areal studies for sand production w')\n",
      "(371, 9, 3, 'ill only be limited to few wells and heavily\\ndependent on data availability, human-based interpretation, and time constraints. To administer a\\nholistic basin study for sand production comprising of hundreds of wells with conventional manual\\nmethod is cons')\n",
      "(372, 9, 4, 'idered complex and time consuming, hence sand mitigation best practices are typically\\nderived from localized reservoir and production engineering data only, and knowledge is organically\\nbuilt through accumulated expert experience in the area over multiple')\n",
      "(373, 9, 5, ' years of operatorship. Information\\nand reports may be derived from millions of pages of legacy well reports, documentations, or files from\\nover 40 years ranging from digitized medium to hand-written reports in countless formats.\\n\\nA sustainable strategy o')\n",
      "(374, 9, 6, 'f data-driven basis shall be leveraged to address the knowledge and information\\nmanagement issues utilizing the latest advancement of Machine Learning (ML) and data analytics to\\nmaximize the potential of unstructured data. Utilizing the intuitive data-dri')\n",
      "(375, 9, 7, 'ven approach, the paper will\\nhighlight the areal causation of sand production based on geological characteristics and the best\\npractices of sand control commenced by 8 operators in Norwegian Basins practically informative for\\nfuture exploration wells to b')\n",
      "(376, 9, 8, 'e developed nearby current wells. The study first creates a relationship\\nbetween the causation of sand production versus the sand control practices implied and best practices\\nare derived from the practices of multi-wells.\\n\\nMethodology\\n\\nUnstructured data i')\n",
      "(377, 9, 9, 'n nature is significantly sophisticated to be manually interpreted and skimmed\\nthrough by human-intervention. An intuitive approach embedded with Deep Convolutional Neural\\nNetwork (DCNN) for autonomous image recognition and Natural Language Processing (NL')\n",
      "(378, 9, 10, 'P) for texts\\nand entity processing and recognition has been a pioneering enterprise-scaled platform in managing\\nunstructured data (Hernandez et al., 2019). It will be capable to ingest “big data” for the case study\\ncomprising of 70,000 files with 490,000 ')\n",
      "(379, 9, 11, 'pages and 430,000 images inclusive of 361 wells over 5 basins\\nin Norway. 40 years of unstructured data for sand production case study is consolidated approximately\\nwithin 16 days of study period.\\n\\nCorrelate findings with\\n\\nImage search module\\nplots/images/')\n",
      "(380, 9, 12, 'maps/stratigraphic\\n\\nplots\\n\\nLith ology tab\\n\\nFigure 1 Data-driven case study research strategy for sand production in Norwegian Basins.\\n\\n— —————_— ——————\\n\\n\\nVIENNA | AUSTRIA\\n\\nStep (1) is a generic deep search of the sand production scope across the whole cor')\n",
      "(381, 9, 13, 'pus. Step (2) leads\\nto discovering all wells significant parameters based on the files search results within well summary\\ntab. Step (3) portrays an early insight of the general idea of the document with word cloud. Step (4) heat\\nmap resembles the wells di')\n",
      "(382, 9, 14, 'stribution in a GIS map based on colour density of corpus search frequency\\nmentioned in the documents. To uncover more questions along the research process and to obtain more\\nin-depth information, step (5) is conducted in an iterative manner. Step (6) is ')\n",
      "(383, 9, 15, 'to relate the lithology\\ndistribution by lithology count within each well document to the previous detailed search parameters.\\nStep (7) aims to find more representable images to support the case study through the automatically\\nclassified images through DCN')\n",
      "(384, 9, 16, 'N in the reports. After all significant parameters are obtained, well-to-\\nwell relationship is studied to get more details on further causation and best practices of sand production\\nmanagement.\\n\\nThe features of this intuitive knowledge management platform')\n",
      "(385, 9, 17, ' transform voluminous unstructured data\\ninto structured data that are ready to be consumed and utilised for production enhancement case study.\\nFour main ML analytical tools embedded in the platform are as presented below (Baillard et al.,2021):\\n\\ne Expedit')\n",
      "(386, 9, 18, 'ious and intelligent search module by keyword-basis searching through hundreds of\\nthousands of pages of texts and texts embedded inside images.\\n\\ne Autonomous extraction of images from documents and image segregation into respective image\\nclasses of tables')\n",
      "(387, 9, 19, ', figures, well plots and maps with DCNN image detection algorithm.\\n\\ne Knowledge graph with contextual well name relationship portraying connectivity of ‘related\\ncorpuses’ to understand well-to-well relationship as described in their respective document c')\n",
      "(388, 9, 20, 'orpus.\\n\\ne Heat Map illustrates the density of keywords by colour gradient on wells based on the search results\\non a map. Polygonal or square filter feature enable selective wells to be screened out for users\\nnarrowed search interest.\\n\\nCase Study: Prelimin')\n",
      "(389, 9, 21, 'ary Study on Sand Production and Developing Sand Control Benchmark of\\nNorwegian Basin with Unstructured Data\\n\\nThe study was conducted extensively throughout approximately 361 wells consuming 16 days of study\\nperiod covering the analysis and interpretation')\n",
      "(390, 9, 22, ' of sand production trends, causation and best practices\\nin Norwegian Basins. A total of 8 operators were participating in exploration phase of reservoirs\\nespecially in Voring and Northern North Sea basins.\\n\\nVoring Basin Wells\\n\\nFigure 2 Reservoir Performa')\n",
      "(391, 9, 23, 'nce Tests (RFT) for Voring Basin Wells\\n\\nSand production was reported in 7 wells and most discoveries of sanding were reported during Drill-\\nstem Testing (DST) and reported in completion reports and drilling program reports as in Figure 2, A\\n\\n— —————_— ———')\n",
      "(392, 9, 24, '———\\n\\n\\nVIENNA | AUSTRIA\\n\\nfew wells were reported to experience little to no sanding issues however providing adequate\\ninformation in the scope of best practices and recommendations.\\n\\nHHH MHGG Re\\n\\nee ‘dean sandstone, fine grained, well sorted\\n\\noman ‘mediurn')\n",
      "(393, 9, 25, ' fo coarse ~grained, moderately H\\n‘sorted, friable to loose grains.\\n\\n(Moderately sorted, fine to very fine grain size,\\nbroorany habe cet he ice wh\\n2558.0 —\\n~\\n‘Sandstones, friable to very friable, moderately\\n‘Sorted, subrounded to rounded\\n.\\ni\\n\\nAN ML\\n\\nFigur')\n",
      "(394, 9, 26, 'e 3 Chronostratigraphic evaluation of Sand Prone Weils\\n\\nReferring to Figure 3, chronostratigraphic reports denote sufficient reasoning of sand production\\noccurrence throughout Norwegian basins as most sanding issues are prone in younger formations or\\ntert')\n",
      "(395, 9, 27, 'iary aged formations from Upper Jurassic, Late Paleocene, Danian, Early Toracian, Sinemurian and\\nUpper Toracian. Cuttings and core samples obtained from different stratigraphy depths of sanding prone\\nformations; Tofte, Aldra, Froya and Top Heimdal were mo')\n",
      "(396, 9, 28, 'stly described with friable, loosely grained,\\ntraces of sands, soft tertiary claystone, little to no cementation and fine-grained characteristics\\ndominantly originating from sandstone, carbonate and claystone-sandstone mix lithology. Marginal\\nmarine and d')\n",
      "(397, 9, 29, 'eltaic depositional environments leads to less cementation and loosely grained deposited\\nsand characteristics.\\n\\n| Northern North Sea Basin Wells ree er\\n\\n«Quality of MDT wireline semples was: = Sand fadlure test (high-rate test - gradual\\nquestioned due to ')\n",
      "(398, 9, 30, 'plugging ofthe toot by increase to high rate for 6 hours)\\nsand peoduction 1 No sand production observed\\nSand detection monitor did not dicate * Well was flowed for 5000 gab/a for 24\\nary sand was being produved with the irours and choked back ta 3960 ibd w')\n",
      "(399, 9, 31, 'hen\\n\\nfluid stream and verified through grind-\\n\\n‘outs which indicates onty traces of BSBW.\\n» Unconsolidated ands stringers Utsira\\n\\nformation caused an increase of ROP rates,\\n\\n‘send production is above 1% for several\\nminutes {+/-1%6 for S000 stb/d) - 141 ps')\n",
      "(400, 9, 32, 'i\\ndrawdown\\n\\nSS es\\n(WOB as the zone is primarity loose,\\nunconsolidated. ‘Monitored with non intrusive sand\\n\\nevection sensor 2s wel as manual\\nsampling\\n\\n«© Prepacked screens were installed across,\\nfeservoir interval to prevent sand\\nProduction from unconsolid')\n",
      "(401, 9, 33, 'ated formation.\\n\\n‘+ Formation stability test increase rate flow\\nsequence after the main buildup. Sand\\nproduction and erosion is monitored by\\nSANDEC system - record impact of sand\\n‘grains on probe\\n\\nFormation stability test Is constraint by low\\npermeability')\n",
      "(402, 9, 34, ' reservoir not wanting to\\nflow the well approaching absolute open\\nflow\\n\\nin significant\\n‘quantities, the flow rave will be reduced\\n\\nprimary sand contro! with downhole wire\\n‘wrapped streen run intest srg.\\n\\n+ Sand production monitored with non-\\nintrusive san')\n",
      "(403, 9, 35, 'd detection sensor as well as\\nmanual sampling\\n\\n+ Rate should be reduced i sand production\\n>2.5% continues more than 15-20 minutes\\n\\n+ BSW samples should be taken frequently\\nat early phase of rate build-up and before\\nand after rate changes\\n\\nFigure 4 Heat Ma')\n",
      "(404, 9, 36, 'p for sand production best practices — Voring Basin\\n\\nReservoir parameters analysis was conducted to observe the sanding occurrence trends with respect to\\nporosity, permeability, skin and perforation shots for each wells experiencing sand production issue.')\n",
      "(405, 9, 37, '\\nStimulated wells with negative skin value, significant high permeability and porosity values are\\n\\n— —————_— ——————\\n\\n\\nVIENNA | AUSTRIA\\n\\narbitrarily associated to sanding issues. However, a few wells do highlight these characteristics but no\\nor little sand')\n",
      "(406, 9, 38, 'ing occurred, and assumptions were made that inter-grain cementation are intact or sanding\\nprobably will occur soon in the later phases of the reservoir as sand production onset is distinct in each\\nwell. Perforation design does not lead primarily towards ')\n",
      "(407, 9, 39, 'sand production as comparison has been made\\nfor wells with the same perforation shots with significantly different reservoir parameters for\\ncomparative analysis. Pore pressure abnormalities attained from Knowledge Graph module possibly\\ncauses sand product')\n",
      "(408, 9, 40, 'ion problems specifically reported in well 25/5-5 and 25/6-3 within Heimdal\\nformation interval, leading to depleted pressure gradient trends in both wells. Analysing the causation\\nof sanding creates an understanding in relation to the sand control practic')\n",
      "(409, 9, 41, 'es conducted for each of the\\nwells. Wells describing sand production issues, sand control mitigation methods and other relatable\\ndescriptions of sand production were intensively analysed as Figure 4 above.\\n\\nConclusion\\n\\nManaging unstructured data into an i')\n",
      "(410, 9, 42, 'ntuitive structured data with embedded end-to-end ML\\nadvanced technology made it possible to interpret, analyze and make decisions with regards to\\nhandling “big data” and derive sand production causation and best practices across 490,000\\npages of public d')\n",
      "(411, 9, 43, 'ocuments inclusive of 361 wells and 2 Norwegian basins in total. The novel\\napproach serves as a holistic study of sand management focused on unstructured “big data”\\nwhich combines multiple digitalization techniques currently applied in the petroleum indus')\n",
      "(412, 9, 44, 'try.\\nMaximizing the potential of underutilized unstructured data leads to opening of vast\\nopportunities for enhancement of production in existing oil and gas wells, and reduces\\ninvestment in the drilling of newer, more expensive wells, in alignment with a')\n",
      "(413, 9, 45, ' re-use, reduce,\\nup-cycle mentality, towards sustainable energy transition for the industry.\\n\\nAcknowledgment\\n\\nThis paper utilizes the data from the Norwegian Petroleum Directorate (NPD) open dataset. Disclaimer\\nof those interpretations from the study are ')\n",
      "(414, 9, 46, 'from investigation and analysis of the authors alone.\\n\\nReferences\\n\\nAcock, A. & ORourke, T. & Shirmboh, D. & Alexander, J. & Andersen, G. & Kaneko, T. &\\nVenkitaraman, A. & Lopez de Cardenas, Jorge & Nishi, M. & Numasawa, M. & Yoshioka, K. & Roy,\\nA. & Wilso')\n",
      "(415, 9, 47, 'n, A. & Twynam, Allan. (2004). Practical approaches to sand management. Oilfield\\nReview. 16. 10-27.\\n\\nBaillard, F., & Hernandez, N. (2021). A Case Study of Understand Bonaparte Basin using\\nUnstructured Data Analysis with Machine Learning Techniques. EAGE A')\n",
      "(416, 9, 48, 'nnual.\\n\\nHernandez, M., & Baillard, F. (2019). An effective G&G exploration strategy inspired by a wolfpack.\\nForce workshop.\\n\\nHernandez, N., Lucafias, P., Graciosa, J., Mamador, C., & Panganiban, I. (2019). Automated\\nInformation Retrieval from Unstructured')\n",
      "(417, 9, 49, ' Documents Utilizing a Sequence of Smart Machine\\nLearning. EAGE Workshop on Big Data and Machine Learning for E&P Efficiency 25 - 27 February.\\n\\nTiab, D. D., Erle C. (2012). Petrophysics - Theory and Practice of Measuring Reservoir Rock and\\nFluid Transport')\n",
      "(418, 9, 50, ' Properties (3rd Edition) - 9.36 Porosity as Strength Indicator to Evaluate Sand\\nProduction. Elsevier.\\n\\nKim, 8.H., Sharma, M. M., and Harvey J. F. (2011). A Predictive Model for Sand Production in\\nPoorly Consolidated Sands. International Petroleum Technol')\n",
      "(419, 9, 51, 'ogy Conference. Doi:\\nhttps://doi.org/10.2523/IPTC-15087-MS.\\n\\n— —————_— ——————\\n\\n')\n",
      "(420, 10, 1, '\\nVIENNA | AUSTRIA\\n\\nUsing Machine Learning-Based Data Factory to Unlock Mining in Australia for Environmental,\\nSocial and Corporate Governance (ESG)\\n\\nIntroduction\\n\\nThe road to net zero requires a lot of raw materials from the mining industry. Renewable ene')\n",
      "(421, 10, 2, 'rgy systems\\nfor solar, hydro, and wind need to be built to support the transition. Among the many metals critical to\\ntechnology and infrastructure necessary for new energy, copper is highly sought after thanks to its\\nconductive efficiency making it an irr')\n",
      "(422, 10, 3, 'eplaceable element of any electrical equipment. Therefore, it is\\nprojected that by 2050, the demand for copper will reach more than 53 million metric tons. This is\\n“more than all the copper consumed in the world between 1900 and 2021”. Given the above, co')\n",
      "(423, 10, 4, 'pper\\nprice spikes, and copper supply challenges are to be expected (Bonakdarpour & Bailey, 2022). Hence,\\nit is crucial to optimize the way copper is mined in order to meet future demands, accelerate the energy\\ntransition and execute the plans of stakehold')\n",
      "(424, 10, 5, 'ers to achieve Environmental, Social and Corporate\\nGovernance (ESG) targets.\\n\\nOptimization of copper mining exploration and operations starts with the capability to easily make\\ndecisions and gain insights using the organizations’ data. However, this data ')\n",
      "(425, 10, 6, 'is often unstructured,\\nscattered, and unsearchable. To extract, manage and sustainably utilize all these unstructured data, a\\ndigital data factory composed of an orchestration of Machine Learning (ML) pipelines, data tracking,\\nand monitoring services, has')\n",
      "(426, 10, 7, ' been implemented on a subset of data from the Geological Survey of\\nQueensland (GSQ) in Australia. Utilizing the ML-based Data factory approach, this paper highlights\\nhow mining information from the GSQ can be analyzed, unlocked, and used in optimizing th')\n",
      "(427, 10, 8, 'e various\\nstages of the copper mining operation such as exploration, mining operation, copper ore processing,\\nreclamation and safety, health, and environmental control.\\n\\nMethodology\\n\\nUnstructured data from the GSQ contains scientific reports, borehole com')\n",
      "(428, 10, 9, 'pletion reports, publications,\\njournals, mining datasets, map collections, and mining records. The documents are highly technical and\\nspread over decades of mining operations making manual human interpretation and data extraction\\nchallenging. The dataset ')\n",
      "(429, 10, 10, 'covers 62 years of mining operation in Queensland and has been ingested in\\nthe data factory at a rate of 3,000 pages and 4,000 images per day through its scalable automated ML\\npipeline and big data capabilities. The steps of the processing include uploadi')\n",
      "(430, 10, 11, 'ng the data to the cloud,\\naudit of the data, text/image extraction, image classification, and table export capabilities as seen in\\nFigure 1. The features of this ML-based data factory transform voluminous unstructured data into\\nstructured data that are re')\n",
      "(431, 10, 12, 'adily accessible through a cloud-based application for text, image, and\\nknowledge search. The data factory’s features have applications that can be extended to all copper\\nmining stages.\\n\\nSomme aN RE ay Province Deposit\\nPralisatic st oom\\n\\nee ln = er | oe\\nT')\n",
      "(432, 10, 13, 'able OCR Image classification Word Cloud\\n\\nFigure 1 Transversal corpus search features of the digital data factory.\\nSeamless Search Tool\\n\\nTo have a firm grasp of the copper resource information covering the definitions, inferences,\\nindications, and compile')\n",
      "(433, 10, 14, 'd measurements, geologists and mining professionals involved in the\\n\\n— —————_— ——————\\n\\n\\nVIENNA | AUSTRIA\\n\\nexploration stage of the copper mining projects would need to be able to gain new insights and search\\nthrough their unstructured data (OceanaGold Cor')\n",
      "(434, 10, 15, 'poration, 2022). The ingestion and digestion process\\nmakes it possible to obtain new knowledge and insights, which is very difficult to achieve from the\\noriginal unstructured data. The ingested data is run through a Machine Learning-based pipeline that\\ntr')\n",
      "(435, 10, 16, 'ansforms the unstructured data into structured data with its elements made searchable (Mamador et\\nal., 2020). With the seamless search, geological, mineral and deposit information can be found\\nefficiently and fresh insights into the site mineralogy can be')\n",
      "(436, 10, 17, ' gained with relative ease (Maver et al.,\\n2021).\\n\\nCopper mineral deposit models can be correlated to their appropriate locations on geological maps and\\nsupported by visual evidence such as mineralogy descriptions in drill hole cores and geological maps\\nas')\n",
      "(437, 10, 18, ' displayed in Figure 2. Solid geological inferences can be made regarding the characteristics of the\\ncopper ore deposit, which can then lead to feasible drilling and productive mining plans supported by\\nowned data.\\n\\nFigure 2 Findings from deep corpus sear')\n",
      "(438, 10, 19, 'ch of copper resource models and new geological insights\\nacross Queensland.\\n\\nFile, Domain and Image Tagging\\n\\nFile, domain, and image tagging are performed through the data factory. This allows for the\\nconsolidation of unstructured data, breaking data silo')\n",
      "(439, 10, 20, 's across documents and disciplines, and making\\nall the relevant data during the copper mining operation accessible across organizations and contractors,\\nhence streamlining mining workflows and supporting cross-company collaboration (Maver et al., 2021).\\n\\n')\n",
      "(440, 10, 21, 'An ongoing copper mining operation would continuously produce various figurative and imagery data\\nsuch as resources and machinery management, schedules, rainfall, land survey information, engineering\\nsolutions, geology, and more. Some, if not all of these')\n",
      "(441, 10, 22, ' will be integrated or considered in the mining\\nplan or model (OceanaGold Corporation, 2022).\\n\\nThe continuous aggregation by domain experts and ingestion of unstructured data that happens during\\nthis stage of operation are improved via machine learning pr')\n",
      "(442, 10, 23, 'ocesses and scaled suitably. This is\\nparticularly useful to track, reassess, visualize, and evaluate the mining plans or mining models at\\nvarious copper mining stages, such as tracking the progress of specific sub-blocks at a particular time.\\nInformation ')\n",
      "(443, 10, 24, 'from various sources would be integrated or correlated with these mining plans or models\\nto support decision-making associated with the site as shown in Figure 3. This process facilitates not\\nonly efficient and easy problem-solving conditions but supports')\n",
      "(444, 10, 25, ' planning processes and governance\\nstructures to be data-based and able to respond to ESG opportunities, risks and challenges (Maver et\\nal., 2021).\\n\\n— —————_— ——————\\n\\n\\nVIENNA | AUSTRIA\\n\\nTEE\\nSEE\\nrlele]s\\n\\n> TK HILL\\nINE\\n\\nRRESCRE\\n\\nFigure 3 Important documents')\n",
      "(445, 10, 26, ' and varying information concerning the mining model at different\\nscales are accessible by various roles (mining engineers, operators, surveyors, geologists, etc.) across\\nthe organization involved.\\n\\nTable extraction\\n\\nEngineering, geoscience, and even meta')\n",
      "(446, 10, 27, 'llurgic processes at the copper processing plant produce a vast\\nwealth of tables and numerical data (OceanaGold Corporation, 2022). Classifying tables to a particular\\nimage group is also tracked by the data factory. Optical character recognition (OCR) is ')\n",
      "(447, 10, 28, 'used to identify\\nand locate individual and specific information which can be used in further analyses. By automatically\\nconverting each table image to a .csv file, valuable information becomes easily available, searchable,\\nand aggregated across various mi')\n",
      "(448, 10, 29, 'ning operation stages or copper processing plant processes as shown\\non Figure 4, Manual translation of the table to a .csv file can therefore be avoided, and information\\ntracked to the original location in the report.\\n\\nTonnage || Copper | Tin || Siver || ')\n",
      "(449, 10, 30, 'indium\\nSwsaeasion | ue) | gw) |) iw)\\nworcaren | ose | 25 | os] ee || se\\neenneo | 000s [ar [oa | ow | ve\\n\\nTOTAL 0.828 25 oa || 96 36\\n\\nFigure 4 Table image with numerical values such as tonnage and ore grades identified by the data\\nfactory’s OCR and extract')\n",
      "(450, 10, 31, 'ed for external documents.\\n\\nBeing able to extract numerical values from tables is valuable to help track mining information such as\\nore grades, tonnage, production values, coordinates, rainfall, work hours, processing plant or laboratory\\nparameters.\\n\\nMapp')\n",
      "(451, 10, 32, 'ing of Similar Files and Word Cloud\\n\\nA data factory contains multiple tools that facilitate rapid comprehension and understanding of the\\ncontext of the data. For example, the searchability of the elements in each document allows transverse\\ndocuments withi')\n",
      "(452, 10, 33, 'n the vast database with similar keywords to be grouped together through the search\\nresults. The word cloud associated with each document also allows rapid comprehension of the whole\\ndocument briefly. Finding analogues, similarities, and historical issues')\n",
      "(453, 10, 34, ' is a problem that now has a\\nsolution. In the case of safety, health, and environmental control, incidents, lost time injury (LTD, and\\nreports of investigation (RI) can be traced to specific documents or even specific pages in the original\\nreports,\\n\\n\\n\\nVIE')\n",
      "(454, 10, 35, 'NNA | AUSTRIA\\n\\nEnvironmental, Social and Corporate Governance Targets in Mining\\n\\nThe data factory certainly allows the risks and opportunities related to sustainability to be recognized,\\nevaluated and managed under a holistic framework pertaining to envir')\n",
      "(455, 10, 36, 'onmental, social and governance\\naspects. The data factory approach is an incentive that can add value and align the mining operation\\nwith broader Environmental, Social and Corporate Governance (ESG) goals to limit environment\\nimpact. The data-supported ho')\n",
      "(456, 10, 37, 'listic ecosystem from this approach is positioned to enhance cost-benefit\\nassessment of the ESG throughout the mining cycle.\\n\\nConclusion\\n\\nManaging unstructured data into structured data embedded with end-to-end ML/AI advanced\\ntechnology made it possible t')\n",
      "(457, 10, 38, 'o explore, analyze and make fast decisions using big data. With this,\\norganizations involved in copper mining projects and more generally in the mining industry are able to\\nprocess and present new mining information and knowledge from the dataset. Tools w')\n",
      "(458, 10, 39, 'ithin the data\\nfactory such as deep search module, word cloud, table extraction, and image identification contribute\\nsignificantly to providing a comprehensive understanding across the full value chain for the copper\\ndeposit models, mining plans, copper t')\n",
      "(459, 10, 40, 'reatment processes, rehabilitation plans, and safety, health and\\nenvironmental trends. Hence, maximizing the capability of unstructured data has proved impactful in\\nterms of significantly reducing the consumption of research time and costs (Maver et al., ')\n",
      "(460, 10, 41, '2021) and\\nalign mining operations with global ESG limiting the impact on the environment.\\n\\nAcknowledgment\\n\\nThis paper utilizes the data from the GSQ Open Data Portal database (geoscience.data.qld.gov.au). This\\ndatabase is owned by the Queensland Governmen')\n",
      "(461, 10, 42, 't and is open for public access. However, the\\ninterpretation and conclusion contained in this report are those of the authors alone.\\n\\nReferences\\n\\nBonakdarpour, M. & Bailey, T.M. (2022) The future of copper — Will the looming supply gap short-\\ncircuit the ')\n",
      "(462, 10, 43, 'energy transition? S&P Global. JHS Markit.\\n\\nMamador, C., Aranda, J. O., Arif, N. E., Hernandez, N. M., & Baillard, F. (2020, September). A\\ngeological regional case study for pressure, temperature, and salinity for the GoM using machine\\nlearning technology')\n",
      "(463, 10, 44, ' on unstructured data. In EAGE/AAPG digital subsurface for Asia Pacific\\nConference (Vol. 2020, No. 1, pp. 1-4). European Association of Geoscientists & Engineers.\\n\\nMaver, K. G., Baillard, F., & Hernandez, N. M. (2021, May). Accelerating E&P Decisions by\\nA')\n",
      "(464, 10, 45, 'pplying Artificial Intelligence and Big Data Analytics to Unstructured Data. In Digital Subsurface\\nConference in Latin America (Vol. 2021, No. 1, pp. 1-5). European Association of Geoscientists &\\nEngineers.\\n\\nMaver, K. G., Hernandez, N. M., Baillard, F., &')\n",
      "(465, 10, 46, ' Cooper, R. (2020). Processing of unstructured\\ngeoscience and engineering information for instant access and extraction of new knowledge. First\\nBreak, 38(6), 59-64.\\n\\nOceanaGold Corporation (2022). The mining process. OceanaGold. Retrieved from\\nhttps://oce')\n",
      "(466, 10, 47, 'anagold.com/operation/macraes/the-mining-process/\\n\\n— —————_— ——————\\n\\n')\n"
     ]
    }
   ],
   "source": [
    "# Execute a SELECT query\n",
    "query = \"SELECT * FROM chunks\"\n",
    "mycursor.execute(query)\n",
    "\n",
    "# Fetch all rows\n",
    "rows = mycursor.fetchall()\n",
    "\n",
    "# Print the results\n",
    "for row in rows:\n",
    "    print(row)  # You can format this output as needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate a dictionary from the paper\n",
    "As of 09/06/2024, the chatbot model uses the dictionary data type to look up information,\n",
    "so here I try to query the database and turn the paper we saved into a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute a query to select all the rows from the 'papers' table\n",
    "query = \"SELECT title, author, chunk FROM papers\"\n",
    "mycursor.execute(query)\n",
    "\n",
    "# Fetch all the rows\n",
    "rows = mycursor.fetchall()\n",
    "\n",
    "# Create a dictionary with the format you specified\n",
    "paper = {\n",
    "    \"title\": rows[0][0],\n",
    "    \"author\": rows[0][1],\n",
    "    \"content\": ''.join(row[2] for row in rows)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check our output\n",
    "We verify if the paper has indeed been loaded into a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'title': 'A CASE STUDY OF UNDERSTANDING THE BONAPARTE BASIN USING UNSTRUCTURED DATA ANALYSIS WITH MACHINE LEARNING TECHNIQUES', 'author': 'A.N.N. Sazali, N.M. Hernandez, F. Baillard, K.G. Maver', 'content': \"\\nA CASE STUDY OF UNDERSTANDING THE\\n\\nBONAPARTE BASIN USING UNSTRUCTURED DATA\\nANALYSIS WITH MACHINE LEARNING TECHNIQUES\\n\\nANN. Sazali!, N.M. Hernandez', F. Baillard', K.G. Maver!\\n\\n' Traya Energies\\n\\nSummary\\n\\nAs part of exploration and production the oil and gas industry produce substantial amounts of data\\nwithin different disciplines of which 80% are unstructured like reports, presentations, spreadsheets etc.\\nThe value of technical work is reduced due to the lack of time available for analysis and critical\\nthinking and the under-utilization of the data. To assist geoscientist and engineers, Machine Learning\\n(ML) and Artificial Intelligence (AI) technologies are applied to process the unstructured data from\\n440 wells from the Bonaparte Basin in Australia making it possible to perform more accurate analysis\\nand make faster decisions.\\n\\nBased on the play-based exploration pyramid concept, the time spent at the Basin Focus stage can be\\nreduced, and more time are available to focus on the other project stages. The explorationist will be\\nable to bring more value to the study.\\n\\nIt will be shown that potential issues encountered during exploration of the Bonaparte Basin can be\\nidentified. Based on a quick look and gathering of all information it can be concluded that most of the\\nproduction in the Bonaparte Basin is from Jurassic and Triassic with observed net pay of 18-60m\\nthickness, porosity of 11-29% and saturation of 11-55% Sw.\\n\\n\\nA Case Study of Understanding the Bonaparte Basin using Unstructured Data Analysis with\\nMachine Learning Techniques\\n\\nIntroduction\\n\\nAs part of exploration and production the oil and gas industry produce substantial amounts of data\\nwithin different disciplines of which 80% are unstructured like reports, presentations, spreadsheets etc\\nand it is expected to grow exponentially. As a result, geoscientists and engineers spend 50 to 80% of\\ntheir time searching and assembling data and only 1 to 5% of the data is fully utilized. The value of\\ntechnical work is therefore reduced due to the lack of time available for analysis and critical thinking\\nand the under-utilization of the data. To assist geoscientist and engineers, Machine Learning (ML)\\nand Artificial Intelligence (AI) technologies are applied to process the unstructured data making it\\npossible to perform more accurate analysis and make faster decisions.\\n\\nIn this case study the area of interest covers Bonaparte Basin, which is located north-west of\\nthe Australian continental margin (Figure 1). It joins the Money Shoal basin in the north-east and\\nthe Browse Basin in the south-west. Furthermore, the Timor Trough defines the northern boundary.\\nThe areal extent of the basin is approximately 270,000 sq. km. The objective of this study is to\\nunderstand and obtain meaningful insights into the Bonaparte Basin based on the substantial amount\\nof information available in previous studies, reports and presentations. The unstructured data of the\\nBonaparte Basin have been ingested in a Knowledge Container through consecutive ML and AI\\npipelines and analysed using big data analytics tools.\\n\\nJava Sea\\n\\nConsist of several structural elements :\\n@ Ashmore Platform  Malita Graben\\n Vulcan Sub-Basin  Sahul Platform\\n Londonderry High @ Flamingo High\\n Petrel Sub-basin @ Flamingo Syncline\\n Darwin Shelf  Sahul Syncline\\n@ Calder Graben  Nancar Trough\\n@ Troubadour Terrace  @)_ Laminaria High\\n\\nFigure 1 Location of the Bonaparte Basin within the Australian continental margin (left) and 14\\nstructural elements observed within the Bonaparte Basin (right).\\n\\nMethodology\\n\\nAs of 2021, the Bonaparte Basin encompasses 440 wells representing 58 years of exploration history\\nsummarized in over 270,000 pages of documents and in 250,000 images. It is estimated that billions of\\ndollars have been invested over the years to acquire and interprete the data, making it a substantial\\nsource of information for new exploration activities.\\n\\nThe Play Based Exploration (PBE) approach is often used as a traditional framework to refine the\\ngeoscientistss understanding from a broad basin level to a narrow prospect focus (Lottaroli et al., 2016).\\nAs a start such an approach often involves capturing the current state of knowledge with massive\\nbackground resources to understand and analyse the key features of the basin and the major risks\\nassociated to it. Such information is primarily available in unstructured data, requiring geoscientist and\\nengineers to process and ingest the information before focusing on a specific play and prospect using\\nstructured data. Therefore, we have modified the existing PBE pyramid to introduce an additional\\n\\n  \\n\\n\\ndimension associated with data science identifying the different types of data available at different\\nstages, allowing us to better define the best suited ML/AI strategy for a given stage (Figure 2).\\n\\nProspect Specific chance\\n\\nProspect focus\\n= image, Map, Evaluate\\n\\nSTRUCTURED chance that a panicular prospect will\\nbecome\\na discovery in case play works.\\n\\nPlay Focus\\n\\n' Play Chance\\n1 Identity imits ofthe single play elements 1 the chance hat a parteuler play\\nunsracres: Al eee wean | gy mesnereamecercett\\n\\\\ dbcare te 1 elements (e.g. reservoir, seal, source)\\neffectiveness of each element | of being present and effective over an\\n\\n(Commmon Risk Segment Mapping)\\n\\n@ Analyse play statistics. Seon Gey O44 a\\n\\nDetermination and description of the\\nRegional context and Basin\\nFramework\\nUnderstanding of the Petroleum\\nsystem(s)\\n\\nBasin Focus\\n\\n= Assess the possibility a play may\\nexists in a basin\\n\\nFigure 2 Customized Play Based Exploration (PBE) pyramid with ML technology (Modified from\\nLottaroli et al., 2016).\\n\\nFocusing on the unstructured data associated with the Basin and Play Analysis, all the data from the\\nBonaparte Basin have been processed through a succession of AI/ML automated pipeline such as\\nNatural Language Processing or Deep Convolutional Neural Network (Hernandez et al., 2019), (Figure\\n3). The sharable structured data is then further processed through deeper level of analytics to detect\\ntrends and anomalies present within the data. Machine assistance is heavily used in repetitive tasks early\\nin the process during the processing of the data and up to 95% of the tasks will be performed by the\\nmachine. This provides additional time for the specialist to focus on critical thinking and cognitive skills\\nto interpret the data.\\n\\nMACHINE LEARNING PIPELINE ANALYTICS, GEOLOGICAL INSIGHTS\\n\\n-inniogy an Early interpretation on\\nGeological environment\\n\\n* Text Search Data are geospatially\\n\\nExtracted image ea\\n+ Imoges. ~~ Image Classification  > nae |, distributed on maps for\\nDeep Convolutional ee trends and anomalies\\nUnstructured pecker hom Giants\\n Structured * Image Search\\nData ee\\na\\n\\n|, Extracted | Metadata Extraction |, Document\\nText and Tagging Tags\\n\\nNotural tanguage Processing\\n\\n._ Early trend can be observed\\n\\n> Heat Mi in\\nea MEe across the whole basin\\n\\n._ Identify well analogues and\\n\\nHEE oe relationship between wells\\n\\nMACHINE 4 on =\\n\\nAf. 50.%5 . i 60% 0%\\n\\nML/Al sequence automated with Analytics tools for data display Human high-level interpretation\\nhuman in the loop for QC\\n\\nFigure 3 Unstructured Big Data pipeline\\n\\nIn this case study, interpretation using the Big Data workflow was used to understand the exploration\\nhistory, how the basin developed, its petroleum system and the main issue of the dry wells occurrence\\nto avoid repeating the mistakes of the past and improve future decision making.\\n\\n\\n\\nBy analysing the data, five potential issues are identified i.e. (i) Discrepancies in Formation Tops, (ii)\\nLimited understanding of Lithology Distribution, (iii) Limited Mineral Composition Understanding,\\n(iv) Fluid Distribution, and (v) Pressure/Temperature Patterns. Each potential issue is tackled by\\nidentifying trends and anomalies across the basin using images, tables and plots extracted from the\\nunstructured data corpus.\\n\\nResults\\n\\nAs an example, the analysis of the (ii) Limited Understanding of Lithology Distribution, shown in\\nFigure 4, is performed using heatmaps. The heatmaps show the distribution of clastic and carbonates\\nacross the Bonaparte Basin and identify patterns and anomalies present in the area. The result can be\\nsupported by the stratigraphic chart where the carbonate environment occurs in the younger formation\\nfrom Cretaceous to Neogene period, whereas clastic environment is present in the older formations from\\nTriassic to Cretaceous.\\n\\nNe\\n\\nPALEOGENE\\neae\\n\\nEa\\n\\nCRETACEOUS\\n\\n$3233 3 3\\nJURASSIC\\n\\ntoy | Mee\\n\\nTing 5\\nwo\\n\\nBasal transgressive snadstone EEEEEE Limestone\\n\\nand marine shelf sand\\nMarine claystone and shale ES van\\n\\nModitied trom Frankowicz & McClay 2009\\n\\nFigure 4 Lithology distribution on heatmaps (left) and corresponding stratigraphic chart (right).\\n\\nThe analysis of the (iii) Limited Mineral Composition Understanding, shown in Figure 5, utilizes the\\nthin section automatically extracted using ML classification over the full area and suggests that:\\n\\n Quartz overgrowth and kaolinite are quite common in Bonaparte Basin\\n\\ne Mica mineral can be observed at the north-eastern part of the basin\\n\\ne Highly corroded, skeletal feldspar has been extensively dissolved, which forms secondary\\nporosity, and can be observed in the northern part of the basin\\n\\ne Some patchy siderites are also observed in the southern part of the basin\\n\\n  \\n\\n\\nFigure 5 Thin section images distributed on a map across the Bonaparte Basin.\\n\\nConclusion\\n\\nA regional understanding is critical and time consuming as it involves dealing with a very large data\\nvolume. Within a project time frame, based on PBE pyramid, the time spent at the Basin Focus stage\\ncan be reduced, and more time are available to focus on the other project stages. The explorationist will\\nbe able to bring more value to the study.\\n\\nML applications have proven to be able to play a crucial part in order to organize large unstructured\\ndata corpuses. This allows faster and accurate decision making within the fast-moving industry.\\n\\nIn this study, some potential issues encountered during exploration of the Bonaparte Basin can be\\nidentified. Based on a quick look and gathering of all information it can be concluded that most of the\\nproduction in the Bonaparte Basin is from Jurassic and Triassic with observed net pay ~18-60m\\nthickness, porosity ~11-29% and saturation ~11-55% Sw.\\n\\nReferences\\n\\nHernandez N., Lucafias P., Graciosa J.C., Mamador C., and Panganiban L. C. L, 2019: Automated\\ninformation retrieval from unstructured documents utilizing a sequence of smart machine learning\\nmethods within a hybrid cloud container. EAGE Workshop on Big Data and Machine Learning for E&P\\nEfficiency 25 - 27 February.\\n\\nLottaroli F., Craig J., Cozzi A., 2016: Evaluating a vintage play fairway exercise using subsequent\\nexploration results: did it work? Petroleum Geoscience, Vol 24, no 2, p. 159-171.\\n\\nMaver K.G., Hernandez N., Lucafias P., Graciosa J.C., Mamador C., Panganiban L.C.I., Yu C., and\\nMaver M.G., 2018: An automated information retrieval platform for unstructured well data smart\\nmachine learning algorithms within a hybrid cloud container. EAGE/PESGB Workshop on Machine\\nLearning, 29  30 November.\\n\\n\\n\"}\n"
     ]
    }
   ],
   "source": [
    "# Print the paper\n",
    "print(paper)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "streamlit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
