{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "18e436666c6540af8538395a01438dcd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_55974a54213b4a26b9bfcce00f390710",
              "IPY_MODEL_2b6848668d4c4533828005e64b58bfe3",
              "IPY_MODEL_976ed6bc78d148ebbe4f36e65bdae57c"
            ],
            "layout": "IPY_MODEL_51a529143fb3461c919f84901981b373"
          }
        },
        "55974a54213b4a26b9bfcce00f390710": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3ff841ec6c394aaea7075c77cca00c55",
            "placeholder": "​",
            "style": "IPY_MODEL_a135aa0834744490b84e6a61d1f3e7f8",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "2b6848668d4c4533828005e64b58bfe3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_59fd13ff138d435ba9468d69bc5e3f75",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_59aaf979d715411a99c234a79e2ed515",
            "value": 2
          }
        },
        "976ed6bc78d148ebbe4f36e65bdae57c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4c0ccef7cae940959ce59e01e0c987fc",
            "placeholder": "​",
            "style": "IPY_MODEL_7fd5edc66ca64e1fb8e5f1f02e8a032c",
            "value": " 2/2 [00:32&lt;00:00, 15.53s/it]"
          }
        },
        "51a529143fb3461c919f84901981b373": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3ff841ec6c394aaea7075c77cca00c55": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a135aa0834744490b84e6a61d1f3e7f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "59fd13ff138d435ba9468d69bc5e3f75": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "59aaf979d715411a99c234a79e2ed515": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4c0ccef7cae940959ce59e01e0c987fc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7fd5edc66ca64e1fb8e5f1f02e8a032c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WmHCaf9ntcO_",
        "outputId": "d95f71ae-8117-4e97-9613-03bb0347650b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting accelerate\n",
            "  Downloading accelerate-0.30.1-py3-none-any.whl (302 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/302.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m297.0/302.6 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.6/302.6 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (24.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.3.0+cu121)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.23.2)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.12.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m70.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2024.2.2)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, accelerate\n",
            "Successfully installed accelerate-0.30.1 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105\n"
          ]
        }
      ],
      "source": [
        "pip install accelerate"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install sentence_transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6eqUzLZCtfUr",
        "outputId": "d89b349b-7c4c-43f4-f65e-d81eface027f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sentence_transformers\n",
            "  Downloading sentence_transformers-3.0.0-py3-none-any.whl (224 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/224.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[32m215.0/224.7 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.7/224.7 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: transformers<5.0.0,>=4.34.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.41.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.66.4)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (2.3.0+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.25.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.11.4)\n",
            "Requirement already satisfied: huggingface-hub>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (0.23.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (9.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (3.14.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (2023.6.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (6.0.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (2.31.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (4.12.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (3.1.4)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11.0->sentence_transformers) (12.5.40)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence_transformers) (2024.5.15)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence_transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence_transformers) (0.4.3)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers) (3.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence_transformers) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (2024.2.2)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->sentence_transformers) (1.3.0)\n",
            "Installing collected packages: sentence_transformers\n",
            "Successfully installed sentence_transformers-3.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install flash-attn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eePRsueqttO-",
        "outputId": "89268c08-f593-4ceb-c545-6386e8312a70"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting flash-attn\n",
            "  Downloading flash_attn-2.5.9.post1.tar.gz (2.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m41.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from flash-attn) (2.3.0+cu121)\n",
            "Collecting einops (from flash-attn)\n",
            "  Downloading einops-0.8.0-py3-none-any.whl (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.2/43.2 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (4.12.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->flash-attn) (12.5.40)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->flash-attn) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->flash-attn) (1.3.0)\n",
            "Building wheels for collected packages: flash-attn\n",
            "  Building wheel for flash-attn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for flash-attn: filename=flash_attn-2.5.9.post1-cp310-cp310-linux_x86_64.whl size=120889689 sha256=5022ba11d48bf74926da9c16260f4ea2b9bb7f4e29bdb4bd6e1383ad1c55d16f\n",
            "  Stored in directory: /root/.cache/pip/wheels/cc/ad/f6/7ccf0238790d6346e9fe622923a76ec218e890d356b9a2754a\n",
            "Successfully built flash-attn\n",
            "Installing collected packages: einops, flash-attn\n",
            "Successfully installed einops-0.8.0 flash-attn-2.5.9.post1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install faiss-gpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6RumV5mYtu0E",
        "outputId": "78452bdc-5065-473f-abfc-caa603e4afc9"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting faiss-gpu\n",
            "  Downloading faiss_gpu-1.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (85.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.5/85.5 MB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faiss-gpu\n",
            "Successfully installed faiss-gpu-1.7.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import faiss\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM,pipeline\n",
        "import torch\n",
        "import re"
      ],
      "metadata": {
        "id": "av3kzqiTuCIQ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# IMPORT MODEL"
      ],
      "metadata": {
        "id": "VFilEkH8uSVH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load model in FP16 precision to save memory\n",
        "chat_model = AutoModelForCausalLM.from_pretrained(\n",
        "    \"microsoft/Phi-3-mini-4k-instruct\",\n",
        "    device_map=\"cuda\",\n",
        "    torch_dtype=torch.float16,  # change to auto\n",
        "    trust_remote_code=True,\n",
        ")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/Phi-3-mini-4k-instruct\")\n",
        "\n",
        "pipe = pipeline(\n",
        "        \"text-generation\",\n",
        "        model=chat_model,\n",
        "        tokenizer=tokenizer,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "18e436666c6540af8538395a01438dcd",
            "55974a54213b4a26b9bfcce00f390710",
            "2b6848668d4c4533828005e64b58bfe3",
            "976ed6bc78d148ebbe4f36e65bdae57c",
            "51a529143fb3461c919f84901981b373",
            "3ff841ec6c394aaea7075c77cca00c55",
            "a135aa0834744490b84e6a61d1f3e7f8",
            "59fd13ff138d435ba9468d69bc5e3f75",
            "59aaf979d715411a99c234a79e2ed515",
            "4c0ccef7cae940959ce59e01e0c987fc",
            "7fd5edc66ca64e1fb8e5f1f02e8a032c"
          ]
        },
        "id": "yiYwV5nluUax",
        "outputId": "a0486e85-71de-48cb-bddf-043416dee85e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "18e436666c6540af8538395a01438dcd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# IMPORT DATA"
      ],
      "metadata": {
        "id": "9rnSRyYsuvO1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample research papers with authors\n",
        "sample_papers = [\n",
        "    {\n",
        "        \"title\": \"Advancements in Quantum Computing\",\n",
        "        \"author\": \"Alice Johnson\",\n",
        "        \"content\": (\n",
        "            \"Quantum computing is revolutionizing the field of information technology by utilizing quantum bits (qubits) instead of traditional bits. \"\n",
        "            \"This allows for unprecedented processing power and efficiency.\\n\\n\"\n",
        "            \"Recent breakthroughs have demonstrated the feasibility of practical quantum computers. Companies like IBM and Google have developed quantum processors \"\n",
        "            \"capable of performing complex calculations at speeds unattainable by classical computers.\\n\\n\"\n",
        "            \"One major challenge is maintaining qubit coherence. Efforts are being made to improve error correction techniques, which are essential for the reliable \"\n",
        "            \"operation of quantum computers. Advances in materials science have also contributed to more stable qubits.\\n\\n\"\n",
        "            \"Quantum algorithms, such as Shor's algorithm for factoring large numbers, have the potential to disrupt industries that rely on encryption. These algorithms \"\n",
        "            \"can solve certain problems exponentially faster than the best classical algorithms.\\n\\n\"\n",
        "            \"The future of quantum computing holds immense promise, with potential applications ranging from drug discovery to financial modeling. As the technology matures, \"\n",
        "            \"it is expected to have a profound impact on various fields.\\n\\n\"\n",
        "            \"Further research is needed to overcome existing challenges and unlock the full potential of quantum computing. Collaborative efforts between academia, \"\n",
        "            \"industry, and government agencies are essential to drive innovation and accelerate the development of practical quantum technologies.\\n\\n\"\n",
        "            \"Moreover, quantum computing has implications for cybersecurity. Quantum-resistant cryptographic techniques are being developed to secure sensitive information \"\n",
        "            \"against potential threats posed by quantum computers.\\n\\n\"\n",
        "            \"In addition, quantum machine learning is emerging as a promising field. By harnessing the power of quantum algorithms, machine learning models can \"\n",
        "            \"achieve unprecedented performance improvements, opening up new possibilities for data analysis and pattern recognition.\"\n",
        "        )\n",
        "    },\n",
        "    {\n",
        "        \"title\": \"Machine Learning in Healthcare\",\n",
        "        \"author\": \"Bob Smith\",\n",
        "        \"content\": (\n",
        "            \"Machine learning is transforming healthcare by enabling more accurate diagnoses and personalized treatments. It leverages large datasets to uncover patterns \"\n",
        "            \"that are not apparent to human analysts.\\n\\n\"\n",
        "            \"One key application is in medical imaging, where machine learning algorithms can detect anomalies in X-rays and MRIs with high precision. These tools assist radiologists \"\n",
        "            \"in identifying early signs of diseases like cancer.\\n\\n\"\n",
        "            \"Predictive analytics is another area where machine learning shines. By analyzing patient data, algorithms can predict the likelihood of disease outbreaks or patient readmissions, \"\n",
        "            \"helping healthcare providers to take proactive measures.\\n\\n\"\n",
        "            \"Natural language processing (NLP) allows for the analysis of unstructured data, such as doctors' notes and clinical reports. This capability enhances the understanding of patient \"\n",
        "            \"histories and improves decision-making processes.\\n\\n\"\n",
        "            \"The integration of machine learning in healthcare is not without challenges. Issues such as data privacy, algorithm bias, and the need for large, high-quality datasets must be addressed \"\n",
        "            \"to fully realize the potential of these technologies.\\n\\n\"\n",
        "            \"Moreover, machine learning is facilitating medical research by analyzing genomic data and identifying potential drug targets. This has the potential to revolutionize \"\n",
        "            \"drug discovery and development processes, leading to more effective treatments for various diseases.\\n\\n\"\n",
        "            \"Furthermore, machine learning algorithms are being used to optimize hospital operations, from resource allocation to patient scheduling. By streamlining administrative \"\n",
        "            \"tasks, healthcare institutions can improve efficiency and reduce costs.\"\n",
        "        )\n",
        "    },\n",
        "    {\n",
        "        \"title\": \"Renewable Energy Technologies\",\n",
        "        \"author\": \"Carol White\",\n",
        "        \"content\": (\n",
        "            \"Renewable energy technologies are critical in the fight against climate change. They provide sustainable and cleaner alternatives to fossil fuels.\\n\\n\"\n",
        "            \"Solar energy has seen significant advancements, with improvements in photovoltaic cell efficiency and reductions in cost. Large-scale solar farms are now viable sources of energy in many \"\n",
        "            \"parts of the world.\\n\\n\"\n",
        "            \"Wind energy is another growing sector. Innovations in turbine design have increased energy capture and reduced maintenance costs, making wind farms more economically competitive.\\n\\n\"\n",
        "            \"Hydroelectric power remains a major renewable energy source. Advances in turbine technology and the development of small-scale hydro systems have expanded its applicability.\\n\\n\"\n",
        "            \"Bioenergy and geothermal energy also contribute to the renewable energy mix. Research into biofuels and advanced geothermal systems continues to improve their efficiency and environmental impact.\\n\\n\"\n",
        "            \"In addition to technological advancements, policy support and investment in renewable energy infrastructure are crucial for accelerating the transition to a sustainable energy future.\\n\\n\"\n",
        "            \"Furthermore, renewable energy technologies offer economic benefits, such as job creation and energy independence. By investing in renewables, countries can reduce their reliance \"\n",
        "            \"on imported fossil fuels and stimulate local economies.\"\n",
        "        )\n",
        "    },\n",
        "    {\n",
        "        \"title\": \"Artificial Intelligence in Finance\",\n",
        "        \"author\": \"David Brown\",\n",
        "        \"content\": (\n",
        "            \"Artificial intelligence (AI) is reshaping the finance industry by automating processes and enhancing decision-making. AI algorithms analyze vast amounts of data to identify trends and make predictions.\\n\\n\"\n",
        "            \"In trading, AI systems execute trades at speeds and volumes impossible for humans, optimizing investment strategies and improving market efficiency.\\n\\n\"\n",
        "            \"Risk management has also benefited from AI. Machine learning models assess credit risk and detect fraudulent transactions, providing greater security and reducing financial losses.\\n\\n\"\n",
        "            \"Customer service is another area where AI has made an impact. Chatbots and virtual assistants handle customer inquiries, offering personalized support and freeing up human agents for more complex tasks.\\n\\n\"\n",
        "            \"Despite the advantages, the integration of AI in finance raises concerns about job displacement, data privacy, and the potential for algorithmic bias. Addressing these challenges is crucial for the ethical deployment of AI technologies.\\n\\n\"\n",
        "            \"Furthermore, AI-powered algorithms are being used to detect market trends and inform investment decisions. By analyzing vast amounts of financial data, these algorithms can identify \"\n",
        "            \"profitable opportunities and mitigate risks.\\n\\n\"\n",
        "            \"Moreover, AI-driven robo-advisors are gaining popularity among investors. These automated investment platforms use algorithms to create personalized portfolios based on individual \"\n",
        "            \"financial goals and risk preferences.\"\n",
        "        )\n",
        "    },\n",
        "    {\n",
        "        \"title\": \"Nanotechnology in Medicine\",\n",
        "        \"author\": \"Eve Davis\",\n",
        "        \"content\": (\n",
        "            \"Nanotechnology is revolutionizing medicine by enabling the development of novel diagnostic and therapeutic tools. Nanoparticles can be engineered to target specific cells, enhancing the precision of treatments.\\n\\n\"\n",
        "            \"One application of nanotechnology is in drug delivery. Nanocarriers can transport drugs directly to diseased cells, reducing side effects and improving treatment efficacy.\\n\\n\"\n",
        "            \"Nanotechnology is also used in imaging. Nanoparticles can enhance the contrast in MRI and CT scans, allowing for earlier and more accurate detection of diseases.\\n\\n\"\n",
        "            \"Tissue engineering benefits from nanotechnology through the creation of scaffolds that promote cell growth and tissue regeneration. These scaffolds mimic the natural extracellular matrix, providing a suitable environment for cell proliferation.\\n\\n\"\n",
        "            \"While the potential of nanotechnology in medicine is vast, challenges such as toxicity, long-term effects, and regulatory hurdles need to be addressed to ensure safe and effective applications.\\n\\n\"\n",
        "            \"Moreover, interdisciplinary collaboration between researchers, clinicians, and regulatory agencies is essential to accelerate the translation of nanotechnology-based medical innovations from the laboratory to clinical practice.\\n\\n\"\n",
        "            \"In addition, nanotechnology holds promise for personalized medicine. By tailoring treatments to individual patients' genetic makeup and disease profiles, nanomedicine offers the potential for more effective and targeted therapies.\\n\\n\"\n",
        "            \"Furthermore, nanotechnology-based diagnostic tools enable early disease detection and monitoring, improving patient outcomes and reducing healthcare costs.\\n\\n\"\n",
        "            \"As nanotechnology continues to advance, its integration into clinical practice has the potential to revolutionize healthcare delivery and improve patient care.\"\n",
        "        )\n",
        "    },\n",
        "    {\n",
        "        \"title\": \"The Future of Space Exploration\",\n",
        "        \"author\": \"Emily Johnson\",\n",
        "        \"content\": (\n",
        "            \"Space exploration has long captured the imagination of humanity, driving technological innovation and expanding our understanding of the universe.\\n\\n\"\n",
        "            \"Advancements in space propulsion systems are enabling faster and more efficient travel beyond Earth's orbit. Concepts such as ion propulsion and solar sails offer the potential \"\n",
        "            \"for interstellar exploration and colonization.\\n\\n\"\n",
        "            \"Robotic missions to celestial bodies, such as Mars and Europa, continue to uncover new insights into planetary geology and the potential for life beyond Earth.\\n\\n\"\n",
        "            \"The emergence of commercial spaceflight companies, such as SpaceX and Blue Origin, is democratizing access to space and fostering innovation in space technology.\\n\\n\"\n",
        "            \"Furthermore, international collaborations, such as the International Space Station (ISS), demonstrate the power of cooperation in advancing scientific research and exploration.\\n\\n\"\n",
        "            \"As we look to the future, space exploration holds the promise of answering fundamental questions about our place in the universe and inspiring future generations of scientists and explorers.\"\n",
        "        )\n",
        "    },\n",
        "    {\n",
        "        \"title\": \"Ethical Considerations in Genetic Engineering\",\n",
        "        \"author\": \"Michael Wilson\",\n",
        "        \"content\": (\n",
        "            \"Genetic engineering offers unprecedented opportunities to modify and manipulate the genetic makeup of organisms, raising complex ethical questions and concerns.\\n\\n\"\n",
        "            \"One of the key ethical considerations is the potential for unintended consequences. Genetic modifications intended to address one issue may have unforeseen impacts on ecosystems \"\n",
        "            \"and biodiversity.\\n\\n\"\n",
        "            \"Another concern is the possibility of genetic discrimination. Access to genetic enhancement technologies could exacerbate existing social inequalities and create new forms of discrimination based on genetic traits.\\n\\n\"\n",
        "            \"The concept of 'designer babies,' where genetic traits are selected or modified for non-medical purposes, raises ethical dilemmas related to autonomy, consent, and the commodification of life.\\n\\n\"\n",
        "            \"Moreover, the global nature of genetic engineering raises questions about governance and regulation. International collaboration and consensus-building are essential to develop \"\n",
        "            \"ethical frameworks and guidelines for responsible genetic research and application.\\n\\n\"\n",
        "            \"As genetic engineering technologies continue to advance, it is imperative that ethical considerations remain at the forefront of scientific discourse and decision-making processes.\"\n",
        "        )\n",
        "    },\n",
        "    {\n",
        "        \"title\": \"The Rise of Virtual Reality\",\n",
        "        \"author\": \"Sophia Miller\",\n",
        "        \"content\": (\n",
        "            \"Virtual reality (VR) technology is revolutionizing the way we interact with digital content and experience immersive environments.\\n\\n\"\n",
        "            \"Advancements in VR hardware, such as headsets and haptic feedback devices, are making virtual experiences more realistic and engaging.\\n\\n\"\n",
        "            \"VR has applications across various industries, including gaming, entertainment, education, and healthcare. In gaming, VR allows players to step into virtual worlds and \"\n",
        "            \"interact with environments and characters in unprecedented ways.\\n\\n\"\n",
        "            \"In healthcare, VR is being used for medical training, therapy, and pain management. Virtual simulations provide a safe and controlled environment for medical professionals \"\n",
        "            \"to practice procedures and for patients to confront fears and phobias.\\n\\n\"\n",
        "            \"The potential of VR extends beyond entertainment and healthcare. In education, VR enables immersive learning experiences, allowing students to explore historical events, \"\n",
        "            \"scientific concepts, and cultural landmarks firsthand.\\n\\n\"\n",
        "            \"As VR technology becomes more accessible and affordable, its impact on society is expected to grow, ushering in new forms of storytelling, communication, and collaboration.\"\n",
        "        )\n",
        "    },\n",
        "    {\n",
        "        \"title\": \"The Impact of Climate Change on Biodiversity\",\n",
        "        \"author\": \"Oliver Davis\",\n",
        "        \"content\": (\n",
        "            \"Climate change poses a significant threat to biodiversity, with profound implications for ecosystems and species around the world.\\n\\n\"\n",
        "            \"Rising temperatures, changing precipitation patterns, and extreme weather events are altering habitats and disrupting ecosystems, leading to shifts in species distributions \"\n",
        "            \"and changes in phenology.\\n\\n\"\n",
        "            \"Many species are facing increased risk of extinction due to habitat loss, reduced food availability, and competition from invasive species.\\n\\n\"\n",
        "            \"Marine ecosystems are particularly vulnerable to climate change, with ocean acidification, coral bleaching, and loss of sea ice threatening marine biodiversity.\\n\\n\"\n",
        "            \"Addressing climate change requires urgent and coordinated action at the local, national, and global levels. Mitigation efforts, such as reducing greenhouse gas emissions and \"\n",
        "            \"protecting and restoring habitats, are essential to safeguarding biodiversity.\\n\\n\"\n",
        "            \"Adaptation strategies, such as creating climate-resilient protected areas and implementing sustainable land and water management practices, can help species and ecosystems \"\n",
        "            \"adapt to changing environmental conditions.\\n\\n\"\n",
        "            \"Preserving biodiversity is not only essential for maintaining healthy ecosystems and supporting human well-being but also crucial for mitigating the impacts of climate change \"\n",
        "            \"and building resilience to future environmental challenges.\"\n",
        "        )\n",
        "    }\n",
        "]"
      ],
      "metadata": {
        "id": "9LqQTK8iuxKU"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PREPROCESS DATA"
      ],
      "metadata": {
        "id": "UhAsIt4lu_ho"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess the content\n",
        "def clean_text(text):\n",
        "    text = re.sub(r'\\s+', ' ', text)  # Remove extra whitespace\n",
        "    text = re.sub(r'\\[[^]]*\\]', '', text)  # Remove references\n",
        "    return text.strip()\n",
        "\n",
        "# Clean and chunk the text\n",
        "documents = []\n",
        "for paper in sample_papers:\n",
        "    cleaned_content = clean_text(paper['content'])\n",
        "    chunks = cleaned_content.split('. ')\n",
        "    for chunk in chunks:\n",
        "        if chunk.strip():  # Only keep non-empty chunks\n",
        "            documents.append({'title': paper['title'], 'author': paper['author'], 'content': chunk.strip()})"
      ],
      "metadata": {
        "id": "dY96hqZLvBMc"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EMBED AND QUERY (Searching Database)"
      ],
      "metadata": {
        "id": "E58YRh37vM_I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the sentence transformer model\n",
        "embed_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "# Generate embeddings for each document chunk\n",
        "embeddings = []\n",
        "metadata = []\n",
        "for doc in documents:\n",
        "    embedding = embed_model.encode(doc['content'])\n",
        "    embeddings.append(embedding)\n",
        "    metadata.append({'title': doc['title'], 'author': doc['author'], 'content': doc['content']})\n",
        "\n",
        "# Convert embeddings list to numpy array\n",
        "embeddings = np.array(embeddings)\n",
        "\n",
        "# Create a FAISS index\n",
        "index = faiss.IndexFlatL2(embeddings.shape[1])\n",
        "index.add(embeddings)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VUU1SCYYvRGP",
        "outputId": "17d43887-19f1-4a39-bfe2-5901fd69e594"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RETRIEVE CONTEXT"
      ],
      "metadata": {
        "id": "1EV6xwd3vbip"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to retrieve context based on query\n",
        "def retrieve_context(query, k=5, threshold=1.3):\n",
        "    query_embedding = embed_model.encode(query).reshape(1, -1)\n",
        "    distances, indices = index.search(query_embedding, k)\n",
        "    results = []\n",
        "    for dist, idx in zip(distances[0], indices[0]):\n",
        "        if dist < threshold:  # Only include relevant contexts\n",
        "            results.append(metadata[idx])\n",
        "    return results"
      ],
      "metadata": {
        "id": "nUgDVoupvTm0"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# User query\n",
        "query = \"What is Nano Techology? And what can it do, sate your source\"\n",
        "\n",
        "# Retrieve context from the knowledge base\n",
        "context = retrieve_context(query)\n",
        "context_text = \"\\n\\n\".join([f\"Title: {item['title']}\\nAuthor: {item['author']}\\nContent: {item['content']}\" for item in context])\n",
        "\n",
        "print(context_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RUKeDFd3vWPh",
        "outputId": "6d8a5bd0-0392-4473-9b3d-209fab8a1828"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Title: Nanotechnology in Medicine\n",
            "Author: Eve Davis\n",
            "Content: Nanotechnology is also used in imaging\n",
            "\n",
            "Title: Nanotechnology in Medicine\n",
            "Author: Eve Davis\n",
            "Content: As nanotechnology continues to advance, its integration into clinical practice has the potential to revolutionize healthcare delivery and improve patient care.\n",
            "\n",
            "Title: Nanotechnology in Medicine\n",
            "Author: Eve Davis\n",
            "Content: Moreover, interdisciplinary collaboration between researchers, clinicians, and regulatory agencies is essential to accelerate the translation of nanotechnology-based medical innovations from the laboratory to clinical practice\n",
            "\n",
            "Title: Nanotechnology in Medicine\n",
            "Author: Eve Davis\n",
            "Content: In addition, nanotechnology holds promise for personalized medicine\n",
            "\n",
            "Title: Nanotechnology in Medicine\n",
            "Author: Eve Davis\n",
            "Content: Nanotechnology is revolutionizing medicine by enabling the development of novel diagnostic and therapeutic tools\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GENERATE RESPONSE"
      ],
      "metadata": {
        "id": "eci7LUxT0Fa6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "generation_args = {\n",
        "  \"max_new_tokens\": 500,\n",
        "  \"return_full_text\": False,\n",
        "  \"temperature\": 0.5,\n",
        "  \"do_sample\": True,\n",
        "}\n",
        "\n",
        "def generate_response(instruction, query):\n",
        "  context = retrieve_context(query)\n",
        "  context_text = \"\\n\\n\".join([f\"Title: {item['title']}\\nAuthor: {item['author']}\\nContent: {item['content']}\" for item in context])\n",
        "\n",
        "  # print(f\"Context: {context_text}\")\n",
        "\n",
        "  messages = [{\"role\": \"user\", \"content\": f\"{instruction} The Content: {context_text}\"},\n",
        "              {\"role\": \"assistant\", \"content\": \"Welcome user, I am your helpful assistant\"}\n",
        "             ]\n",
        "\n",
        "  input = {\"role\": \"user\", \"content\": query}\n",
        "  messages.append(input)\n",
        "\n",
        "  output = pipe(messages, **generation_args)\n",
        "  response = output[0]['generated_text']\n",
        "\n",
        "  print(f\"Bot: {response}\")\n",
        "  # return response\n",
        "\n",
        "  # print(\"\\nHistory:\")\n",
        "  # for i in messages:\n",
        "  #   print(f\"Role: {i['role']} : {i['content']}\")"
      ],
      "metadata": {
        "id": "sLBQxsli0Gs7"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "q = \"What are Nano Technology? And where can it be used (provide a list). Provide your author or source on where you got the data\"\n",
        "i = \"You are a helpful assistant knowledgeable in various research topics. You are to output only the answer and nothing else. As much as possbile use the Context provided if there is context provided. Only use double space when necessary. If asked for source, do not reply with a link, provide the authors or anything related to the source related to the Content\"\n",
        "\n",
        "generate_response(i, q)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jpZ5YcyI0LMg",
        "outputId": "353a0454-5198-43eb-c61b-35ea14e9e716"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bot:  Nanotechnology refers to the manipulation and control of matter on an atomic, molecular, and supramolecular scale, typically between 1 and 100 nanometers. It involves the design, characterization, production, and application of structures, devices, and systems by controlling shape and size at the nanometer scale.\n",
            "\n",
            "Nanotechnology can be used in various fields, including but not limited to:\n",
            "\n",
            "1. Medicine: Nanotechnology is used in drug delivery systems, medical imaging, diagnostics, tissue engineering, and regenerative medicine.\n",
            "2. Electronics: Nanotechnology is used in the development of smaller and more efficient electronic devices, such as transistors, sensors, and memory storage.\n",
            "3. Energy: Nanotechnology is used in the production of more efficient solar cells, batteries, and fuel cells.\n",
            "4. Environment: Nanotechnology is used in water purification, air filtration, and pollution control.\n",
            "5. Materials Science: Nanotechnology is used in the development of stronger, lighter, and more durable materials for various industries, including aerospace, automotive, and construction.\n",
            "\n",
            "The information provided is based on research by Eve Davis, an author who has written extensively on the topic of nanotechnology in medicine. For more in-depth information, you can refer to her work, \"Nanotechnology in Medicine.\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "i = \"You are a helpful assistant knowledgeable in various research topics. You are to output only the answer and nothing else. As much as possbile use the Context provided if there is context provided. Only use double space when necessary\"\n",
        "\n",
        "while True:\n",
        "  q = input(\"User: \")\n",
        "\n",
        "  generate_response(i, q)"
      ],
      "metadata": {
        "id": "0rlONXtN0MYl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gc7_J_zP3Rg1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}